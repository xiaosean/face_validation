{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "1 #define _CUDA_NDARRAY_C\n",
      "2 \n",
      "3 #include <Python.h>\n",
      "4 #include <structmember.h>\n",
      "5 #include \"theano_mod_helper.h\"\n",
      "6 \n",
      "7 #include <numpy/arrayobject.h>\n",
      "8 #include <iostream>\n",
      "9 \n",
      "10 #include \"cuda_ndarray.cuh\"\n",
      "11 \n",
      "12 #ifndef CNMEM_DLLEXPORT\n",
      "13 #define CNMEM_DLLEXPORT\n",
      "14 #endif\n",
      "15 \n",
      "16 #include \"cnmem.h\"\n",
      "17 #include \"cnmem.cpp\"\n",
      "18 \n",
      "19 //If true, when there is a gpu malloc or free error, we print the size of allocated memory on the device.\n",
      "20 #define COMPUTE_GPU_MEM_USED 0\n",
      "21 \n",
      "22 //If true, we fill with NAN allocated device memory.\n",
      "23 #define ALLOC_MEMSET 0\n",
      "24 \n",
      "25 //If true, we print out when we free a device pointer, uninitialize a\n",
      "26 //CudaNdarray, or allocate a device pointer\n",
      "27 #define PRINT_FREE_MALLOC 0\n",
      "28 \n",
      "29 //If true, we do error checking at the start of functions, to make sure there\n",
      "30 //is not a pre-existing error when the function is called.\n",
      "31 //You probably need to set the environment variable\n",
      "32 //CUDA_LAUNCH_BLOCKING=1, and/or modify the CNDA_THREAD_SYNC\n",
      "33 //preprocessor macro in cuda_ndarray.cuh\n",
      "34 //if you want this to work.\n",
      "35 #define PRECHECK_ERROR 0\n",
      "36 \n",
      "37 cublasHandle_t handle = NULL;\n",
      "38 int* err_var = NULL;\n",
      "39 \n",
      "40 /////////////////////////\n",
      "41 // Alloc and Free\n",
      "42 /////////////////////////\n",
      "43 \n",
      "44 static int g_gpu_context_active = 0;\n",
      "45 \n",
      "46 \n",
      "47 PyObject *\n",
      "48 CudaNdarray_Dimshuffle(PyObject* _unused, PyObject* args);\n",
      "49 static PyObject *CudaNdarray_get_shape(CudaNdarray *self, void *closure);\n",
      "50 \n",
      "51 \n",
      "52 /**\n",
      "53  *\n",
      "54  * In the test program I'm using, the _outstanding_mallocs decreases with every call.\n",
      "55  * This suggests there are more free() calls being made than alloc(), but I can't figure out why.\n",
      "56  *\n",
      "57  */\n",
      "58 int _outstanding_mallocs[] = {0,0};\n",
      "59 \n",
      "60 #if COMPUTE_GPU_MEM_USED\n",
      "61 size_t _allocated_size = 0;\n",
      "62 size_t _max_allocated_size = 0;\n",
      "63 \n",
      "64 const int TABLE_SIZE = 10000;\n",
      "65 struct table_struct{\n",
      "66     void* ptr;\n",
      "67     size_t size;\n",
      "68 };\n",
      "69 table_struct _alloc_size_table[TABLE_SIZE];\n",
      "70 #endif\n",
      "71 \n",
      "72 void * device_malloc(size_t size)\n",
      "73 {\n",
      "74     return device_malloc(size, VERBOSE_DEVICE_MALLOC);\n",
      "75 }\n",
      "76 \n",
      "77 static bool g_use_cnmem = false;\n",
      "78 static const int g_max_devices = 8;\n",
      "79 int initCnmem(int card_number_provided, int card_nb, size_t mem) {\n",
      "80     static bool cnmemInitialized = false;\n",
      "81     if(cnmemInitialized) {\n",
      "82         return 0;\n",
      "83     }\n",
      "84     // On stderr to be at the same place as \"Using gpu device...\"\n",
      "85     int numDevices = 0;\n",
      "86     cnmemDevice_t devices[g_max_devices];\n",
      "87     if(cudaGetDeviceCount(&numDevices) != cudaSuccess) {\n",
      "88         PyErr_Format(PyExc_RuntimeError,\n",
      "89                      \"initCnmem: 'cudaGetDeviceCount' failed! Reason=%s\\n\",\n",
      "90                      cudaGetErrorString(cudaGetLastError()));\n",
      "91         return -1;\n",
      "92     }\n",
      "93     if(card_number_provided){\n",
      "94         numDevices = 1;\n",
      "95         int i = 0;\n",
      "96         devices[i].device = card_nb;\n",
      "97         devices[i].size = mem;\n",
      "98         ///@TODO: thejaswi: add support for multiple streams\n",
      "99         devices[i].numStreams = 0;\n",
      "100         devices[i].streams = NULL;\n",
      "101         devices[i].streamSizes = NULL;\n",
      "102     }else{\n",
      "103         for(int i=0;i<numDevices;++i) {\n",
      "104             devices[i].device = i;\n",
      "105             devices[i].size = mem;\n",
      "106             ///@TODO: thejaswi: add support for multiple streams\n",
      "107             devices[i].numStreams = 0;\n",
      "108             devices[i].streams = NULL;\n",
      "109         }\n",
      "110     }\n",
      "111 \n",
      "112     ///@TODO: thejaswi: passing custom cnmem flags?\n",
      "113     cnmemStatus_t status = cnmemInit(numDevices, devices, CNMEM_FLAGS_DEFAULT);\n",
      "114     if(status != CNMEM_STATUS_SUCCESS) {\n",
      "115         PyErr_Format(PyExc_RuntimeError,\n",
      "116                      \"initCnmem: cnmemInit call failed! Reason=%s. numdev=%d\\n\",\n",
      "117                      cnmemGetErrorString(status), numDevices);\n",
      "118         return -1;\n",
      "119     }\n",
      "120     cnmemInitialized = true;\n",
      "121     return 0;\n",
      "122 }\n",
      "123 \n",
      "124 void * device_malloc(size_t size, int verbose)\n",
      "125 {\n",
      "126     #if PRECHECK_ERROR\n",
      "127         cudaThreadSynchronize();\n",
      "128         cudaError_t prevError = cudaGetLastError();\n",
      "129         if (cudaSuccess != prevError)\n",
      "130         {\n",
      "131             fprintf(stderr,\n",
      "132                     \"Error existed before calling device_malloc. %s\\n\",\n",
      "133                     cudaGetErrorString(prevError)\n",
      "134                     );\n",
      "135         }\n",
      "136     #endif\n",
      "137     void * rval=NULL;\n",
      "138     ///@TODO: thejaswi: support for multiple-streams?\n",
      "139     if(g_use_cnmem) {\n",
      "140         cnmemStatus_t status = CNMEM_STATUS_SUCCESS;\n",
      "141         status = cnmemMalloc(&rval, size, NULL);\n",
      "142         if(status != CNMEM_STATUS_SUCCESS) {\n",
      "143             PyErr_Format(PyExc_MemoryError,\n",
      "144                          \"Error allocating %llu bytes of device memory (%s).\",\n",
      "145                          (unsigned long long)size, cnmemGetErrorString(status));\n",
      "146             return NULL;\n",
      "147         }\n",
      "148     }\n",
      "149     else {\n",
      "150         cudaError_t err = cudaMalloc(&rval, size);\n",
      "151         if (cudaSuccess != err)\n",
      "152         {\n",
      "153             // Clear the error flag, cudaMalloc doesn't do it.\n",
      "154             // Currently this returns the same thing as err, but if in future\n",
      "155             // it returns something else I still don't see why we should ignore\n",
      "156             // it.  All we want to do here is reset the flag.\n",
      "157             cudaGetLastError();\n",
      "158             if (verbose)\n",
      "159             {\n",
      "160                 size_t free = 0, total = 0;\n",
      "161                 cudaError_t err2 = cudaMemGetInfo(&free, &total);\n",
      "162                 if (err2 != cudaSuccess){\n",
      "163                     cudaGetLastError();\n",
      "164                     fprintf(stderr,\n",
      "165                             \"Error when trying to find the memory information\"\n",
      "166                             \" on the GPU: %s\\n\", cudaGetErrorString(err2));\n",
      "167                 }\n",
      "168                 #if COMPUTE_GPU_MEM_USED\n",
      "169                     fprintf(stderr,\n",
      "170                             \"Error allocating %llu bytes of device memory (%s).\"\n",
      "171                             \" new total bytes allocated: %llu.\"\n",
      "172                             \" Driver report %llu bytes free and %llu bytes total \\n\",\n",
      "173                             (unsigned long long)size, cudaGetErrorString(err), (unsigned long long)_allocated_size,\n",
      "174                             (unsigned long long)free, (unsigned long long)total);\n",
      "175                 #else\n",
      "176                     fprintf(stderr,\n",
      "177                             \"Error allocating %llu bytes of device memory (%s).\"\n",
      "178                             \" Driver report %llu bytes free and %llu bytes total \\n\",\n",
      "179                             (unsigned long long)size, cudaGetErrorString(err), (unsigned long long)free, (unsigned long long)total);\n",
      "180                 #endif\n",
      "181             }\n",
      "182             PyErr_Format(PyExc_MemoryError,\n",
      "183                          \"Error allocating %llu bytes of device memory (%s).\",\n",
      "184                          (unsigned long long)size, cudaGetErrorString(err));\n",
      "185             return NULL;\n",
      "186         }\n",
      "187     }\n",
      "188     if (rval != NULL){\n",
      "189         // Can it happen that cudaMalloc return cudaSuccess, but return a NULL ptr?\n",
      "190         // Could this be what happen if size is 0?\n",
      "191         _outstanding_mallocs[0] += 1;\n",
      "192 \n",
      "193 #if COMPUTE_GPU_MEM_USED\n",
      "194         _allocated_size += size;\n",
      "195         _max_allocated_size = std::max(_max_allocated_size, _allocated_size);\n",
      "196         int i = 0;\n",
      "197         for(;i<TABLE_SIZE;i++){\n",
      "198             if(NULL==_alloc_size_table[i].ptr){\n",
      "199                 _alloc_size_table[i].ptr=rval;\n",
      "200                 _alloc_size_table[i].size=size;\n",
      "201                 break;\n",
      "202             }\n",
      "203         }\n",
      "204         if (i == TABLE_SIZE){\n",
      "205             fprintf(stderr,\n",
      "206                     \"When tracking GPU malloc, our table size wasn't big enough.\"\n",
      "207                     \" So we loose some tracking. Raise the value of TABLE_SIZE in the file cuda_ndarra.cu\");\n",
      "208         }\n",
      "209 #endif\n",
      "210     }\n",
      "211     //fprintf(stderr,\n",
      "212     //\"allocated %li bytes of device memory (%s). new total bytes allocated: %d. ptr: %p\\n\",\n",
      "213     //(long)size, cudaGetErrorString(err),_allocated_size,rval);\n",
      "214 \n",
      "215     if(ALLOC_MEMSET){\n",
      "216         //We init them to nan to make sure we catch more debug case.\n",
      "217         cudaMemset(rval, 0xFF, size);\n",
      "218         //printf(\"MEMSET\\n\");\n",
      "219     }\n",
      "220     #if PRINT_FREE_MALLOC\n",
      "221         fprintf(stderr, \"device malloc %p of size %d\\n\", rval, size);\n",
      "222     #endif\n",
      "223     return rval;\n",
      "224 }\n",
      "225 \n",
      "226 int device_free(void *ptr)\n",
      "227 {\n",
      "228     #if PRECHECK_ERROR\n",
      "229         cudaThreadSynchronize();\n",
      "230         cudaError_t prevError = cudaGetLastError();\n",
      "231         if (cudaSuccess != prevError)\n",
      "232         {\n",
      "233             fprintf(stderr,\n",
      "234                     \"Error existed before calling device_free. %s\\n\",\n",
      "235                     cudaGetErrorString(prevError)\n",
      "236                     );\n",
      "237         }\n",
      "238     #endif\n",
      "239     #if PRINT_FREE_MALLOC\n",
      "240         size_t free = 0, total = 0;\n",
      "241         cudaError_t err2 = cudaMemGetInfo(&free, &total);\n",
      "242         if (err2 != cudaSuccess){\n",
      "243             cudaGetLastError();\n",
      "244             fprintf(stderr,\n",
      "245                     \"Error when tring to find the memory information\"\n",
      "246                     \" on the GPU: %s\\n\", cudaGetErrorString(err2));\n",
      "247         }\n",
      "248         #if COMPUTE_GPU_MEM_USED\n",
      "249         {\n",
      "250             int i = 0;\n",
      "251             for(;i<TABLE_SIZE;i++)\n",
      "252                 if(_alloc_size_table[i].ptr==ptr){\n",
      "253                     break;\n",
      "254                 }\n",
      "255             assert(i<TABLE_SIZE);\n",
      "256             fprintf(stderr, \"device_free %p of size %d.\"\n",
      "257                     \" Driver report %d bytes free and %d bytes total \\n\",\n",
      "258                     ptr, _alloc_size_table[i].size, free, total);\n",
      "259         }\n",
      "260         #else\n",
      "261             fprintf(stderr, \"device_free %p.\"\n",
      "262                     \" Driver report %d bytes free and %d bytes total \\n\",\n",
      "263                     ptr, free, total);\n",
      "264         #endif\n",
      "265     #endif\n",
      "266 \n",
      "267     // if there is no gpu context, the call to cudaFree will fail; skip it entirely\n",
      "268     if(!g_gpu_context_active) {\n",
      "269         return 0;\n",
      "270     }\n",
      "271 \n",
      "272     ///@TODO: thejaswi: multi-stream support\n",
      "273     if(g_use_cnmem) {\n",
      "274         cnmemStatus_t status = cnmemFree(ptr, NULL);\n",
      "275         if(status != CNMEM_STATUS_SUCCESS) {\n",
      "276             fprintf(stderr, \"device_free: cnmemFree call failed! Reason=%s\\n\",\n",
      "277                     cnmemGetErrorString(status));\n",
      "278         }\n",
      "279     }\n",
      "280     else {\n",
      "281         // We need sync as the Theano's GC could remove intermediate variable that\n",
      "282         // are still needed as the gpu kernel are running or in the queue.\n",
      "283         CNDA_BEGIN_ALLOW_THREADS\n",
      "284         cudaThreadSynchronize();\n",
      "285         CNDA_END_ALLOW_THREADS\n",
      "286 \n",
      "287         cudaError_t err =  cudaFree(ptr);\n",
      "288         if (cudaSuccess != err)\n",
      "289         {\n",
      "290             // Clear the error flag, cudaFree doesn't do it.\n",
      "291             // Currently this returns the same thing as err, but if in future\n",
      "292             // it returns something else I still don't see why we should ignore\n",
      "293             // it.  All we want to do here is reset the flag.\n",
      "294             cudaGetLastError();\n",
      "295             size_t free = 0, total = 0;\n",
      "296             cudaError_t err2 = cudaMemGetInfo(&free, &total);\n",
      "297             if (err2 != cudaSuccess){\n",
      "298                 cudaGetLastError();\n",
      "299                 fprintf(stderr,\n",
      "300                         \"Error when tring to find the memory information\"\n",
      "301                         \" on the GPU: %s\\n\", cudaGetErrorString(err2));\n",
      "302             }\n",
      "303             #if COMPUTE_GPU_MEM_USED\n",
      "304             {\n",
      "305                 int i = 0;\n",
      "306                 for(;i<TABLE_SIZE;i++)\n",
      "307                     if(_alloc_size_table[i].ptr==ptr){\n",
      "308                         break;\n",
      "309                     }\n",
      "310                 assert(i<TABLE_SIZE);\n",
      "311                 fprintf(stderr,\n",
      "312                         \"Error freeing device pointer %p (%s) of size %llu. %llu byte already allocated.\"\n",
      "313                         \" Driver report %llu bytes free and %llu bytes total \\n\",\n",
      "314                         ptr, cudaGetErrorString(err),\n",
      "315                         (unsigned long long)_alloc_size_table[i].size, (unsigned long long)_allocated_size, (unsigned long long)free, (unsigned long long)total);\n",
      "316             }\n",
      "317             #else\n",
      "318                 fprintf(stderr,\n",
      "319                         \"Error freeing device pointer %p (%s).\"\n",
      "320                         \" Driver report %llu bytes free and %llu bytes total \\n\",\n",
      "321                         ptr,\n",
      "322                         cudaGetErrorString(err), (unsigned long long)free, (unsigned long long)total);\n",
      "323             #endif\n",
      "324             if (NULL != PyErr_Occurred()){\n",
      "325                 fprintf(stderr,\n",
      "326                         \"device_free: cudaFree() returned an error, but there is already an\"\n",
      "327                         \" Python error set. This happen during the clean up when there is a\"\n",
      "328                         \" first error and the CUDA driver is in a so bad state that it don't\"\n",
      "329                         \" work anymore. We keep the previous error set to help debugging it.\");\n",
      "330                 return -1;\n",
      "331             }\n",
      "332             PyErr_Format(PyExc_MemoryError,\n",
      "333                     \"error freeing device pointer %p (%s)\",\n",
      "334                     ptr,\n",
      "335                     cudaGetErrorString(err));\n",
      "336             return -1;\n",
      "337         }\n",
      "338     }\n",
      "339     _outstanding_mallocs[0] -= (ptr != NULL);\n",
      "340     #if COMPUTE_GPU_MEM_USED\n",
      "341         int i=0;\n",
      "342         size_t total_freed = 0;\n",
      "343         for(;i<TABLE_SIZE;i++)\n",
      "344             if(_alloc_size_table[i].ptr==ptr){\n",
      "345                 _allocated_size -= _alloc_size_table[i].size;\n",
      "346                 total_freed += _alloc_size_table[i].size;\n",
      "347                 _alloc_size_table[i].ptr=0;\n",
      "348                 _alloc_size_table[i].size=0;\n",
      "349 \n",
      "350                 break;\n",
      "351             }\n",
      "352         //if(i==TABLE_SIZE)\n",
      "353         //    printf(\"Unallocated unknow size!\\n\");\n",
      "354         //fprintf(stderr, \"freed %li bytes of device memory (%s). %d already allocated, ptr=%p\\n\", (long)total_freed, cudaGetErrorString(err),_allocated_size,ptr);\n",
      "355     #endif\n",
      "356     return 0;\n",
      "357 }\n",
      "358 \n",
      "359 static PyObject *\n",
      "360 outstanding_mallocs(PyObject* self, PyObject * args)\n",
      "361 {\n",
      "362     return PyInt_FromLong(_outstanding_mallocs[0]);\n",
      "363 }\n",
      "364 \n",
      "365 \n",
      "366 static void *work_mem = NULL;\n",
      "367 static size_t work_size = 0;\n",
      "368 \n",
      "369 /*\n",
      "370  * Returns a chunk of memory for temporary work inside of an op. You can only\n",
      "371  * request a single chunk of memory at a time since it is reused.\n",
      "372  */\n",
      "373 void *get_work_mem(size_t sz) {\n",
      "374     if (sz <= work_size)\n",
      "375         return work_mem;\n",
      "376     device_free(work_mem);\n",
      "377     work_mem = device_malloc(sz);\n",
      "378     work_size = sz;\n",
      "379     if (work_mem == NULL)\n",
      "380         work_size = 0;\n",
      "381     return work_mem;\n",
      "382 }\n",
      "383 \n",
      "384 /////////////////////////\n",
      "385 // Static helper methods\n",
      "386 /////////////////////////\n",
      "387 \n",
      "388 static void\n",
      "389 CudaNdarray_null_init(CudaNdarray*self)\n",
      "390 {\n",
      "391     self->base = NULL;\n",
      "392     self->nd = -1;\n",
      "393     self->host_structure = NULL;\n",
      "394     self->data_allocated = 0;\n",
      "395     self->dev_structure_fresh = 1;\n",
      "396     self->dev_structure = NULL;\n",
      "397     self->devdata = NULL;\n",
      "398 }\n",
      "399 \n",
      "400 static int\n",
      "401 CudaNdarray_uninit(CudaNdarray*self)\n",
      "402 {\n",
      "403     #if PRINT_FREE_MALLOC\n",
      "404         fprintf(stderr, \"CudaNdarray_uninit %p\\n\", self);\n",
      "405     #endif\n",
      "406     int rval = 0;\n",
      "407     if (self->data_allocated) {\n",
      "408         assert(self->devdata);\n",
      "409         if (device_free(self->devdata))\n",
      "410         {\n",
      "411             fprintf(stderr,\n",
      "412                     \"CudaNdarray_uninit: error freeing self->devdata. (self=%p, self->devata=%p)\\n\",\n",
      "413                     self, self->devdata);\n",
      "414             rval = -1;\n",
      "415         }\n",
      "416         self->devdata = NULL;\n",
      "417         self->data_allocated = 0;\n",
      "418     }\n",
      "419     if (self->dev_structure)\n",
      "420     {\n",
      "421         if (device_free(self->dev_structure))\n",
      "422         {\n",
      "423             fprintf(stderr,\n",
      "424                     \"CudaNdarray_uninit: error freeing dev_structure memory %p (self=%p)\\n\",\n",
      "425                     self->dev_structure, self);\n",
      "426             rval = -1;\n",
      "427         }\n",
      "428         self->dev_structure = NULL;\n",
      "429     }\n",
      "430     if (self->host_structure)\n",
      "431     {\n",
      "432         free(self->host_structure);\n",
      "433         self->host_structure = NULL;\n",
      "434     }\n",
      "435     self->nd = -1;\n",
      "436     Py_XDECREF(self->base);\n",
      "437     self->base = NULL;\n",
      "438     return rval;\n",
      "439 }\n",
      "440 \n",
      "441 \n",
      "442 //make the rightmost coords change fastest\n",
      "443 //TODO: why does a downward for-loop not work????\n",
      "444 //TODO: use the log2_dims and driver code to remove / and %\n",
      "445 //TODO: skip the last division (when d == 0)\n",
      "446 #define decl_k_elemwise_unary_rowmajor(name, F) \\\n",
      "447 __global__ void name (unsigned int numEls,  \\\n",
      "448         unsigned int nd, \\\n",
      "449         const int * dim,  \\\n",
      "450         const float * a_data, const int * a_str, \\\n",
      "451         float * z_data, const int * z_str) \\\n",
      "452 { \\\n",
      "453     const unsigned int idx = blockIdx.x * blockDim.x + threadIdx.x; \\\n",
      "454     const unsigned int numThreads = blockDim.x * gridDim.x; \\\n",
      "455  \\\n",
      "456     for (unsigned int i = idx; i < numEls; i += numThreads) \\\n",
      "457     { \\\n",
      "458         unsigned int ii = i; \\\n",
      "459         const float * a_i = a_data; \\\n",
      "460         float * z_i = z_data; \\\n",
      "461         for (unsigned int _d = 0; _d < nd; ++_d) \\\n",
      "462         { \\\n",
      "463             unsigned int d = nd - _d-1;  \\\n",
      "464             int i_d = ii % dim[d]; /* i_d is our position in the d'th dimension   */ \\\n",
      "465             ii = ii / dim[d]; \\\n",
      "466             a_i += i_d * a_str[d]; /* increment our a and z pointers by i_d elements */ \\\n",
      "467             z_i += i_d * z_str[d]; \\\n",
      "468         } \\\n",
      "469         z_i[0] = F(a_i[0]); \\\n",
      "470     } \\\n",
      "471 }\n",
      "472 \n",
      "473 template<typename T> __device__ T unary_copy(T a) { return a; }\n",
      "474 decl_k_elemwise_unary_rowmajor(k_elemwise_unary_rowmajor_copy, unary_copy<float>)\n",
      "475 \n",
      "476 template<typename T> __device__ T unary_exp(T a) { return exp(a); }\n",
      "477 decl_k_elemwise_unary_rowmajor(k_elemwise_unary_rowmajor_exp, unary_exp<float>)\n",
      "478 \n",
      "479 /////////////////////////////\n",
      "480 // Satisfying reqs to be Type\n",
      "481 /////////////////////////////\n",
      "482 \n",
      "483 //DON'T use directly(if their is other CudaNdarray that point to it, it will cause problem)! use Py_DECREF() instead\n",
      "484 static void\n",
      "485 CudaNdarray_dealloc(CudaNdarray* self)\n",
      "486 {\n",
      "487     if (0) std::cerr << \"CudaNdarray dealloc \" << self << \" \" << self->devdata << '\\n';\n",
      "488     if(Py_REFCNT(self) > 1)\n",
      "489       printf(\"WARNING:CudaNdarray_dealloc called when there is still active reference to it.\\n\");\n",
      "490     CudaNdarray_uninit(self);\n",
      "491     Py_TYPE(self)->tp_free((PyObject*)self);\n",
      "492     --_outstanding_mallocs[1];\n",
      "493     if (0)\n",
      "494     {\n",
      "495         fprintf(stderr, \"device_malloc_counts: (device) %i (obj) %i\\n\",\n",
      "496                 _outstanding_mallocs[0],\n",
      "497                 _outstanding_mallocs[1]);\n",
      "498     }\n",
      "499 }\n",
      "500 \n",
      "501 static PyObject *\n",
      "502 CudaNdarray_new(PyTypeObject *type, PyObject *args, PyObject *kwds)\n",
      "503 {\n",
      "504     CudaNdarray *self;\n",
      "505 \n",
      "506     self = (CudaNdarray *)type->tp_alloc(type, 0);\n",
      "507     if (self != NULL)\n",
      "508     {\n",
      "509         CudaNdarray_null_init(self);\n",
      "510         ++_outstanding_mallocs[1];\n",
      "511     }\n",
      "512     return (PyObject *)self;\n",
      "513 }\n",
      "514 static int\n",
      "515 CudaNdarray_init(CudaNdarray *self, PyObject *args, PyObject *kwds)\n",
      "516 {\n",
      "517     PyObject *arr=NULL;\n",
      "518 \n",
      "519     if (! PyArg_ParseTuple(args, \"O\", &arr))\n",
      "520         return -1;\n",
      "521     if (! PyArray_Check(arr))\n",
      "522     {\n",
      "523         PyErr_SetString(PyExc_TypeError, \"PyArray arg required\");\n",
      "524         return -1;\n",
      "525     }\n",
      "526     int rval = CudaNdarray_CopyFromArray(self, (PyArrayObject*)arr);\n",
      "527     return rval;\n",
      "528 }\n",
      "529 static PyMemberDef CudaNdarray_members[] =\n",
      "530 {\n",
      "531     /*\n",
      "532     {\"first\", T_OBJECT_EX, offsetof(CudaNdarray, first), 0,\n",
      "533      \"first name\"},\n",
      "534     {\"last\", T_OBJECT_EX, offsetof(CudaNdarray, last), 0,\n",
      "535      \"last name\"},\n",
      "536     {\"number\", T_INT, offsetof(CudaNdarray, number), 0,\n",
      "537      \"noddy number\"},\n",
      "538      */\n",
      "539     {NULL}  /* Sentinel */\n",
      "540 };\n",
      "541 \n",
      "542 PyObject * CudaNdarray_CreateArrayObj(CudaNdarray * self, PyObject *args)\n",
      "543 {\n",
      "544     PyObject * dtype = NULL;\n",
      "545     if (args && !PyArg_ParseTuple(args, \"|O\", &dtype))\n",
      "546         return NULL;\n",
      "547     if (dtype) {\n",
      "548         PyArray_Descr* dtype2;\n",
      "549         // PyArray_DescrConverter try to convert anything to a PyArray_Descr.\n",
      "550         if(!PyArray_DescrConverter(dtype, &dtype2))\n",
      "551         {\n",
      "552             PyObject * str = PyObject_Repr(dtype);\n",
      "553             PyErr_Format(PyExc_TypeError,\n",
      "554                          \"CudaNdarray dtype parameter not understood: %s\",\n",
      "555                          PyString_AsString(str)\n",
      "556                          );\n",
      "557             Py_CLEAR(str);\n",
      "558             return NULL;\n",
      "559         }\n",
      "560         int typeNum = dtype2->type_num;\n",
      "561         Py_DECREF(dtype2);\n",
      "562         if (typeNum != NPY_FLOAT32)\n",
      "563         {\n",
      "564             PyObject * str = PyObject_Repr(dtype);\n",
      "565             PyErr_Format(PyExc_TypeError,\n",
      "566                          \"CudaNdarray support only support float32 dtype, provided: %d\",\n",
      "567                          typeNum\n",
      "568                          );\n",
      "569             Py_CLEAR(str);\n",
      "570             return NULL;\n",
      "571         }\n",
      "572     }\n",
      "573 \n",
      "574     int verbose = 0;\n",
      "575     if(self->nd>=0 && CudaNdarray_SIZE(self)==0){\n",
      "576         npy_intp * npydims = (npy_intp*)malloc(self->nd * sizeof(npy_intp));\n",
      "577         assert (npydims);\n",
      "578         for (int i = 0; i < self->nd; ++i) npydims[i] = (npy_intp)(CudaNdarray_HOST_DIMS(self)[i]);\n",
      "579         PyObject * rval = PyArray_SimpleNew(self->nd, npydims, REAL_TYPENUM);\n",
      "580         free(npydims);\n",
      "581         if (!rval){\n",
      "582             return NULL;\n",
      "583         }\n",
      "584         assert (PyArray_ITEMSIZE((PyArrayObject *)rval) == sizeof(real));\n",
      "585         return rval;\n",
      "586     }\n",
      "587     if ((self->nd < 0) || (self->devdata == 0))\n",
      "588     {\n",
      "589         PyErr_SetString(PyExc_ValueError, \"can't copy from un-initialized CudaNdarray\");\n",
      "590         return NULL;\n",
      "591     }\n",
      "592     CudaNdarray * contiguous_self = NULL;\n",
      "593     if (CudaNdarray_is_c_contiguous(self))\n",
      "594     {\n",
      "595         contiguous_self = self;\n",
      "596         Py_INCREF(contiguous_self);\n",
      "597         if (verbose) std::cerr << \"CreateArrayObj already contiguous\" << contiguous_self << '\\n';\n",
      "598     }\n",
      "599     else\n",
      "600     {\n",
      "601         contiguous_self = (CudaNdarray*)CudaNdarray_Copy(self);\n",
      "602         if (verbose) std::cerr << \"CreateArrayObj created contiguous\" << contiguous_self << '\\n';\n",
      "603     }\n",
      "604     if (!contiguous_self)\n",
      "605     {\n",
      "606         return NULL;\n",
      "607     }\n",
      "608 \n",
      "609     npy_intp * npydims = (npy_intp*)malloc(self->nd * sizeof(npy_intp));\n",
      "610     assert (npydims);\n",
      "611     for (int i = 0; i < self->nd; ++i)\n",
      "612         npydims[i] = (npy_intp)(CudaNdarray_HOST_DIMS(self)[i]);\n",
      "613     PyArrayObject * rval = (PyArrayObject *) PyArray_SimpleNew(self->nd,\n",
      "614                                                                npydims,\n",
      "615                                                                REAL_TYPENUM);\n",
      "616     free(npydims);\n",
      "617     if (!rval)\n",
      "618     {\n",
      "619         Py_DECREF(contiguous_self);\n",
      "620         return NULL;\n",
      "621     }\n",
      "622 \n",
      "623     assert (PyArray_ITEMSIZE(rval) == sizeof(real));\n",
      "624 \n",
      "625     npy_intp rval_size = PyArray_SIZE(rval);\n",
      "626     void *rval_data = PyArray_DATA(rval);\n",
      "627     cudaError_t err;\n",
      "628     CNDA_BEGIN_ALLOW_THREADS;\n",
      "629 \n",
      "630     err = cudaMemcpy(rval_data, contiguous_self->devdata,\n",
      "631                      rval_size * sizeof(real),\n",
      "632                      cudaMemcpyDeviceToHost\n",
      "633                      );\n",
      "634     //CNDA_THREAD_SYNC;  // unneeded because cudaMemcpy is blocking anyway\n",
      "635     CNDA_END_ALLOW_THREADS;\n",
      "636 \n",
      "637     if (cudaSuccess != err)\n",
      "638     {\n",
      "639         PyErr_Format(PyExc_RuntimeError, \"error (%s)copying data to host\",\n",
      "640                      cudaGetErrorString(err));\n",
      "641         Py_DECREF(rval);\n",
      "642         rval = NULL;\n",
      "643     }\n",
      "644 \n",
      "645     Py_DECREF(contiguous_self);\n",
      "646     return (PyObject *)rval;\n",
      "647 }\n",
      "648 \n",
      "649 // TODO-- we have two functions here, ZEROS and Zeros.\n",
      "650 // ZEROS is meant to be called just from C code (you don't need to pass it PyObject * s)\n",
      "651 // but this naming is very weird, makes it look like a macro\n",
      "652 // we should figure out the correct convention and change to that\n",
      "653 PyObject* CudaNdarray_ZEROS(int n, int * dims)\n",
      "654 {\n",
      "655 \n",
      "656     size_t total_elements = 1;\n",
      "657 \n",
      "658     for(size_t i=0;i<n;i++){\n",
      "659         // Detect overflow on unsigned integer\n",
      "660         if (dims[i] != 0 && total_elements > (SIZE_MAX / dims[i])) {\n",
      "661             PyErr_Format(PyExc_RuntimeError,\n",
      "662                          \"Can't store in size_t for the bytes requested %llu * %llu\",\n",
      "663                          (unsigned long long)total_elements,\n",
      "664                          (unsigned long long)dims[i]);\n",
      "665             return NULL;\n",
      "666         }\n",
      "667         total_elements*=dims[i];\n",
      "668     }\n",
      "669 \n",
      "670     // total_elements now contains the size of the array, in reals\n",
      "671     if (total_elements > (SIZE_MAX / sizeof(real))){\n",
      "672         PyErr_Format(PyExc_RuntimeError,\n",
      "673                      \"Can't store in size_t for the bytes requested %llu * 4\",\n",
      "674                      (unsigned long long)total_elements);\n",
      "675         return NULL;\n",
      "676     }\n",
      "677     size_t total_size = total_elements * sizeof(real);\n",
      "678 \n",
      "679     CudaNdarray* rval = (CudaNdarray*)CudaNdarray_New();\n",
      "680     if (!rval)\n",
      "681     {\n",
      "682         PyErr_SetString(PyExc_RuntimeError, \"CudaNdarray_ZEROS: call to New failed\");\n",
      "683         return NULL;\n",
      "684     }\n",
      "685 \n",
      "686     if (CudaNdarray_alloc_contiguous(rval, n, dims))\n",
      "687     {\n",
      "688         PyErr_SetString(PyExc_RuntimeError, \"CudaNdarray_ZEROS: allocation failed.\");\n",
      "689         Py_DECREF(rval);\n",
      "690         return NULL;\n",
      "691     }\n",
      "692 \n",
      "693     // Fill with zeros\n",
      "694     //fprintf(stdout, \"Sizeof: %d\\n\", total_size);\n",
      "695     if (cudaSuccess != cudaMemset(rval->devdata, 0, total_size))\n",
      "696     {\n",
      "697         PyErr_Format(PyExc_MemoryError,\n",
      "698                      \"CudaNdarray_ZEROS: Error memsetting %llu bytes of device memory.\",\n",
      "699                      (unsigned long long)total_size);\n",
      "700         Py_DECREF(rval);\n",
      "701         return NULL;\n",
      "702     }\n",
      "703 \n",
      "704     if (cnda_copy_structure_to_device(rval))\n",
      "705     {\n",
      "706         PyErr_SetString(PyExc_RuntimeError, \"CudaNdarray_ZEROS: syncing structure to device failed\");\n",
      "707         Py_DECREF(rval);\n",
      "708         return NULL;\n",
      "709     }\n",
      "710     return (PyObject*) rval;\n",
      "711 }\n",
      "712 \n",
      "713 // declared as a static method (hence 1st parameter is not used)\n",
      "714 // Based on _Copy and _dimshuffle\n",
      "715 PyObject* CudaNdarray_Zeros(PyObject* _unused, PyObject* shape)\n",
      "716 {\n",
      "717     if(!shape)\n",
      "718     {\n",
      "719         PyErr_SetString(PyExc_TypeError, \"CudaNdarray_Zeros: function takes at least 1 argument (0 given)\");\n",
      "720         return NULL;\n",
      "721     }\n",
      "722     if(!PySequence_Check(shape))\n",
      "723     {\n",
      "724         PyErr_SetString(PyExc_TypeError, \"shape argument must be a sequence\");\n",
      "725         return NULL;\n",
      "726     }\n",
      "727 \n",
      "728     int shplen = PySequence_Length(shape);\n",
      "729 \n",
      "730     if (shplen == 0)\n",
      "731     {\n",
      "732         return CudaNdarray_ZEROS(0, NULL);\n",
      "733     }\n",
      "734 \n",
      "735     int* newdims = (int *)malloc(sizeof(int) * shplen);\n",
      "736 \n",
      "737     if (!newdims)\n",
      "738     {\n",
      "739         PyErr_SetString(PyExc_MemoryError,\n",
      "740             \"CudaNdarray_Zeros: Failed to allocate temporary space\");\n",
      "741         return NULL;\n",
      "742     }\n",
      "743 \n",
      "744     // start from the end to compute strides\n",
      "745     for (int i = shplen-1; i >= 0; --i)\n",
      "746     {\n",
      "747         PyObject* shp_el_obj = PySequence_GetItem(shape, i);\n",
      "748         if(shp_el_obj == NULL)\n",
      "749         {\n",
      "750             // shouldn't happen since we checked length before...\n",
      "751             PyErr_SetString(PyExc_RuntimeError, \"CudaNdarray_Zeros: Index out of bound in sequence\");\n",
      "752             free(newdims);\n",
      "753             return NULL;\n",
      "754         }\n",
      "755 \n",
      "756         int shp_el = PyInt_AsLong(shp_el_obj);\n",
      "757         Py_DECREF(shp_el_obj);\n",
      "758 \n",
      "759         if (shp_el < 0)\n",
      "760         {\n",
      "761             PyErr_SetString(PyExc_ValueError, \"CudaNdarray_Zeros: shape must contain only non-negative values for size of a dimension\");\n",
      "762             free(newdims);\n",
      "763             return NULL;\n",
      "764         }\n",
      "765 \n",
      "766         newdims[i] = shp_el;\n",
      "767     }\n",
      "768 \n",
      "769     PyObject* rval = CudaNdarray_ZEROS(shplen,newdims);\n",
      "770 \n",
      "771     free(newdims);\n",
      "772 \n",
      "773     return (PyObject*)rval;\n",
      "774 }\n",
      "775 \n",
      "776 \n",
      "777 \n",
      "778 \n",
      "779 \n",
      "780 PyObject * CudaNdarray_Copy(const CudaNdarray * self)\n",
      "781 {\n",
      "782     PyObject * rval = CudaNdarray_New();\n",
      "783     if ((!rval) || (-1 == self->nd))\n",
      "784     {\n",
      "785         return rval;\n",
      "786     }\n",
      "787     if (CudaNdarray_alloc_contiguous((CudaNdarray*)rval, self->nd, CudaNdarray_HOST_DIMS(self)))\n",
      "788     {\n",
      "789         Py_DECREF(rval);\n",
      "790         return NULL;\n",
      "791     }\n",
      "792     if (CudaNdarray_CopyFromCudaNdarray((CudaNdarray*)rval, self))\n",
      "793     {\n",
      "794         Py_DECREF(rval);\n",
      "795         return NULL;\n",
      "796     }\n",
      "797     return rval;\n",
      "798 }\n",
      "799 PyObject * CudaNdarray_DeepCopy(CudaNdarray * self, PyObject * memo)\n",
      "800 {\n",
      "801     assert(PyDict_Check(memo));\n",
      "802     PyObject * selfkey = PyInt_FromLong((long)self);\n",
      "803     assert(selfkey);\n",
      "804     if (PyDict_Contains(memo, selfkey))\n",
      "805     {\n",
      "806         PyObject * rval = PyDict_GetItem(memo, selfkey);\n",
      "807         Py_DECREF(selfkey);\n",
      "808         Py_XINCREF(rval);\n",
      "809         return rval;\n",
      "810     }\n",
      "811     else\n",
      "812     {\n",
      "813         PyObject * rval = CudaNdarray_Copy(self);\n",
      "814         if (0) std::cerr << \"DeepCopy created \" << rval << \" devdata \" << ((CudaNdarray*)rval)->devdata << \"\\n\";\n",
      "815         if (NULL == rval)\n",
      "816         {\n",
      "817             Py_DECREF(selfkey);\n",
      "818             return NULL;\n",
      "819         }\n",
      "820         if (PyDict_SetItem(memo, selfkey, rval))\n",
      "821         {\n",
      "822             Py_DECREF(rval);\n",
      "823             Py_DECREF(selfkey);\n",
      "824             return NULL;\n",
      "825         }\n",
      "826         Py_DECREF(selfkey);\n",
      "827         return rval;\n",
      "828     }\n",
      "829 }\n",
      "830 PyObject * CudaNdarray_ReduceSum(CudaNdarray * self, PyObject * py_reduce_mask)\n",
      "831 {\n",
      "832     if (!PySequence_Check(py_reduce_mask))\n",
      "833     {\n",
      "834         PyErr_SetString(PyExc_TypeError, \"reduce_mask must be sequence of ints\");\n",
      "835         return NULL;\n",
      "836     }\n",
      "837     int len = PySequence_Length(py_reduce_mask);\n",
      "838     if (len != self->nd)\n",
      "839     {\n",
      "840         PyErr_SetString(PyExc_TypeError, \"length of reduce_mask must match self->nd\");\n",
      "841         return NULL;\n",
      "842     }\n",
      "843     CudaNdarray * self_sum = (CudaNdarray*)CudaNdarray_New();\n",
      "844     if (!self_sum)\n",
      "845     {\n",
      "846         return NULL;\n",
      "847     }\n",
      "848     //TODO: allocate a fixed size dimshuffle_pattern_cache on the stack,\n",
      "849     //      and use it if it is big enough.\n",
      "850     int * dimshuffle_pattern = (int*)malloc(len * 2 * sizeof(int));\n",
      "851     int * sum_dims = dimshuffle_pattern + len;\n",
      "852     int n_remaining_dims = 0;\n",
      "853     if (!dimshuffle_pattern)\n",
      "854     {\n",
      "855         Py_DECREF(self_sum);\n",
      "856         PyErr_SetString(PyExc_MemoryError, \"failed to alloc internal storage\");\n",
      "857         return NULL;\n",
      "858     }\n",
      "859     for (int i = 0; i < len; ++i)\n",
      "860     {\n",
      "861         PyObject *o_i = PySequence_GetItem(py_reduce_mask, i);\n",
      "862         int o_i_int = PyInt_AsLong(o_i);\n",
      "863         Py_XDECREF(o_i);\n",
      "864         if (PyErr_Occurred())\n",
      "865         {\n",
      "866             Py_DECREF(self_sum);\n",
      "867             free(dimshuffle_pattern);\n",
      "868             return NULL;\n",
      "869         }\n",
      "870         if (o_i_int) // this is a dimension over which we are reducing\n",
      "871         {\n",
      "872             sum_dims[i] = 1;\n",
      "873         }\n",
      "874         else\n",
      "875         {\n",
      "876             sum_dims[i] = CudaNdarray_HOST_DIMS(self)[i];\n",
      "877             dimshuffle_pattern[n_remaining_dims++] = i;\n",
      "878         }\n",
      "879     }\n",
      "880     if (0   || CudaNdarray_alloc_contiguous(self_sum, len, sum_dims)\n",
      "881             || CudaNdarray_reduce_sum(self_sum, self)\n",
      "882             || CudaNdarray_dimshuffle(self_sum, n_remaining_dims, dimshuffle_pattern))\n",
      "883     {\n",
      "884         Py_DECREF(self_sum);\n",
      "885         free(dimshuffle_pattern);\n",
      "886         return NULL;\n",
      "887     }\n",
      "888     free(dimshuffle_pattern);\n",
      "889     return (PyObject*)self_sum;\n",
      "890 }\n",
      "891 \n",
      "892 // Reshape self to the new shape gived by the tuple shape.\n",
      "893 //\n",
      "894 // If self is c contiguous, it return a view. Otherwise it always do a copy.\n",
      "895 // TODO: make it return a view when the strides allow it even if it is not\n",
      "896 //       c contiguous\n",
      "897 PyObject * CudaNdarray_Reshape(CudaNdarray * self, PyObject * shape)\n",
      "898 {\n",
      "899     if(!CudaNdarray_is_c_contiguous(self))\n",
      "900     {\n",
      "901         // allocate new space\n",
      "902         //TODO: test to see if we can re-use old one and take a new param to\n",
      "903         //  use this\n",
      "904         CudaNdarray* rval = (CudaNdarray*) CudaNdarray_Copy(self);\n",
      "905         if (!rval)\n",
      "906         {\n",
      "907             return NULL;\n",
      "908         }\n",
      "909 \n",
      "910         CudaNdarray* ret = (CudaNdarray*) CudaNdarray_Reshape(rval, shape);\n",
      "911         Py_XDECREF(rval);\n",
      "912         return (PyObject*)ret;\n",
      "913     }\n",
      "914 \n",
      "915     // check shape tuple\n",
      "916     unsigned int rval_nd;\n",
      "917     unsigned int * rval_dims;\n",
      "918     size_t rval_size = 1;\n",
      "919 \n",
      "920     if (PyTuple_Check(shape)){\n",
      "921         // copy shape to integer array\n",
      "922         rval_nd = PyTuple_Size(shape);\n",
      "923     }else if (PyInt_Check(shape)){\n",
      "924         rval_nd = 1;\n",
      "925     }else{\n",
      "926         PyErr_SetString(PyExc_TypeError, \"shape must be tuple of integers or an integer\");\n",
      "927         return NULL;\n",
      "928     }\n",
      "929     rval_dims = (unsigned int*)malloc(rval_nd * sizeof(int));\n",
      "930 \n",
      "931     if(PyTuple_Check(shape)){\n",
      "932         for (int i = 0; i < rval_nd; ++i)\n",
      "933         {\n",
      "934             rval_dims[i] = PyInt_AsLong(PyTuple_GetItem(shape, i)); //GetItem returns borrowed reference\n",
      "935             if (PyErr_Occurred()) //error in AsLong\n",
      "936             {\n",
      "937                 free(rval_dims);\n",
      "938                 return NULL;\n",
      "939             }\n",
      "940             if(rval_dims[i]<0){\n",
      "941                 PyErr_Format(PyExc_ValueError, \"Reshape has invalid dimension %i (must be >=0)\",rval_dims[i]);\n",
      "942                 free(rval_dims);\n",
      "943                 return NULL;\n",
      "944             }\n",
      "945             rval_size = rval_size * rval_dims[i];\n",
      "946         }\n",
      "947     }else{\n",
      "948         rval_size = PyInt_AsLong(shape);\n",
      "949         rval_dims[0] = rval_size;\n",
      "950     }\n",
      "951     // calculate new size, assert same as old size\n",
      "952     if (rval_size != CudaNdarray_SIZE(self))\n",
      "953     {\n",
      "954         PyErr_Format(PyExc_ValueError, \"size must remain unchanged, changed from %lld to %lld\", CudaNdarray_SIZE(self), rval_size);\n",
      "955         free(rval_dims);\n",
      "956         return NULL;\n",
      "957     }\n",
      "958     if (rval_size==0)\n",
      "959     {\n",
      "960         PyObject * rval = CudaNdarray_NewDims(rval_nd, rval_dims);\n",
      "961         free(rval_dims);\n",
      "962         return rval;\n",
      "963     }\n",
      "964 \n",
      "965     //return a view, not a copy\n",
      "966     //we can do this as we checked self is c_contiguous\n",
      "967     CudaNdarray * rval = (CudaNdarray * )CudaNdarray_New(rval_nd);\n",
      "968 \n",
      "969     if (!rval || 0 != rval->data_allocated\n",
      "970         ||CudaNdarray_set_device_data(rval, CudaNdarray_DEV_DATA(self), self))\n",
      "971     {\n",
      "972         Py_XDECREF(rval);\n",
      "973         free(rval_dims);\n",
      "974         return NULL;\n",
      "975     }\n",
      "976     //set dim and stride\n",
      "977     int size = 1;\n",
      "978     for (int i = rval_nd-1; i >= 0; --i)\n",
      "979     {\n",
      "980         CudaNdarray_set_stride(rval, i, (rval_dims[i] == 1) ? 0 : size);\n",
      "981         CudaNdarray_set_dim(rval, i, rval_dims[i]);\n",
      "982         size = size * rval_dims[i];\n",
      "983     }\n",
      "984     free(rval_dims);\n",
      "985     return (PyObject*)rval;\n",
      "986 }\n",
      "987 \n",
      "988 PyObject * CudaNdarray_View(const CudaNdarray * self)\n",
      "989 {\n",
      "990     CudaNdarray * rval = (CudaNdarray*)CudaNdarray_New(self->nd);\n",
      "991     if (!rval || CudaNdarray_set_device_data(rval, CudaNdarray_DEV_DATA(self), self))\n",
      "992     {\n",
      "993         Py_XDECREF(rval);\n",
      "994         rval = NULL;\n",
      "995     }\n",
      "996     else\n",
      "997     {\n",
      "998         for (int i = 0; i < self->nd; ++i)\n",
      "999         {\n",
      "1000             CudaNdarray_set_dim(rval, i, CudaNdarray_HOST_DIMS(self)[i]);\n",
      "1001             CudaNdarray_set_stride(rval, i, CudaNdarray_HOST_STRIDES(self)[i]);\n",
      "1002         }\n",
      "1003     }\n",
      "1004     return (PyObject*)rval;\n",
      "1005 }\n",
      "1006 \n",
      "1007 /*\n",
      "1008  * d0,... are the output dims\n",
      "1009  * indices are a list of index to operate on\n",
      "1010  *         They are int32 viewed as float32.\n",
      "1011  * a is the output\n",
      "1012  * b is the input\n",
      "1013  * dB0, the source leading dimensions size\n",
      "1014  */\n",
      "1015 template <int operator_num>\n",
      "1016 __global__ void k_take_3(const int d0, const int d1, const int d2,\n",
      "1017                          const npy_int64* indices,\n",
      "1018                          float* a,\n",
      "1019                          const int sA0, const int sA1, const int sA2,\n",
      "1020                          const float* b, const int dB0,\n",
      "1021                          const int sB0, const int sB1, const int sB2,\n",
      "1022                          int* err){\n",
      "1023     for (int i0 = blockIdx.x; i0 < d0; i0 += gridDim.x){\n",
      "1024         npy_int64 idx = indices[i0];\n",
      "1025         if (idx<0)\n",
      "1026             idx += dB0; // To allow negative indexing.\n",
      "1027         if ((idx < 0) || (idx >= dB0)){\n",
      "1028             // Any value other the 0 probably work. But to be more safe, I want\n",
      "1029             // to change all bits to prevent problem with concurrent write that\n",
      "1030             // could cross cache line. But this should not happen with the\n",
      "1031             // current code and driver.\n",
      "1032             *err = 0xFFFF;\n",
      "1033             continue;\n",
      "1034         }\n",
      "1035         for (int i1 = threadIdx.x; i1 < d1; i1 += blockDim.x){\n",
      "1036             for (int i2 = threadIdx.y; i2 < d2; i2 += blockDim.y){\n",
      "1037                 int a_idx = i0*sA0 + i1*sA1 + i2*sA2;\n",
      "1038                 int b_idx = idx*sB0 + i1*sB1 + i2*sB2;\n",
      "1039                 a[a_idx] = b[b_idx];\n",
      "1040             }\n",
      "1041         }\n",
      "1042     }\n",
      "1043 }\n",
      "1044 \n",
      "1045 // We try to be similar to the PyArray_TakeFrom function\n",
      "1046 //http://docs.scipy.org/doc/numpy/reference/c-api.array.html\n",
      "1047 //TODO: support other clip mode then raise(clip, wrap)\n",
      "1048 //self is the input that we copy data from.\n",
      "1049 //The indices that we receive MUST be an CudaNdarray(float32)\n",
      "1050 //    that is in fact a view to int64 indices\n",
      "1051 PyObject*\n",
      "1052 CudaNdarray_TakeFrom(CudaNdarray * self, PyObject *args){\n",
      "1053     int verbose = 0;\n",
      "1054     PyObject * indices_obj = NULL;\n",
      "1055     //int axis; Default None, that mean the flattened array.\n",
      "1056     PyObject * axis_obj = Py_None;\n",
      "1057     PyObject * out_obj = Py_None;\n",
      "1058     PyObject * clipmode_obj = NULL;\n",
      "1059     int max_threads = 1; // max threads per blocks\n",
      "1060 \n",
      "1061     if (! PyArg_ParseTuple(args, \"O|OOOi\", &indices_obj, &axis_obj,\n",
      "1062                            &out_obj, &clipmode_obj, &max_threads))\n",
      "1063         return NULL;\n",
      "1064 \n",
      "1065     //Check argument indices\n",
      "1066     //TODO: if not a numpy.ndarray, convert to numpy.ndarray\n",
      "1067     //TODO: If a CudaNdarray, accept it and suppose the data is int32? is float32 number of int?\n",
      "1068     //TODO: Support ndarray of other dtype then int32\n",
      "1069     //TODO: support list of indices that are not c_contiguous\n",
      "1070     CudaNdarray * indices = NULL;\n",
      "1071     if (CudaNdarray_Check(indices_obj)) {\n",
      "1072         if (verbose) printf(\"cudandarray indices\\n\");\n",
      "1073         indices = (CudaNdarray*) indices_obj;\n",
      "1074         Py_INCREF(indices);\n",
      "1075     } else if (PyArray_Check(indices_obj)) {\n",
      "1076         if (verbose) printf(\"ndarray indices\\n\");\n",
      "1077         if (PyArray_TYPE((PyArrayObject *)indices_obj) != NPY_INT64) {\n",
      "1078             PyErr_SetString(PyExc_TypeError,\n",
      "1079                             \"CudaNdarray_TakeFrom: need a ndarray for indices\"\n",
      "1080                             \" with dtype int64\");\n",
      "1081             return NULL;\n",
      "1082         }\n",
      "1083         if (PyArray_NDIM(((PyArrayObject*)indices_obj)) != 1) {\n",
      "1084             PyErr_SetString(PyExc_TypeError,\n",
      "1085                             \"CudaNdarray_TakeFrom: need a CudaNdarray of\"\n",
      "1086                             \" indices with only 1 dimensions\");\n",
      "1087             return NULL;\n",
      "1088         }\n",
      "1089         // We need indices_obj to be contiguous, in order to take a view\n",
      "1090         // with a different dtype.\n",
      "1091         if (!PyArray_IS_C_CONTIGUOUS((PyArrayObject*) indices_obj)) {\n",
      "1092             PyObject* indices_obj_contig = PyArray_NewCopy((PyArrayObject*) indices_obj, NPY_CORDER);\n",
      "1093             if (!indices_obj_contig)\n",
      "1094                 return NULL;\n",
      "1095             indices_obj = indices_obj_contig;\n",
      "1096         } else {\n",
      "1097             // Keep the refcount consistent\n",
      "1098             Py_INCREF(indices_obj);\n",
      "1099         }\n",
      "1100         PyArray_Descr* float32_descr = PyArray_DescrFromType(NPY_FLOAT32);\n",
      "1101         PyObject * indices_float32 = NULL;\n",
      "1102         indices_float32 = PyArray_View((PyArrayObject*)indices_obj,\n",
      "1103                                                   float32_descr, NULL);\n",
      "1104         if (verbose) printf(\"ndarray indices\\n\");\n",
      "1105         if (!indices_float32) {\n",
      "1106             Py_DECREF(indices_obj);\n",
      "1107             return NULL;\n",
      "1108         }\n",
      "1109 \n",
      "1110         indices = (CudaNdarray*) CudaNdarray_New();\n",
      "1111         if (verbose) printf(\"\\nndarray after new\\n\");\n",
      "1112         if (! indices){\n",
      "1113             Py_DECREF(indices_obj);\n",
      "1114             Py_DECREF(indices_float32);\n",
      "1115             return NULL;\n",
      "1116         }\n",
      "1117         if (CudaNdarray_CopyFromArray(indices,\n",
      "1118                                       (PyArrayObject *)indices_float32)){\n",
      "1119             Py_DECREF(indices_obj);\n",
      "1120             Py_DECREF(indices_float32);\n",
      "1121             return NULL;\n",
      "1122         }\n",
      "1123         Py_DECREF(indices_obj);\n",
      "1124         Py_DECREF(indices_float32);\n",
      "1125     } else {\n",
      "1126         PyObject* py_s = PyObject_Str(indices_obj);\n",
      "1127         const char* s = PyString_AsString(py_s);\n",
      "1128         Py_DECREF(py_s);\n",
      "1129         PyErr_Format(PyExc_TypeError,\n",
      "1130                      \"CudaNdarray_TakeFrom: need an ndarray of int64 or a\"\n",
      "1131                      \" CudaNdarray(float32) that is a view from int64 data\"\n",
      "1132                      \" for indices. Got %s\", s);\n",
      "1133         return NULL;\n",
      "1134     }\n",
      "1135 \n",
      "1136     if (verbose) {\n",
      "1137         printf(\"indices used on the gpu\\n\");\n",
      "1138         fprint_CudaNdarray(stdout, indices);\n",
      "1139         PyObject * used_indices = CudaNdarray_CreateArrayObj(indices);\n",
      "1140         PyObject_Print(used_indices, stdout, 0);\n",
      "1141         Py_DECREF(used_indices);\n",
      "1142     }\n",
      "1143     if (verbose) printf(\"after print of object\\n\");\n",
      "1144     if(!CudaNdarray_is_c_contiguous(indices) != 0) {\n",
      "1145         PyErr_SetString(PyExc_NotImplementedError,\n",
      "1146                         \"CudaNdarray_TakeFrom: The indices must be contiguous in memory.\");\n",
      "1147         Py_DECREF(indices);\n",
      "1148         return NULL;\n",
      "1149     }\n",
      "1150     int nb_indices = CudaNdarray_SIZE((CudaNdarray *)indices) / 2;// int64 are 8 bytes, float32 are 4 bytes\n",
      "1151 \n",
      "1152     //Check argument axis\n",
      "1153     //TODO: implement the default and other axis\n",
      "1154     long axis = PyInt_AsLong(axis_obj);\n",
      "1155 \n",
      "1156     if (axis != 0) {\n",
      "1157         PyErr_Format(PyExc_NotImplementedError,\n",
      "1158                      \"CudaNdarray_TakeFrom: only axis=0 is currently supported.\"\n",
      "1159                      \" Got %ld.\", axis);\n",
      "1160         Py_DECREF(indices);\n",
      "1161         return NULL;\n",
      "1162     }\n",
      "1163 \n",
      "1164     //Check argument out_obj\n",
      "1165     CudaNdarray * out = NULL;\n",
      "1166     if (out_obj && CudaNdarray_Check(out_obj))\n",
      "1167         out = (CudaNdarray*) out_obj;\n",
      "1168     if (out && (out->nd != self->nd ||\n",
      "1169                 CudaNdarray_HOST_DIMS(out)[0] != nb_indices))\n",
      "1170         out = NULL;\n",
      "1171     int * dims = (int *)malloc(sizeof(int) * self->nd);\n",
      "1172     dims[0] = nb_indices;\n",
      "1173 \n",
      "1174     for (int i=1 ; i<self->nd ; i++) {\n",
      "1175         dims[i] = CudaNdarray_HOST_DIMS(self)[i];\n",
      "1176         if (out && CudaNdarray_HOST_DIMS(out)[i] != dims[i]) {\n",
      "1177             out = NULL;\n",
      "1178         }\n",
      "1179     }\n",
      "1180     if (!out) {\n",
      "1181         out = (CudaNdarray*)CudaNdarray_New();\n",
      "1182         if (!out){\n",
      "1183             Py_DECREF(indices);\n",
      "1184             free(dims);\n",
      "1185             return NULL;\n",
      "1186         }\n",
      "1187         if (CudaNdarray_alloc_contiguous(out, self->nd, dims)) {\n",
      "1188             Py_DECREF(out);\n",
      "1189             Py_DECREF(indices);\n",
      "1190             free(dims);\n",
      "1191             return NULL;\n",
      "1192         }\n",
      "1193     }else {\n",
      "1194         Py_INCREF(out);\n",
      "1195     }\n",
      "1196 \n",
      "1197     //Check argument clipmode\n",
      "1198     if (clipmode_obj) {\n",
      "1199         char * clipmode = PyString_AsString(clipmode_obj);\n",
      "1200         if (! clipmode){\n",
      "1201             Py_DECREF(indices);\n",
      "1202             Py_DECREF(out);\n",
      "1203             free(dims);\n",
      "1204             return NULL;\n",
      "1205         }\n",
      "1206         if (strcmp(clipmode, \"raise\") != 0) {\n",
      "1207             PyErr_Format(PyExc_NotImplementedError,\n",
      "1208                          \"CudaNdarray_TakeFrom: only the raise mode is currently supported. Got '%s'\",\n",
      "1209                          clipmode);\n",
      "1210             Py_DECREF(indices);\n",
      "1211             Py_DECREF(out);\n",
      "1212             free(dims);\n",
      "1213             return NULL;\n",
      "1214         }\n",
      "1215     }\n",
      "1216     void (*k3)(const int, const int, const int,\n",
      "1217                const npy_int64*,\n",
      "1218                float*, const int, const int, const int,\n",
      "1219                const float*, const int,\n",
      "1220                const int, const int, const int,\n",
      "1221                int*);\n",
      "1222     k3 = k_take_3<CPY>;\n",
      "1223 \n",
      "1224     // Create the memory place that will store the error information.\n",
      "1225     if(init_err_var() != 0) return NULL;\n",
      "1226 \n",
      "1227     dim3 n_blocks(std::min(CudaNdarray_HOST_DIMS(out)[0],65535),1,1);\n",
      "1228     if(CudaNdarray_HOST_DIMS(out)[0] == 0){\n",
      "1229         // We take 0 elements, so no need for the rest of the code.\n",
      "1230         // This speed up that case AND fix crash otherwise.\n",
      "1231         free(dims);\n",
      "1232         Py_DECREF(indices);\n",
      "1233         return (PyObject *)out;\n",
      "1234     }\n",
      "1235 \n",
      "1236     switch (self->nd) {\n",
      "1237         case 1:\n",
      "1238             {\n",
      "1239                 dim3 n_threads(1, 1, 1);\n",
      "1240                 if (verbose)\n",
      "1241                     printf(\"cudaGetLastError=%d, nd=%d\"\n",
      "1242                            \" kernel config: (n_blocks.x=%d, n_blocks.y=%d,\"\n",
      "1243                            \" n_threads.x=%i, n_threads.y=%i)\\n\",\n",
      "1244                            cudaGetLastError(), self->nd,\n",
      "1245                            n_blocks.x, n_blocks.y, n_threads.x, n_threads.y);\n",
      "1246                 k3<<<n_blocks, n_threads>>>(\n",
      "1247                         dims[0],\n",
      "1248                         1,\n",
      "1249                         1,\n",
      "1250                         (npy_int64*) CudaNdarray_DEV_DATA(indices),\n",
      "1251                         CudaNdarray_DEV_DATA(out),\n",
      "1252                         CudaNdarray_HOST_STRIDES(out)[0], //strides\n",
      "1253                         1,\n",
      "1254                         1,\n",
      "1255                         CudaNdarray_DEV_DATA(self),\n",
      "1256                         CudaNdarray_HOST_DIMS(self)[0], //For indices check\n",
      "1257                         CudaNdarray_HOST_STRIDES(self)[0], //strides\n",
      "1258                         1,\n",
      "1259                         1,\n",
      "1260                         err_var);\n",
      "1261             }\n",
      "1262             break;\n",
      "1263         case 2:\n",
      "1264             {\n",
      "1265                 dim3 n_threads(std::min(CudaNdarray_HOST_DIMS(out)[1], max_threads), 1, 1);\n",
      "1266 \n",
      "1267                 if (verbose)\n",
      "1268                     printf(\"cudaGetLastError=%d, nd=%d\"\n",
      "1269                            \" kernel config: (n_blocks.x=%d, n_blocks.y=%d,\"\n",
      "1270                            \" n_threads.x=%i, n_threads.y=%i)\\n\",\n",
      "1271                            cudaGetLastError(), self->nd,\n",
      "1272                            n_blocks.x, n_blocks.y, n_threads.x, n_threads.y);\n",
      "1273 \n",
      "1274                 k3<<<n_blocks, n_threads>>>(\n",
      "1275                         dims[0], //dimensions\n",
      "1276                         dims[1],\n",
      "1277                         1,\n",
      "1278                         (npy_int64*) CudaNdarray_DEV_DATA(indices),\n",
      "1279                         CudaNdarray_DEV_DATA(out),\n",
      "1280                         CudaNdarray_HOST_STRIDES(out)[0], //strides\n",
      "1281                         CudaNdarray_HOST_STRIDES(out)[1],\n",
      "1282                         1,\n",
      "1283                         CudaNdarray_DEV_DATA(self),\n",
      "1284                         CudaNdarray_HOST_DIMS(self)[0], //For indices check\n",
      "1285                         CudaNdarray_HOST_STRIDES(self)[0], //strides\n",
      "1286                         CudaNdarray_HOST_STRIDES(self)[1],\n",
      "1287                         1,\n",
      "1288                         err_var);\n",
      "1289             }\n",
      "1290             break;\n",
      "1291         case 3:\n",
      "1292             {\n",
      "1293                 int ty = std::min(CudaNdarray_HOST_DIMS(out)[2], max_threads);\n",
      "1294                 int tx = std::min(CudaNdarray_HOST_DIMS(out)[1], max_threads / ty);\n",
      "1295                 dim3 n_threads(tx, ty, 1);\n",
      "1296                 if (verbose)\n",
      "1297                     printf(\"cudaGetLastError=%d, nd=%d\"\n",
      "1298                            \" kernel config: (n_blocks.x=%d, n_blocks.y=%d,\"\n",
      "1299                            \" n_threads.x=%i, n_threads.y=%i)\\n\",\n",
      "1300                            cudaGetLastError(), self->nd,\n",
      "1301                            n_blocks.x, n_blocks.y, n_threads.x, n_threads.y);\n",
      "1302                 k3<<<n_blocks, n_threads>>>(\n",
      "1303                         dims[0], //dimensions\n",
      "1304                         dims[1],\n",
      "1305                         dims[2],\n",
      "1306                         (npy_int64*) CudaNdarray_DEV_DATA(indices),\n",
      "1307                         CudaNdarray_DEV_DATA(out),\n",
      "1308                         CudaNdarray_HOST_STRIDES(out)[0], //strides\n",
      "1309                         CudaNdarray_HOST_STRIDES(out)[1],\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1310                         CudaNdarray_HOST_STRIDES(out)[2],\n",
      "1311                         CudaNdarray_DEV_DATA(self),\n",
      "1312                         CudaNdarray_HOST_DIMS(self)[0], //For indices check\n",
      "1313                         CudaNdarray_HOST_STRIDES(self)[0], //strides\n",
      "1314                         CudaNdarray_HOST_STRIDES(self)[1],\n",
      "1315                         CudaNdarray_HOST_STRIDES(self)[2],\n",
      "1316                         err_var);\n",
      "1317             }\n",
      "1318             break;\n",
      "1319     default:\n",
      "1320         PyErr_SetString(PyExc_NotImplementedError,\n",
      "1321                         \"CudaNdarray_TakeFrom: only input with 1, 2 or 3\"\n",
      "1322                         \" dimensions are currently supported\");\n",
      "1323 \n",
      "1324     }\n",
      "1325     free(dims);\n",
      "1326     CNDA_THREAD_SYNC;\n",
      "1327     cudaError_t err = cudaGetLastError();\n",
      "1328     if (cudaSuccess != err) {\n",
      "1329         PyErr_Format(PyExc_RuntimeError,\n",
      "1330                      \"Cuda error: %s: %s.\\n\",\n",
      "1331                      \"CudaNdarray_TakeFrom\",\n",
      "1332                      cudaGetErrorString(err));\n",
      "1333         Py_DECREF(indices);\n",
      "1334         Py_DECREF(out);\n",
      "1335         return NULL;\n",
      "1336     }\n",
      "1337 \n",
      "1338     int index_err = check_err_var();\n",
      "1339     Py_DECREF(indices);\n",
      "1340     if (index_err != 0) {\n",
      "1341         Py_DECREF(out);\n",
      "1342         return NULL;\n",
      "1343     }\n",
      "1344 \n",
      "1345     if (verbose) printf(\"TAKE SUCCEDED\\n\");\n",
      "1346     return (PyObject *)out;\n",
      "1347 }\n",
      "1348 \n",
      "1349 \n",
      "1350 PyObject * CudaNdarray_SetStride(CudaNdarray * self, PyObject *args)\n",
      "1351 {\n",
      "1352     int pos, stride;\n",
      "1353     if (! PyArg_ParseTuple(args, \"ii\", &pos, &stride))\n",
      "1354         return NULL;\n",
      "1355     if ((pos < 0) || (pos >= self->nd))\n",
      "1356     {\n",
      "1357         PyErr_Format(PyExc_ValueError, \"position argument out of legal range [0, %i)\", self->nd);\n",
      "1358         return NULL;\n",
      "1359     }\n",
      "1360     CudaNdarray_set_stride(self, pos, stride);\n",
      "1361     if (cnda_copy_structure_to_device(self))\n",
      "1362     {\n",
      "1363         return NULL;\n",
      "1364     }\n",
      "1365     Py_INCREF(Py_None);\n",
      "1366     return Py_None;\n",
      "1367 }\n",
      "1368 PyObject * CudaNdarray_SetShapeI(CudaNdarray * self, PyObject *args)\n",
      "1369 {\n",
      "1370     int pos, dim;\n",
      "1371     if (! PyArg_ParseTuple(args, \"ii\", &pos, &dim))\n",
      "1372         return NULL;\n",
      "1373     if ((pos < 0) || (pos >= self->nd))\n",
      "1374     {\n",
      "1375         PyErr_Format(PyExc_ValueError, \"position argument out of legal range [0, %i)\", self->nd);\n",
      "1376         return NULL;\n",
      "1377     }\n",
      "1378     CudaNdarray_set_dim(self, pos, dim);\n",
      "1379     if (cnda_copy_structure_to_device(self))\n",
      "1380     {\n",
      "1381         return NULL;\n",
      "1382     }\n",
      "1383     Py_INCREF(Py_None);\n",
      "1384     return Py_None;\n",
      "1385 }\n",
      "1386 \n",
      "1387 static PyObject *\n",
      "1388 CudaNdarray_exp(CudaNdarray* self)\n",
      "1389 {\n",
      "1390     CudaNdarray * rval = (CudaNdarray *)CudaNdarray_New();\n",
      "1391     if ((NULL == rval) || CudaNdarray_alloc_contiguous(rval, self->nd, CudaNdarray_HOST_DIMS(self)))\n",
      "1392     {\n",
      "1393         Py_XDECREF(rval);\n",
      "1394         return NULL;\n",
      "1395     }\n",
      "1396     unsigned int size = 1;\n",
      "1397     for (int i = 0; i < self->nd; i++)\n",
      "1398     {\n",
      "1399         size *= (unsigned int) CudaNdarray_HOST_DIMS(self)[i];\n",
      "1400     }\n",
      "1401     unsigned int threads_per_block = std::min(size, (unsigned int)NUM_VECTOR_OP_THREADS_PER_BLOCK);\n",
      "1402     unsigned int n_blocks = std::min(ceil_intdiv(size,threads_per_block), (unsigned int)NUM_VECTOR_OP_BLOCKS);\n",
      "1403     k_elemwise_unary_rowmajor_exp<<<n_blocks,threads_per_block>>>(size, self->nd, CudaNdarray_DEV_DIMS(self),\n",
      "1404             CudaNdarray_DEV_DATA(self), CudaNdarray_DEV_STRIDES(self),\n",
      "1405             CudaNdarray_DEV_DATA(rval), CudaNdarray_DEV_STRIDES(rval));\n",
      "1406 \n",
      "1407     //TODO: don't do this right away, do it when we need the result\n",
      "1408     CNDA_THREAD_SYNC;\n",
      "1409     cudaError_t err = cudaGetLastError();\n",
      "1410     if( cudaSuccess != err)\n",
      "1411     {\n",
      "1412         Py_DECREF(rval);\n",
      "1413         PyErr_Format(PyExc_RuntimeError, \"Cuda error: %s: %s.\\n\", \"kExp\", cudaGetErrorString(err));\n",
      "1414         return NULL;\n",
      "1415     }\n",
      "1416 \n",
      "1417     return (PyObject*)rval;\n",
      "1418 }\n",
      "1419 \n",
      "1420 static PyMethodDef CudaNdarray_methods[] =\n",
      "1421 {\n",
      "1422     {\"__array__\",\n",
      "1423         (PyCFunction)CudaNdarray_CreateArrayObj, METH_VARARGS,\n",
      "1424         \"Copy from the device to a numpy ndarray\"},\n",
      "1425     {\"__copy__\",\n",
      "1426         (PyCFunction)CudaNdarray_View, METH_NOARGS,\n",
      "1427         \"Create a shallow copy of this object. used by module copy\"},\n",
      "1428     {\"__deepcopy__\",\n",
      "1429         (PyCFunction)CudaNdarray_DeepCopy, METH_O,\n",
      "1430         \"Create a copy of this object\"},\n",
      "1431     {\"zeros\",\n",
      "1432         (PyCFunction)CudaNdarray_Zeros, METH_STATIC | METH_O,\n",
      "1433         \"Create a new CudaNdarray with specified shape, filled with zeros.\"},\n",
      "1434     {\"copy\",\n",
      "1435         (PyCFunction)CudaNdarray_Copy, METH_NOARGS,\n",
      "1436         \"Create a copy of this object\"},\n",
      "1437     {\"is_c_contiguous\",\n",
      "1438         (PyCFunction)CudaNdarray_IS_C_Contiguous, METH_NOARGS,\n",
      "1439         \"Return True is the object is c contiguous. False otherwise.\"},\n",
      "1440     {\"reduce_sum\",\n",
      "1441         (PyCFunction)CudaNdarray_ReduceSum, METH_O,\n",
      "1442         \"Reduce over the given dimensions by summation\"},\n",
      "1443     {\"exp\",\n",
      "1444         (PyCFunction)CudaNdarray_exp, METH_NOARGS,\n",
      "1445         \"Return the exponential of all elements\"},\n",
      "1446     {\"reshape\",\n",
      "1447         (PyCFunction)CudaNdarray_Reshape, METH_O,\n",
      "1448         \"Return a reshaped view (or copy) of this ndarray\\n\\\n",
      "1449             The required argument is a tuple of integers specifying the shape of the new ndarray.\"},\n",
      "1450     {\"view\",\n",
      "1451         (PyCFunction)CudaNdarray_View, METH_NOARGS,\n",
      "1452         \"Return an alias of this ndarray\"},\n",
      "1453     {\"_set_stride\",\n",
      "1454         (PyCFunction)CudaNdarray_SetStride, METH_VARARGS,\n",
      "1455         \"For integer arguments (i, s), set the 'i'th stride to 's'\"},\n",
      "1456     {\"take\",\n",
      "1457         (PyCFunction)CudaNdarray_TakeFrom, METH_VARARGS,\n",
      "1458         \"Equivalent of numpy.take\"},\n",
      "1459     {\"_set_shape_i\",\n",
      "1460         (PyCFunction)CudaNdarray_SetShapeI, METH_VARARGS,\n",
      "1461         \"For integer arguments (i, s), set the 'i'th shape to 's'\"},\n",
      "1462     {NULL, NULL, NULL, NULL}  /* Sentinel */\n",
      "1463 };\n",
      "1464 \n",
      "1465 \n",
      "1466 ////////////////////\n",
      "1467 // Number protocol\n",
      "1468 ////////////////////\n",
      "1469 \n",
      "1470 __global__ void kAdd_contiguous(float* a, float* b, float* dest, unsigned int numEls) {\n",
      "1471     const unsigned int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
      "1472     const unsigned int numThreads = blockDim.x * gridDim.x;\n",
      "1473 \n",
      "1474     for (unsigned int i = idx; i < numEls; i += numThreads) {\n",
      "1475         dest[i] = a[i] + b[i];\n",
      "1476     }\n",
      "1477 }\n",
      "1478 \n",
      "1479 // Will be called by __add__ in Python\n",
      "1480 static PyObject *\n",
      "1481 CudaNdarray_add(PyObject* py_self, PyObject * py_other)\n",
      "1482 {\n",
      "1483     if (! CudaNdarray_Check(py_self)) {\n",
      "1484         PyErr_SetString(PyExc_TypeError, \"need a CudaNdarray on left\");\n",
      "1485         return NULL;\n",
      "1486     }\n",
      "1487     if (! CudaNdarray_Check(py_other)) {\n",
      "1488         PyErr_SetString(PyExc_TypeError, \"need a CudaNdarray on right\");\n",
      "1489         return NULL;\n",
      "1490     }\n",
      "1491     CudaNdarray * self = (CudaNdarray *)py_self;\n",
      "1492     CudaNdarray * other = (CudaNdarray *)py_other;\n",
      "1493     if(!CudaNdarray_is_c_contiguous(self) || !CudaNdarray_is_c_contiguous(other)){\n",
      "1494         PyErr_SetString(PyExc_TypeError, \"We have implementet only the c_contiguous version for now.\");\n",
      "1495         return NULL;\n",
      "1496     }\n",
      "1497 \n",
      "1498     //standard elemwise size checks\n",
      "1499     if (self->nd != other->nd)\n",
      "1500     {\n",
      "1501         PyErr_SetString(PyExc_TypeError, \"CudaNdarray_add: need same number of dims\");\n",
      "1502         return NULL;\n",
      "1503     }\n",
      "1504     //standard elemwise dim checks\n",
      "1505     unsigned int size = 1;\n",
      "1506     for (int i = 0; i< self->nd; ++i)\n",
      "1507     {\n",
      "1508         if (CudaNdarray_HOST_DIMS(self)[i] != CudaNdarray_HOST_DIMS(other)[i])\n",
      "1509         {\n",
      "1510             PyErr_SetString(PyExc_TypeError, \"need same dimensions\");\n",
      "1511             return NULL;\n",
      "1512         }\n",
      "1513         size *= (unsigned int) CudaNdarray_HOST_DIMS(self)[i];\n",
      "1514     }\n",
      "1515     CudaNdarray * rval = (CudaNdarray *)CudaNdarray_New();\n",
      "1516     if (!rval || CudaNdarray_alloc_contiguous(rval, self->nd, CudaNdarray_HOST_DIMS(self)))\n",
      "1517     {\n",
      "1518         Py_XDECREF(rval);\n",
      "1519         return NULL;\n",
      "1520     }\n",
      "1521 \n",
      "1522     if(CudaNdarray_SIZE((CudaNdarray *)py_self)==0 && CudaNdarray_SIZE((CudaNdarray *)py_other)==0){\n",
      "1523       return (PyObject *) rval;\n",
      "1524     }\n",
      "1525 \n",
      "1526     int threads_per_block = std::min(size, (unsigned int)NUM_VECTOR_OP_THREADS_PER_BLOCK);\n",
      "1527     int n_blocks = std::min(ceil_intdiv(size,(unsigned int)threads_per_block), (unsigned int)NUM_VECTOR_OP_BLOCKS);\n",
      "1528     kAdd_contiguous<<<n_blocks,threads_per_block>>>(\n",
      "1529             self->devdata, other->devdata, rval->devdata, size);\n",
      "1530     CNDA_THREAD_SYNC;\n",
      "1531     cudaError_t err = cudaGetLastError();\n",
      "1532     if( cudaSuccess != err)\n",
      "1533     {\n",
      "1534         PyErr_Format(PyExc_RuntimeError, \"Cuda error: %s: %s.\\n\", \"kAdd\", cudaGetErrorString(err));\n",
      "1535         Py_DECREF(rval);\n",
      "1536         return NULL;\n",
      "1537     }\n",
      "1538     return (PyObject *) rval;\n",
      "1539 }\n",
      "1540 \n",
      "1541 template <int operator_num>\n",
      "1542 __global__ void k_ielem_3(const int d0, const int d1, const int d2,\n",
      "1543         float* a, const int sA0, const int sA1, const int sA2,\n",
      "1544         const float* b, const int sB0, const int sB1, const int sB2){\n",
      "1545     for (int i0 = blockIdx.x; i0 < d0; i0 += gridDim.x){\n",
      "1546         for (int i1 = blockIdx.y; i1 < d1; i1 += gridDim.y){\n",
      "1547             for (int i2 = threadIdx.x; i2 < d2; i2 += blockDim.x){\n",
      "1548                 switch (operator_num)\n",
      "1549                 {\n",
      "1550                   case IADD:\n",
      "1551                     a[i0*sA0 + i1*sA1 + i2*sA2] += b[i0*sB0 + i1*sB1 + i2*sB2];\n",
      "1552                     break;\n",
      "1553                   case IDIV:\n",
      "1554                     a[i0*sA0 + i1*sA1 + i2*sA2] /= b[i0*sB0 + i1*sB1 + i2*sB2];\n",
      "1555                     break;\n",
      "1556                   case CPY:\n",
      "1557                     a[i0*sA0 + i1*sA1 + i2*sA2] = b[i0*sB0 + i1*sB1 + i2*sB2];\n",
      "1558                     break;\n",
      "1559                 }\n",
      "1560             }\n",
      "1561         }\n",
      "1562     }\n",
      "1563 }\n",
      "1564 \n",
      "1565 template <int operator_num>\n",
      "1566 __global__ void k_ielem_4(const int d0, const int d1, const int d2, const int d3,\n",
      "1567                          float* a, const int sA0, const int sA1,\n",
      "1568                          const int sA2, const int sA3,\n",
      "1569                          const float* b, const int sB0, const int sB1,\n",
      "1570                          const int sB2, const int sB3){\n",
      "1571     for (int i0 = blockIdx.x; i0 < d0; i0 += gridDim.x){\n",
      "1572         for (int i1 = blockIdx.y; i1 < d1; i1 += gridDim.y){\n",
      "1573             for (int i2 = threadIdx.x; i2 < d2; i2 += blockDim.x){\n",
      "1574                 for (int i3 = threadIdx.y; i3 < d3; i3 += blockDim.y){\n",
      "1575                     switch (operator_num) {\n",
      "1576                         case IADD:\n",
      "1577                             a[i0*sA0 + i1*sA1 + i2*sA2 + i3*sA3]\n",
      "1578                             += b[i0*sB0 + i1*sB1 + i2*sB2 + i3*sB3];\n",
      "1579                             break;\n",
      "1580                         case IDIV:\n",
      "1581                             a[i0*sA0 + i1*sA1 + i2*sA2 + i3*sA3]\n",
      "1582                             /= b[i0*sB0 + i1*sB1 + i2*sB2 + i3*sB3];\n",
      "1583                             break;\n",
      "1584                         case CPY:\n",
      "1585                             a[i0*sA0 + i1*sA1 + i2*sA2 + i3*sA3]\n",
      "1586                             = b[i0*sB0 + i1*sB1 + i2*sB2 + i3*sB3];\n",
      "1587                             break;\n",
      "1588                     }\n",
      "1589                 }\n",
      "1590             }\n",
      "1591         }\n",
      "1592     }\n",
      "1593 }\n",
      "1594 \n",
      "1595 template <int operator_num>\n",
      "1596 __global__ void k_ielem_6(const int d0, const int d1,\n",
      "1597                           const int d2, const int d3,\n",
      "1598                           const int d4, const int d5,\n",
      "1599                           float* a, const int sA0, const int sA1,\n",
      "1600                           const int sA2, const int sA3,\n",
      "1601                           const int sA4, const int sA5,\n",
      "1602                           const float* b, const int sB0, const int sB1,\n",
      "1603                           const int sB2, const int sB3,\n",
      "1604                           const int sB4, const int sB5\n",
      "1605                           ){\n",
      "1606     for (int i0 = blockIdx.x; i0 < d0; i0 += gridDim.x){\n",
      "1607         for (int i1 = blockIdx.y; i1 < d1; i1 += gridDim.y){\n",
      "1608             for (int i2 = blockIdx.z; i2 < d2; i2 += gridDim.z){\n",
      "1609                 for (int i3 = threadIdx.x; i3 < d3; i3 += blockDim.x){\n",
      "1610                     for (int i4 = threadIdx.y; i4 < d4; i4 += blockDim.y){\n",
      "1611                         for (int i5 = threadIdx.z; i5 < d5; i5 += blockDim.z){\n",
      "1612                             switch (operator_num) {\n",
      "1613                             case IADD:\n",
      "1614                                 a[i0*sA0 + i1*sA1 + i2*sA2 + i3*sA3 + i4*sA4 + i5*sA5]\n",
      "1615                                     += b[i0*sB0 + i1*sB1 + i2*sB2 + i3*sB3 + i4*sB4 + i5*sB5];\n",
      "1616                                 break;\n",
      "1617                             case IDIV:\n",
      "1618                                 a[i0*sA0 + i1*sA1 + i2*sA2 + i3*sA3 + i4*sA4 + i5*sA5]\n",
      "1619                                     /= b[i0*sB0 + i1*sB1 + i2*sB2 + i3*sB3 + i4*sB4 + i5*sB5];\n",
      "1620                                 break;\n",
      "1621                             case CPY:\n",
      "1622                                 a[i0*sA0 + i1*sA1 + i2*sA2 + i3*sA3 + i4*sA4 + i5*sA5]\n",
      "1623                                     = b[i0*sB0 + i1*sB1 + i2*sB2 + i3*sB3 + i4*sB4 + i5*sB5];\n",
      "1624                                 break;\n",
      "1625                             }\n",
      "1626                         }\n",
      "1627                     }\n",
      "1628                 }\n",
      "1629             }\n",
      "1630         }\n",
      "1631     }\n",
      "1632 }\n",
      "1633 \n",
      "1634 /*\n",
      "1635 CudaNdarray_inplace_elemwise\n",
      "1636 Compute elemwise, working inplace on A.\n",
      "1637 Currently implemented A / B, A + B and A = B\n",
      "1638 (the last is not tested and not used!)\n",
      "1639 \n",
      "1640 py_self - the CudaNdarray that we'll modify (A)\n",
      "1641 py_other - the other argument (B)\n",
      "1642 fct_nb - which operation to perform (operator_t)\n",
      "1643 \n",
      "1644 Returns 0 on success.\n",
      "1645 Returns -1 on failure, and sets Python exception.\n",
      "1646 \n",
      "1647 */\n",
      "1648 int\n",
      "1649 CudaNdarray_inplace_elemwise(PyObject* py_self, PyObject * py_other, operator_t fct_nb)\n",
      "1650 {\n",
      "1651     int verbose = 0;\n",
      "1652     void (*k3)(const int, const int, const int,\n",
      "1653                     float*, const int, const int, const int,\n",
      "1654                     const float*, const int, const int, const int);\n",
      "1655     void (*k4)(const int, const int, const int, const int,\n",
      "1656                     float*, const int, const int,\n",
      "1657                     const int, const int,\n",
      "1658                     const float*, const int, const int,\n",
      "1659                     const int, const int);\n",
      "1660     void (*k6)(const int, const int,\n",
      "1661                const int, const int,\n",
      "1662                const int, const int,\n",
      "1663                float*, const int, const int,\n",
      "1664                const int, const int,\n",
      "1665                const int, const int,\n",
      "1666                const float*, const int, const int,\n",
      "1667                const int, const int,\n",
      "1668                const int, const int);\n",
      "1669     switch (fct_nb)\n",
      "1670     {\n",
      "1671         case IADD:\n",
      "1672             k3 = k_ielem_3<IADD>;\n",
      "1673             k4 = k_ielem_4<IADD>;\n",
      "1674             k6 = k_ielem_6<IADD>;\n",
      "1675             break;\n",
      "1676         case IDIV:\n",
      "1677             k3 = k_ielem_3<IDIV>;\n",
      "1678             k4 = k_ielem_4<IDIV>;\n",
      "1679             k6 = k_ielem_6<IDIV>;\n",
      "1680             break;\n",
      "1681         case CPY:\n",
      "1682             k3 = k_ielem_3<CPY>;\n",
      "1683             k4 = k_ielem_4<CPY>;\n",
      "1684             k6 = k_ielem_6<CPY>;\n",
      "1685             break;\n",
      "1686         default:\n",
      "1687             assert (0);\n",
      "1688             PyErr_Format(\n",
      "1689                 PyExc_TypeError,\n",
      "1690                 \"CudaNdarray_inplace_elemwise invalid fct_nb (%i).\",\n",
      "1691                 (int)fct_nb);\n",
      "1692             return -1;\n",
      "1693     }\n",
      "1694     if (!CudaNdarray_Check(py_self)) {\n",
      "1695         PyErr_SetString(\n",
      "1696             PyExc_TypeError,\n",
      "1697             \"CudaNdarray_inplace_elemwise need a CudaNdarray on left\");\n",
      "1698         return -1;\n",
      "1699     }\n",
      "1700     CudaNdarray * new_other = NULL;\n",
      "1701     if (!CudaNdarray_Check(py_other)) {\n",
      "1702         new_other = (CudaNdarray*) CudaNdarray_New();\n",
      "1703         if(!new_other)\n",
      "1704         {\n",
      "1705             return -1;\n",
      "1706         }\n",
      "1707         if(CudaNdarray_CopyFromArray(new_other, (PyArrayObject *) py_other))\n",
      "1708         {\n",
      "1709             Py_XDECREF(new_other);\n",
      "1710             return -1;\n",
      "1711         }\n",
      "1712         py_other = (PyObject *) new_other;\n",
      "1713     }\n",
      "1714 \n",
      "1715     CudaNdarray * self = (CudaNdarray *)py_self;\n",
      "1716     CudaNdarray * other = (CudaNdarray *)py_other;\n",
      "1717 \n",
      "1718     if (verbose)\n",
      "1719     {\n",
      "1720         fprintf(stderr,\n",
      "1721             \"INPLACE ADD/DIV for self->nd=%d other->nd=%d\\n\",\n",
      "1722             self->nd, other->nd);\n",
      "1723     }\n",
      "1724 \n",
      "1725     //standard elemwise nb dim checks\n",
      "1726     if (self->nd < other->nd)\n",
      "1727     {\n",
      "1728         PyErr_Format(\n",
      "1729             PyExc_TypeError,\n",
      "1730             \"CudaNdarray_inplace_elemwise: The destination need more or the\"\n",
      "1731             \" same number of dimensions then the source. Got %d and %d.\",\n",
      "1732             self->nd, other->nd);\n",
      "1733         Py_XDECREF(new_other);\n",
      "1734         return -1;\n",
      "1735     }\n",
      "1736 \n",
      "1737     //broadcast to the same number of dimensions.\n",
      "1738     int* other_dims = (int*) alloca(self->nd * sizeof(int));\n",
      "1739     int* other_strides = (int*) alloca(self->nd * sizeof(int));\n",
      "1740     int added_dims = self->nd - other->nd;\n",
      "1741     // Add the added broadcasted dimensions\n",
      "1742     for (int i = 0; i< added_dims; ++i)\n",
      "1743     {\n",
      "1744         other_dims[i] = 1;\n",
      "1745         other_strides[i] = 0;\n",
      "1746     }\n",
      "1747     // Copy the existing dimensions\n",
      "1748     for (int i = 0; i< other->nd; ++i)\n",
      "1749     {\n",
      "1750         other_dims[i+added_dims] = CudaNdarray_HOST_DIMS(other)[i];\n",
      "1751         other_strides[i+added_dims] = CudaNdarray_HOST_STRIDES(other)[i];\n",
      "1752     }\n",
      "1753 \n",
      "1754     //standard elemwise dim checks\n",
      "1755     unsigned int size = 1;\n",
      "1756     for (int i = 0; i< self->nd; ++i)\n",
      "1757     {\n",
      "1758         if ((CudaNdarray_HOST_DIMS(self)[i] != other_dims[i])\n",
      "1759             && (other_dims[i] != 1))\n",
      "1760         {\n",
      "1761             PyErr_SetString(\n",
      "1762                 PyExc_ValueError,\n",
      "1763                 \"CudaNdarray_inplace_elemwise need same dimensions (or broadcastable dimension)\");\n",
      "1764             Py_XDECREF(new_other);\n",
      "1765             return -1;\n",
      "1766         }\n",
      "1767         // if we're broadcasting other, then make sure it has stride 0\n",
      "1768         assert ((CudaNdarray_HOST_DIMS(self)[i] == other_dims[i])\n",
      "1769             || (other_strides[i] == 0));\n",
      "1770         size *= (unsigned int) CudaNdarray_HOST_DIMS(self)[i];\n",
      "1771     }\n",
      "1772 \n",
      "1773     if (size==0)\n",
      "1774     {\n",
      "1775         int other_size = CudaNdarray_SIZE((CudaNdarray *)py_other);\n",
      "1776         if (!(other_size == 0 || other_size == 1))\n",
      "1777         {\n",
      "1778             PyErr_SetString(\n",
      "1779                 PyExc_ValueError,\n",
      "1780                 \"CudaNdarray_inplace_elemwise cannot work inplace on\"\n",
      "1781                 \" un-initialized array when the new value have more than\"\n",
      "1782                 \" 0 or 1 broadcastable dimensions\");\n",
      "1783             Py_XDECREF(new_other);\n",
      "1784             return 0;\n",
      "1785         }\n",
      "1786         Py_XDECREF(new_other);\n",
      "1787         return 0;\n",
      "1788     }\n",
      "1789 \n",
      "1790     switch(self->nd)\n",
      "1791     {\n",
      "1792         case 0:\n",
      "1793             {\n",
      "1794                 dim3 n_blocks(1, 1, 1);\n",
      "1795                 dim3 n_threads(1);\n",
      "1796                 k3<<<n_blocks, n_threads>>>(\n",
      "1797                         1, //d0\n",
      "1798                         1, //d1\n",
      "1799                         1, //d2\n",
      "1800                         CudaNdarray_DEV_DATA(self),\n",
      "1801                         1, //strides\n",
      "1802                         1,\n",
      "1803                         1,\n",
      "1804                         CudaNdarray_DEV_DATA(other),\n",
      "1805                         1, //strides\n",
      "1806                         1,\n",
      "1807                         1);\n",
      "1808                 CNDA_THREAD_SYNC;\n",
      "1809                 cudaError_t err = cudaGetLastError();\n",
      "1810                 if (cudaSuccess != err)\n",
      "1811                 {\n",
      "1812                     PyErr_Format(\n",
      "1813                         PyExc_RuntimeError,\n",
      "1814                         \"CudaNdarray_inplace_elemwise case0: Cuda error: %s: %s.\\n\",\n",
      "1815                         \"k3\",\n",
      "1816                         cudaGetErrorString(err));\n",
      "1817                     Py_XDECREF(new_other);\n",
      "1818                     return -1;\n",
      "1819                 }\n",
      "1820             }\n",
      "1821             break;\n",
      "1822         case 1:\n",
      "1823             {\n",
      "1824                 dim3 n_blocks(1, 1, 1);\n",
      "1825                 dim3 n_threads(\n",
      "1826                         std::min(\n",
      "1827                             CudaNdarray_HOST_DIMS(self)[0],\n",
      "1828                             NUM_VECTOR_OP_THREADS_PER_BLOCK));\n",
      "1829                 k3<<<n_blocks, n_threads>>>(\n",
      "1830                         1, //dimensions\n",
      "1831                         1,\n",
      "1832                         CudaNdarray_HOST_DIMS(self)[0],\n",
      "1833                         CudaNdarray_DEV_DATA(self),\n",
      "1834                         1, //strides\n",
      "1835                         1,\n",
      "1836                         CudaNdarray_HOST_STRIDES(self)[0],\n",
      "1837                         CudaNdarray_DEV_DATA(other),\n",
      "1838                         1, //strides\n",
      "1839                         1,\n",
      "1840                         other_strides[0]);\n",
      "1841                 CNDA_THREAD_SYNC;\n",
      "1842                 cudaError_t err = cudaGetLastError();\n",
      "1843                 if (cudaSuccess != err)\n",
      "1844                 {\n",
      "1845                     PyErr_Format(\n",
      "1846                         PyExc_RuntimeError,\n",
      "1847                         \"CudaNdarray_inplace_elemwise case1: Cuda error: %s: %s.\\n\",\n",
      "1848                         \"k3\",\n",
      "1849                         cudaGetErrorString(err));\n",
      "1850                     Py_XDECREF(new_other);\n",
      "1851                     return -1;\n",
      "1852                 }\n",
      "1853             }\n",
      "1854             break;\n",
      "1855         case 2:\n",
      "1856             {\n",
      "1857                 //TODO:  if both self and other are f-contiguous\n",
      "1858                 //       Then flip the block and thread dimensions\n",
      "1859                 //       to make contiguous reads & writes\n",
      "1860                 dim3 n_blocks(1,\n",
      "1861                         std::min(\n",
      "1862                             CudaNdarray_HOST_DIMS(self)[0],\n",
      "1863                             NUM_VECTOR_OP_BLOCKS));\n",
      "1864                 dim3 n_threads(\n",
      "1865                         std::min(\n",
      "1866                             CudaNdarray_HOST_DIMS(self)[1],\n",
      "1867                             NUM_VECTOR_OP_THREADS_PER_BLOCK));\n",
      "1868                 k3<<<n_blocks, n_threads>>>(1,\n",
      "1869                         CudaNdarray_HOST_DIMS(self)[0],\n",
      "1870                         CudaNdarray_HOST_DIMS(self)[1],\n",
      "1871                         CudaNdarray_DEV_DATA(self),\n",
      "1872                         1,\n",
      "1873                         CudaNdarray_HOST_STRIDES(self)[0],\n",
      "1874                         CudaNdarray_HOST_STRIDES(self)[1],\n",
      "1875                         CudaNdarray_DEV_DATA(other),\n",
      "1876                         1,\n",
      "1877                         other_strides[0],\n",
      "1878                         other_strides[1]);\n",
      "1879                 CNDA_THREAD_SYNC;\n",
      "1880                 cudaError_t err = cudaGetLastError();\n",
      "1881                 if (cudaSuccess != err)\n",
      "1882                 {\n",
      "1883                     PyErr_Format(\n",
      "1884                         PyExc_RuntimeError,\n",
      "1885                         \"CudaNdarray_inplace_elemwise case2: Cuda error: %s: %s.\\n\",\n",
      "1886                         \"k3\",\n",
      "1887                         cudaGetErrorString(err));\n",
      "1888                     Py_XDECREF(new_other);\n",
      "1889                     return -1;\n",
      "1890                 }\n",
      "1891             }\n",
      "1892             break;\n",
      "1893         case 3:\n",
      "1894             {\n",
      "1895                 //TODO:  Dimshuffle so that at least one of the arrays\n",
      "1896                 //       has a contiguous dimension on the thread idx.\n",
      "1897                 dim3 n_blocks(\n",
      "1898                         std::min(\n",
      "1899                             CudaNdarray_HOST_DIMS(self)[0],\n",
      "1900                             NUM_VECTOR_OP_BLOCKS),\n",
      "1901                         CudaNdarray_HOST_DIMS(self)[1]);\n",
      "1902                 while (n_blocks.x * n_blocks.y > NUM_VECTOR_OP_BLOCKS)\n",
      "1903                     n_blocks.y /= 2;\n",
      "1904                 dim3 n_threads(\n",
      "1905                         std::min(\n",
      "1906                             CudaNdarray_HOST_DIMS(self)[2],\n",
      "1907                             NUM_VECTOR_OP_THREADS_PER_BLOCK));\n",
      "1908                 k3<<<n_blocks, n_threads>>>(\n",
      "1909                         CudaNdarray_HOST_DIMS(self)[0],\n",
      "1910                         CudaNdarray_HOST_DIMS(self)[1],\n",
      "1911                         CudaNdarray_HOST_DIMS(self)[2],\n",
      "1912                         CudaNdarray_DEV_DATA(self),\n",
      "1913                         CudaNdarray_HOST_STRIDES(self)[0],\n",
      "1914                         CudaNdarray_HOST_STRIDES(self)[1],\n",
      "1915                         CudaNdarray_HOST_STRIDES(self)[2],\n",
      "1916                         CudaNdarray_DEV_DATA(other),\n",
      "1917                         other_strides[0],\n",
      "1918                         other_strides[1],\n",
      "1919                         other_strides[2]);\n",
      "1920                 CNDA_THREAD_SYNC;\n",
      "1921                 cudaError_t err = cudaGetLastError();\n",
      "1922                 if (cudaSuccess != err)\n",
      "1923                 {\n",
      "1924                     PyErr_Format(\n",
      "1925                         PyExc_RuntimeError,\n",
      "1926                         \"CudaNdarray_inplace_elemwise case3: Cuda error: %s: %s.\\n\",\n",
      "1927                         \"k3\",\n",
      "1928                         cudaGetErrorString(err));\n",
      "1929                     Py_XDECREF(new_other);\n",
      "1930                     return -1;\n",
      "1931                 }\n",
      "1932             }\n",
      "1933             break;\n",
      "1934         case 4:\n",
      "1935             {\n",
      "1936                 dim3 n_blocks(\n",
      "1937                         std::min(\n",
      "1938                             CudaNdarray_HOST_DIMS(self)[0],\n",
      "1939                             NUM_VECTOR_OP_BLOCKS),\n",
      "1940                         CudaNdarray_HOST_DIMS(self)[1]\n",
      "1941                         );\n",
      "1942                 while (n_blocks.x * n_blocks.y > NUM_VECTOR_OP_BLOCKS)\n",
      "1943                     n_blocks.y /= 2;\n",
      "1944                 dim3 n_threads(\n",
      "1945                         std::min(\n",
      "1946                             CudaNdarray_HOST_DIMS(self)[2],\n",
      "1947                             NUM_VECTOR_OP_THREADS_PER_BLOCK)\n",
      "1948                     //TODO: DON\"T YOU NEED OT PUT DIMS[3] in here???\n",
      "1949                             );\n",
      "1950                 k4<<<n_blocks, n_threads>>>(\n",
      "1951                         CudaNdarray_HOST_DIMS(self)[0],\n",
      "1952                         CudaNdarray_HOST_DIMS(self)[1],\n",
      "1953                         CudaNdarray_HOST_DIMS(self)[2],\n",
      "1954                         CudaNdarray_HOST_DIMS(self)[3],\n",
      "1955                         CudaNdarray_DEV_DATA(self),\n",
      "1956                         CudaNdarray_HOST_STRIDES(self)[0],\n",
      "1957                         CudaNdarray_HOST_STRIDES(self)[1],\n",
      "1958                         CudaNdarray_HOST_STRIDES(self)[2],\n",
      "1959                         CudaNdarray_HOST_STRIDES(self)[3],\n",
      "1960                         CudaNdarray_DEV_DATA(other),\n",
      "1961                         other_strides[0],\n",
      "1962                         other_strides[1],\n",
      "1963                         other_strides[2],\n",
      "1964                         other_strides[3]);\n",
      "1965                 CNDA_THREAD_SYNC;\n",
      "1966                 cudaError_t err = cudaGetLastError();\n",
      "1967                 if (cudaSuccess != err)\n",
      "1968                 {\n",
      "1969                     PyErr_Format(\n",
      "1970                         PyExc_RuntimeError,\n",
      "1971                         \"CudaNdarray_inplace_elemwise case4: Cuda error: %s: %s.\\n\",\n",
      "1972                         \"k4\",\n",
      "1973                         cudaGetErrorString(err));\n",
      "1974                     Py_XDECREF(new_other);\n",
      "1975                     return -1;\n",
      "1976                 }\n",
      "1977             }\n",
      "1978             break;\n",
      "1979         case 5:\n",
      "1980             {\n",
      "1981                 dim3 n_blocks(\n",
      "1982                         std::min(\n",
      "1983                             CudaNdarray_HOST_DIMS(self)[1],\n",
      "1984                             NUM_VECTOR_OP_BLOCKS),\n",
      "1985                         CudaNdarray_HOST_DIMS(self)[2]);\n",
      "1986                 while (n_blocks.x * n_blocks.y > NUM_VECTOR_OP_BLOCKS)\n",
      "1987                     n_blocks.y /= 2;\n",
      "1988                 dim3 n_threads(\n",
      "1989                         std::min(\n",
      "1990                             CudaNdarray_HOST_DIMS(self)[3],\n",
      "1991                             NUM_VECTOR_OP_THREADS_PER_BLOCK)\n",
      "1992                     //TODO: DON\"T YOU NEED OT PUT DIMS[3] in here???\n",
      "1993                     );\n",
      "1994                 for (int i = 0; i < CudaNdarray_HOST_DIMS(self)[0]; ++i)\n",
      "1995                 {\n",
      "1996                      k4<<<n_blocks, n_threads>>>(\n",
      "1997                             CudaNdarray_HOST_DIMS(self)[1],\n",
      "1998                             CudaNdarray_HOST_DIMS(self)[2],\n",
      "1999                             CudaNdarray_HOST_DIMS(self)[3],\n",
      "2000                             CudaNdarray_HOST_DIMS(self)[4],\n",
      "2001                             CudaNdarray_DEV_DATA(self) + i * CudaNdarray_HOST_STRIDES(self)[0],\n",
      "2002                             CudaNdarray_HOST_STRIDES(self)[1],\n",
      "2003                             CudaNdarray_HOST_STRIDES(self)[2],\n",
      "2004                             CudaNdarray_HOST_STRIDES(self)[3],\n",
      "2005                             CudaNdarray_HOST_STRIDES(self)[4],\n",
      "2006                             CudaNdarray_DEV_DATA(other) + i * other_strides[0],\n",
      "2007                             other_strides[1],\n",
      "2008                             other_strides[2],\n",
      "2009                             other_strides[3],\n",
      "2010                             other_strides[4]);\n",
      "2011                     CNDA_THREAD_SYNC;\n",
      "2012                     cudaError_t err = cudaGetLastError();\n",
      "2013                     if( cudaSuccess != err)\n",
      "2014                     {\n",
      "2015                         PyErr_Format(\n",
      "2016                             PyExc_RuntimeError,\n",
      "2017                             \"CudaNdarray_inplace_elemwise case5: Cuda error: %s: %s. n_block=(%ld,%ld) n_threads=%ld\\n\",\n",
      "2018                             \"k5 with loop over k4\",\n",
      "2019                             cudaGetErrorString(err),\n",
      "2020                             (long) n_blocks.x, (long) n_blocks.y, (long) n_threads.x);\n",
      "2021                         Py_XDECREF(new_other);\n",
      "2022                         return -1;\n",
      "2023                     }\n",
      "2024                 }\n",
      "2025             }\n",
      "2026             break;\n",
      "2027         case 6:\n",
      "2028             {\n",
      "2029                 dim3 n_blocks(\n",
      "2030                         std::min(\n",
      "2031                             CudaNdarray_HOST_DIMS(self)[0],\n",
      "2032                             NUM_VECTOR_OP_BLOCKS),\n",
      "2033                         CudaNdarray_HOST_DIMS(self)[1],\n",
      "2034                         CudaNdarray_HOST_DIMS(self)[2]\n",
      "2035                         );\n",
      "2036                 while (n_blocks.x * n_blocks.y > NUM_VECTOR_OP_BLOCKS)\n",
      "2037                     n_blocks.y /= 2;\n",
      "2038                 // GTX285(compute capabilities 1.3) don't support n_blocks.z > 1\n",
      "2039                 // (compute capabilities 2.0) support 65535 for n_blocks.z\n",
      "2040                 //while (n_blocks.x * n_blocks.y * n_blocks.z > NUM_VECTOR_OP_BLOCKS)\n",
      "2041                 //    n_blocks.z /= 2;\n",
      "2042                 n_blocks.z = 1;\n",
      "2043                 dim3 n_threads(\n",
      "2044                         std::min(\n",
      "2045                             CudaNdarray_HOST_DIMS(self)[3],\n",
      "2046                             NUM_VECTOR_OP_THREADS_PER_BLOCK)\n",
      "2047                     //TODO: DON'T YOU NEED TO PUT DIMS[4] in here???\n",
      "2048                     //TODO: DON'T YOU NEED TO PUT DIMS[5] in here???\n",
      "2049                             );\n",
      "2050                 k6<<<n_blocks, n_threads>>>(\n",
      "2051                         CudaNdarray_HOST_DIMS(self)[0],\n",
      "2052                         CudaNdarray_HOST_DIMS(self)[1],\n",
      "2053                         CudaNdarray_HOST_DIMS(self)[2],\n",
      "2054                         CudaNdarray_HOST_DIMS(self)[3],\n",
      "2055                         CudaNdarray_HOST_DIMS(self)[4],\n",
      "2056                         CudaNdarray_HOST_DIMS(self)[5],\n",
      "2057                         CudaNdarray_DEV_DATA(self),\n",
      "2058                         CudaNdarray_HOST_STRIDES(self)[0],\n",
      "2059                         CudaNdarray_HOST_STRIDES(self)[1],\n",
      "2060                         CudaNdarray_HOST_STRIDES(self)[2],\n",
      "2061                         CudaNdarray_HOST_STRIDES(self)[3],\n",
      "2062                         CudaNdarray_HOST_STRIDES(self)[4],\n",
      "2063                         CudaNdarray_HOST_STRIDES(self)[5],\n",
      "2064                         CudaNdarray_DEV_DATA(other),\n",
      "2065                         other_strides[0],\n",
      "2066                         other_strides[1],\n",
      "2067                         other_strides[2],\n",
      "2068                         other_strides[3],\n",
      "2069                         other_strides[4],\n",
      "2070                         other_strides[5]);\n",
      "2071                 CNDA_THREAD_SYNC;\n",
      "2072                 cudaError_t err = cudaGetLastError();\n",
      "2073                 if (cudaSuccess != err)\n",
      "2074                 {\n",
      "2075                     PyErr_Format(\n",
      "2076                         PyExc_RuntimeError,\n",
      "2077                         \"CudaNdarray_inplace_elemwise case6: Cuda error: %s: %s. n_blocks=(%ld, %ld, %ld) n_threads=(%ld)\\n\",\n",
      "2078                         \"k6\",\n",
      "2079                         cudaGetErrorString(err),\n",
      "2080                         (long) n_blocks.x, (long) n_blocks.y, (long) n_blocks.z,\n",
      "2081                         (long) n_threads.x);\n",
      "2082                     Py_XDECREF(new_other);\n",
      "2083                     return -1;\n",
      "2084                 }\n",
      "2085             }\n",
      "2086             break;\n",
      "2087         default:\n",
      "2088         {\n",
      "2089             PyErr_Format(\n",
      "2090                 PyExc_NotImplementedError,\n",
      "2091                 \"inplace_elemwise w nd=%i\\n\",\n",
      "2092                 self->nd);\n",
      "2093             Py_XDECREF(new_other);\n",
      "2094             return -1;\n",
      "2095         }\n",
      "2096     }\n",
      "2097     if (verbose)\n",
      "2098         fprintf(stderr, \"INPLACE ADD/DIV end\\n\");\n",
      "2099     Py_XDECREF(new_other);\n",
      "2100     return 0;\n",
      "2101 }\n",
      "2102 \n",
      "2103 /*\n",
      "2104  * We need this inplace Add to support IncSubTensor\n",
      "2105  * It returns py_self on success with an additional reference. Else NULL.\n",
      "2106  */\n",
      "2107 // Will be called by __iadd__ in Python\n",
      "2108 PyObject *\n",
      "2109 CudaNdarray_inplace_add(PyObject* py_self, PyObject * py_other)\n",
      "2110 {\n",
      "2111     if (CudaNdarray_inplace_elemwise(py_self, py_other, IADD))\n",
      "2112     {\n",
      "2113         return NULL;\n",
      "2114     }\n",
      "2115     Py_INCREF(py_self);\n",
      "2116     return py_self;\n",
      "2117 }\n",
      "2118 \n",
      "2119 /*\n",
      "2120  * We need this inplace div for cuda/tests/test_basic_ops.py:test_shared_options\n",
      "2121  * It returns py_self on success with an additional reference. Else NULL.\n",
      "2122  */\n",
      "2123 // Will be called by __idiv__ in Python\n",
      "2124 static PyObject *\n",
      "2125 CudaNdarray_inplace_div(PyObject* py_self, PyObject * py_other)\n",
      "2126 {\n",
      "2127     if (CudaNdarray_inplace_elemwise(py_self, py_other, IDIV))\n",
      "2128     {\n",
      "2129         return NULL;\n",
      "2130     }\n",
      "2131     Py_INCREF(py_self);\n",
      "2132     return py_self;\n",
      "2133 }\n",
      "2134 \n",
      "2135 // The PyNumberMethods struct layout changed in a non-trivial way from 2 to 3.\n",
      "2136 #if PY_MAJOR_VERSION == 3\n",
      "2137 static PyNumberMethods CudaNdarrayNumberMethods =\n",
      "2138 {\n",
      "2139     (binaryfunc)CudaNdarray_add,  //binaryfunc nb_add;  __add__\n",
      "2140     0,  //binaryfunc nb_subtract;\n",
      "2141     0,  //binaryfunc nb_multiply;\n",
      "2142     0,  //binaryfunc nb_remainder;\n",
      "2143     0,  //binaryfunc nb_divmod;\n",
      "2144     0,  //ternaryfunc nb_power;\n",
      "2145     0,  //unaryfunc nb_negative;\n",
      "2146     0,  //unaryfunc nb_positive;\n",
      "2147     0,  //unaryfunc nb_absolute;\n",
      "2148     0,  //inquiry nb_bool;\n",
      "2149     0,  //unaryfunc nb_invert;\n",
      "2150     0,  //binaryfunc nb_lshift;\n",
      "2151     0,  //binaryfunc nb_rshift;\n",
      "2152     0,  //binaryfunc nb_and;\n",
      "2153     0,  //binaryfunc nb_xor;\n",
      "2154     0,  //binaryfunc nb_or;\n",
      "2155     0,  //unaryfunc nb_int;\n",
      "2156     0,  //void *nb_reserved;\n",
      "2157     0,  //unaryfunc nb_float;\n",
      "2158 \n",
      "2159     (binaryfunc)CudaNdarray_inplace_add,  //binaryfunc nb_inplace_add;  __iadd__\n",
      "2160     0,  //binaryfunc nb_inplace_subtract;\n",
      "2161     0,  //binaryfunc nb_inplace_multiply;\n",
      "2162     0,  //binaryfunc nb_inplace_remainder;\n",
      "2163     0,  //ternaryfunc nb_inplace_power;\n",
      "2164     0,  //binaryfunc nb_inplace_lshift;\n",
      "2165     0,  //binaryfunc nb_inplace_rshift;\n",
      "2166     0,  //binaryfunc nb_inplace_and;\n",
      "2167     0,  //binaryfunc nb_inplace_xor;\n",
      "2168     0,  //binaryfunc nb_inplace_or;\n",
      "2169 \n",
      "2170     0,  //binaryfunc nb_floor_divide;\n",
      "2171     0,  //binaryfunc nb_true_divide;\n",
      "2172     0,  //binaryfunc nb_inplace_floor_divide;\n",
      "2173     (binaryfunc)CudaNdarray_inplace_div,  //binaryfunc nb_inplace_true_divide;        __idiv__\n",
      "2174 \n",
      "2175     0,  //unaryfunc nb_index\n",
      "2176 };\n",
      "2177 #else\n",
      "2178 static PyNumberMethods CudaNdarrayNumberMethods =\n",
      "2179 {\n",
      "2180     (binaryfunc)CudaNdarray_add,  //binaryfunc nb_add;  __add__\n",
      "2181     0,  //binaryfunc nb_subtract;      __sub__\n",
      "2182     0,  //binaryfunc nb_multiply;      __mul__\n",
      "2183     0,  //binaryfunc nb_divide;        __div__\n",
      "2184     0,  //binaryfunc nb_remainder;     __mod__\n",
      "2185     0,  //binaryfunc nb_divmod;        __divmod__\n",
      "2186     0,  //ternaryfunc nb_power;        __pow__\n",
      "2187     0,  //unaryfunc nb_negative;       __neg__\n",
      "2188     0,  //unaryfunc nb_positive;       __pos__\n",
      "2189     0,  //unaryfunc nb_absolute;       __abs__\n",
      "2190     0,  //inquiry nb_nonzero;          __nonzero__     /* Used by PyObject_IsTrue */\n",
      "2191     0,  //unaryfunc nb_invert;         __invert__\n",
      "2192     0,  //binaryfunc nb_lshift;        __lshift__\n",
      "2193     0,  //binaryfunc nb_rshift;        __rshift__\n",
      "2194     0,  //binaryfunc nb_and;           __and__\n",
      "2195     0,  //binaryfunc nb_xor;           __xor__\n",
      "2196     0,  //binaryfunc nb_or;            __or__\n",
      "2197     0,  //coercion nb_coerce;          __coerce__     /* Used by the coerce() function */\n",
      "2198     0,  //unaryfunc nb_int;            __int__\n",
      "2199     0,  //unaryfunc nb_long;           __long__\n",
      "2200     0,  //unaryfunc nb_float;          __float__\n",
      "2201     0,  //unaryfunc nb_oct;            __oct__\n",
      "2202     0,  //unaryfunc nb_hex;            __hex__\n",
      "2203 \n",
      "2204     /* Added in release 2.0 */\n",
      "2205     (binaryfunc)CudaNdarray_inplace_add,  //binaryfunc nb_inplace_add;  __iadd__\n",
      "2206     0,  //binaryfunc nb_inplace_subtract;      __isub__\n",
      "2207     0,  //binaryfunc nb_inplace_multiply;      __imul__\n",
      "2208     (binaryfunc)CudaNdarray_inplace_div,  //binaryfunc nb_inplace_divide;        __idiv__\n",
      "2209     0,  //binaryfunc nb_inplace_remainder;     __imod__\n",
      "2210     0,  //ternaryfunc nb_inplace_power;        __ipow__\n",
      "2211     0,  //binaryfunc nb_inplace_lshift;        __ilshift__\n",
      "2212     0,  //binaryfunc nb_inplace_rshift;        __irshift__\n",
      "2213     0,  //binaryfunc nb_inplace_and;           __iand__\n",
      "2214     0,  //binaryfunc nb_inplace_xor;           __ixor__\n",
      "2215     0,  //binaryfunc nb_inplace_or;            __ior__\n",
      "2216 \n",
      "2217     /* Added in release 2.2 */\n",
      "2218     0,  //binaryfunc nb_floor_divide;          __floordiv__\n",
      "2219     0,  //binaryfunc nb_true_divide;           __truediv__\n",
      "2220     0,  //binaryfunc nb_inplace_floor_divide;  __ifloordiv__\n",
      "2221     (binaryfunc)CudaNdarray_inplace_div,  //binaryfunc nb_inplace_true_divide;   __itruediv__\n",
      "2222 \n",
      "2223 #if PY_MINOR_VERSION > 4\n",
      "2224     /* Added in release 2.5 */\n",
      "2225     0  //unaryfunc nb_index;  __index__\n",
      "2226 #endif\n",
      "2227 };\n",
      "2228 #endif\n",
      "2229 \n",
      "2230 \n",
      "2231 /////////////////////\n",
      "2232 // Mapping protocol\n",
      "2233 /////////////////////\n",
      "2234 \n",
      "2235 // Will by called by __len__ in Python\n",
      "2236 static Py_ssize_t\n",
      "2237 CudaNdarray_len(PyObject * py_self)\n",
      "2238 {\n",
      "2239     CudaNdarray * self = (CudaNdarray*) py_self;\n",
      "2240     if (self->nd <= 0)\n",
      "2241     {\n",
      "2242         return (Py_ssize_t) 0;\n",
      "2243     }\n",
      "2244     else\n",
      "2245     {\n",
      "2246         return (Py_ssize_t) CudaNdarray_HOST_DIMS(self)[0];\n",
      "2247     }\n",
      "2248 }\n",
      "2249 \n",
      "2250 // Will by called by __getitem__ in Python\n",
      "2251 PyObject *\n",
      "2252 CudaNdarray_Subscript(PyObject * py_self, PyObject * key)\n",
      "2253 {\n",
      "2254     int verbose = 0;\n",
      "2255     if (verbose) fprintf(stderr, \"Subscript .... \\n\");\n",
      "2256     CudaNdarray * self = (CudaNdarray*) py_self;\n",
      "2257     PyObject * py_rval = NULL;\n",
      "2258     CudaNdarray * rval = NULL;\n",
      "2259     PyObject * intobj = NULL;\n",
      "2260 \n",
      "2261     //PyObject_Print(key, stderr, 0);\n",
      "2262 \n",
      "2263     if (key == Py_Ellipsis)\n",
      "2264     {\n",
      "2265         Py_INCREF(py_self);\n",
      "2266         return py_self;\n",
      "2267     }\n",
      "2268     if ((intobj=PyNumber_Int(key))) //INDEXING BY INTEGER\n",
      "2269     //else if (PyInt_Check(key)) //INDEXING BY INTEGER\n",
      "2270     {\n",
      "2271         int d_idx = PyInt_AsLong(intobj);\n",
      "2272         Py_DECREF(intobj); intobj=NULL;\n",
      "2273         //int d_idx = PyInt_AsLong(key);\n",
      "2274         if (self->nd == 0)\n",
      "2275         {\n",
      "2276             PyErr_SetString(PyExc_IndexError, \"0-d arrays can't be indexed\");\n",
      "2277             return NULL;\n",
      "2278         }\n",
      "2279         int d_dim = CudaNdarray_HOST_DIMS(self)[0];\n",
      "2280         int offset = 0;\n",
      "2281 \n",
      "2282         if ((d_idx >= 0) && (d_idx < d_dim))\n",
      "2283         {\n",
      "2284             //normal indexing\n",
      "2285             offset += d_idx * CudaNdarray_HOST_STRIDES(self)[0];\n",
      "2286         }\n",
      "2287         else if ((d_idx < 0) && (d_idx >= -d_dim))\n",
      "2288         {\n",
      "2289             //end-based indexing\n",
      "2290             // d_idx is negative\n",
      "2291             offset += (d_dim + d_idx) * CudaNdarray_HOST_STRIDES(self)[0];\n",
      "2292         }\n",
      "2293         else\n",
      "2294         {\n",
      "2295             PyErr_Format(PyExc_IndexError,\n",
      "2296                          \"index out of bounds. Asked %d, but size of %d\",\n",
      "2297                          d_idx, d_dim);\n",
      "2298             return NULL;\n",
      "2299         }\n",
      "2300 \n",
      "2301         //allocate our subtensor view\n",
      "2302         py_rval = CudaNdarray_new_nd(self->nd - 1);\n",
      "2303         rval = (CudaNdarray*) py_rval;\n",
      "2304         if (!rval) return NULL;\n",
      "2305         assert (0 == rval->data_allocated);\n",
      "2306 \n",
      "2307         //initialize the view's data pointer to our own.\n",
      "2308         if (CudaNdarray_set_device_data(rval, CudaNdarray_DEV_DATA(self) + offset, self))\n",
      "2309         {\n",
      "2310             Py_DECREF(rval);\n",
      "2311             return NULL;\n",
      "2312         }\n",
      "2313         for (int d = 1; d < self->nd; ++d)\n",
      "2314         {\n",
      "2315             CudaNdarray_set_stride(rval, d-1, CudaNdarray_HOST_STRIDES(self)[d]);\n",
      "2316             CudaNdarray_set_dim(rval, d-1, CudaNdarray_HOST_DIMS(self)[d]);\n",
      "2317         }\n",
      "2318     }\n",
      "2319     else\n",
      "2320     {\n",
      "2321         PyErr_Clear();\n",
      "2322     }\n",
      "2323     if (PySlice_Check(key)) //INDEXING BY SLICE\n",
      "2324     {\n",
      "2325         if (verbose) fprintf(stderr, \"by slice\\n\");\n",
      "2326         if (self->nd == 0)\n",
      "2327         {\n",
      "2328             PyErr_SetString(PyExc_ValueError, \"cannot slice a 0-d array\");\n",
      "2329             return NULL;\n",
      "2330         }\n",
      "2331 \n",
      "2332         int d_dim = CudaNdarray_HOST_DIMS(self)[0];\n",
      "2333         Py_ssize_t start, stop, step, slen;\n",
      "2334         if (PySlice_GetIndicesEx(SLICE_CAST(key), d_dim, &start, &stop, &step, &slen))\n",
      "2335         {\n",
      "2336             if (verbose)\n",
      "2337                 fprintf(stderr, \"PySlice_GetIndicesEx failed\\n\");\n",
      "2338             return NULL;\n",
      "2339         }\n",
      "2340         if (verbose)\n",
      "2341         {\n",
      "2342             std::cerr << \"start \" << start << \"\\n\";\n",
      "2343             std::cerr << \"stop \" << stop << \"\\n\";\n",
      "2344             std::cerr << \"step \" << step << \"\\n\";\n",
      "2345             std::cerr << \"slen \" << slen << \"\\n\";\n",
      "2346         }\n",
      "2347 \n",
      "2348         //allocate our subtensor view\n",
      "2349         py_rval = CudaNdarray_new_nd(self->nd);\n",
      "2350         rval = (CudaNdarray*) py_rval;\n",
      "2351         if (!rval) return NULL;\n",
      "2352         assert (0 == rval->data_allocated);\n",
      "2353 \n",
      "2354 \n",
      "2355         //initialize the view's data pointer to our own.\n",
      "2356         if (CudaNdarray_set_device_data(rval,\n",
      "2357                     CudaNdarray_DEV_DATA(self) + start * CudaNdarray_HOST_STRIDES(self)[0],\n",
      "2358                     self))\n",
      "2359         {\n",
      "2360             Py_DECREF(rval);\n",
      "2361             return NULL;\n",
      "2362         }\n",
      "2363         //initialize dimension 0 of rval\n",
      "2364         CudaNdarray_set_stride(rval, 0,\n",
      "2365                 (slen == 1) ? 0 : step * CudaNdarray_HOST_STRIDES(self)[0]);\n",
      "2366         CudaNdarray_set_dim(rval, 0, slen);\n",
      "2367         if (verbose) std::cerr << \"rval stride \" << CudaNdarray_HOST_STRIDES(rval)[0] << \"\\n\";\n",
      "2368         // initialize dimensions > 0 of rval\n",
      "2369         for (int d = 1; d < self->nd; ++d)\n",
      "2370         {\n",
      "2371             CudaNdarray_set_stride(rval, d, CudaNdarray_HOST_STRIDES(self)[d]);\n",
      "2372             CudaNdarray_set_dim(rval, d, CudaNdarray_HOST_DIMS(self)[d]);\n",
      "2373         }\n",
      "2374     }\n",
      "2375     if (PyTuple_Check(key)) //INDEXING BY TUPLE\n",
      "2376     {\n",
      "2377         if (verbose) fprintf(stderr, \"by tuple\\n\");\n",
      "2378         //elements of the tuple can be either integers or slices\n",
      "2379         //the dimensionality of the view we will return is diminished for each slice in the tuple\n",
      "2380 \n",
      "2381         if (PyTuple_Size(key) > self->nd)\n",
      "2382         {\n",
      "2383             PyErr_SetString(PyExc_IndexError, \"index error\");\n",
      "2384             return NULL;\n",
      "2385         }\n",
      "2386 \n",
      "2387         //calculate the number of dimensions in the return value\n",
      "2388         int rval_nd = self->nd;\n",
      "2389         for (int d = 0; d < PyTuple_Size(key); ++d)\n",
      "2390         {\n",
      "2391             //On some paltform PyInt_Check(<type 'numpy.int64'>) return true, other it return false.\n",
      "2392             //So we use PyArray_IsAnyScalar that should covert everything.\n",
      "2393             rval_nd -= PyArray_IsAnyScalar(PyTuple_GetItem(key, d));\n",
      "2394         }\n",
      "2395 \n",
      "2396         //allocate our subtensor view\n",
      "2397         py_rval = CudaNdarray_new_nd(rval_nd);\n",
      "2398         rval = (CudaNdarray*) py_rval;\n",
      "2399         if (!rval) return NULL;\n",
      "2400         assert (0 == rval->data_allocated);\n",
      "2401 \n",
      "2402         //initialize the view's data pointer to our own.\n",
      "2403         if (CudaNdarray_set_device_data(rval, CudaNdarray_DEV_DATA(self), self))\n",
      "2404         {\n",
      "2405             Py_DECREF(rval);\n",
      "2406             return NULL;\n",
      "2407         }\n",
      "2408 \n",
      "2409         // rval_d will refer to the current dimension in the rval.\n",
      "2410         // It will not be incremented for integer keys, but will be incremented for slice\n",
      "2411         // keys\n",
      "2412         int rval_d = 0;\n",
      "2413 \n",
      "2414         for (int d = 0; d < self->nd; ++d)\n",
      "2415         {\n",
      "2416             // keys can be shorter than self->nd.\n",
      "2417             // when that happens, it means that the remaining dimensions are \"full slices\"\n",
      "2418             if (d >=PyTuple_Size(key))\n",
      "2419             {\n",
      "2420                 CudaNdarray_set_stride(rval, rval_d, CudaNdarray_HOST_STRIDES(self)[d]);\n",
      "2421                 CudaNdarray_set_dim(rval, rval_d, CudaNdarray_HOST_DIMS(self)[d]);\n",
      "2422                 ++rval_d;\n",
      "2423             }\n",
      "2424             else\n",
      "2425             {\n",
      "2426                 PyObject * key_d = PyTuple_GetItem(key, d);\n",
      "2427 \n",
      "2428                 if (PySlice_Check(key_d))\n",
      "2429                 {\n",
      "2430                     Py_ssize_t start, stop, step, slen;\n",
      "2431                     if (PySlice_GetIndicesEx(SLICE_CAST(key_d), CudaNdarray_HOST_DIMS(self)[d], &start, &stop, &step, &slen))\n",
      "2432                     {\n",
      "2433                         Py_DECREF(rval);\n",
      "2434                         return NULL;\n",
      "2435                     }\n",
      "2436                     rval->devdata += start * CudaNdarray_HOST_STRIDES(self)[d];\n",
      "2437                     CudaNdarray_set_stride(rval, rval_d,\n",
      "2438                             (slen == 1) ? 0 : step * CudaNdarray_HOST_STRIDES(self)[d]);\n",
      "2439                     CudaNdarray_set_dim(rval, rval_d, slen);\n",
      "2440                     if (0)\n",
      "2441                     {\n",
      "2442                         std::cerr << \"start \" << start << \"\\n\";\n",
      "2443                         std::cerr << \"stop \" << stop << \"\\n\";\n",
      "2444                         std::cerr << \"step \" << step << \"\\n\";\n",
      "2445                         std::cerr << \"slen \" << slen << \"\\n\";\n",
      "2446                     }\n",
      "2447                     ++rval_d;\n",
      "2448                 }\n",
      "2449                 else if ((intobj=PyNumber_Int(key_d)))\n",
      "2450                 {\n",
      "2451                     assert(PyArray_IsAnyScalar(key_d));\n",
      "2452                     int d_idx = PyInt_AsLong(intobj);\n",
      "2453                     Py_DECREF(intobj);\n",
      "2454                     intobj = NULL;\n",
      "2455                     int d_dim = CudaNdarray_HOST_DIMS(self)[d];\n",
      "2456 \n",
      "2457                     if ((d_idx >= 0) && (d_idx < d_dim))\n",
      "2458                     {\n",
      "2459                         //normal indexing\n",
      "2460                         rval->devdata += d_idx * CudaNdarray_HOST_STRIDES(self)[d];\n",
      "2461                     }\n",
      "2462                     else if ((d_idx < 0) && (d_idx >= -d_dim))\n",
      "2463                     {\n",
      "2464                         //end-based indexing\n",
      "2465                         rval->devdata += (d_dim + d_idx) * CudaNdarray_HOST_STRIDES(self)[d];\n",
      "2466                     }\n",
      "2467                     else\n",
      "2468                     {\n",
      "2469                         PyErr_Format(PyExc_IndexError,\n",
      "2470                                      \"index out of bounds. Asked %d for dimensions %d, but size of %d\",\n",
      "2471                                      d_idx, d, d_dim);\n",
      "2472                         Py_DECREF(rval);\n",
      "2473                         return NULL;\n",
      "2474                     }\n",
      "2475                 }\n",
      "2476                 else\n",
      "2477                 {\n",
      "2478                     PyErr_Clear(); // clear the error set by PyNumber_Int\n",
      "2479                     PyErr_SetString(PyExc_IndexError, \"index must be either int or slice\");\n",
      "2480                     Py_DECREF(rval);\n",
      "2481                     return NULL;\n",
      "2482                 }\n",
      "2483             }\n",
      "2484         }\n",
      "2485     }\n",
      "2486     if (py_rval)\n",
      "2487     {\n",
      "2488         if (verbose) fprint_CudaNdarray(stderr, self);\n",
      "2489         if (verbose) fprint_CudaNdarray(stderr, rval);\n",
      "2490     }\n",
      "2491     else\n",
      "2492     {\n",
      "2493         PyErr_SetString(PyExc_NotImplementedError, \"Unknown key type\");\n",
      "2494         return NULL;\n",
      "2495     }\n",
      "2496     return py_rval;\n",
      "2497 }\n",
      "2498 \n",
      "2499 // Will by called by __setitem__ in Python\n",
      "2500 // See http://docs.python.org/dev/py3k/c-api/object.html#PyObject_SetItem\n",
      "2501 // Doesn't handle broadcasting, e.g. a[:] = 5\n",
      "2502 // Can only be assigned from a CudaNdarray on the right side\n",
      "2503 // Or a ndarray\n",
      "2504 // Or a python scalar with value 0 when the left side part is c contiguous.\n",
      "2505 static int\n",
      "2506 CudaNdarray_setitem(PyObject *o, PyObject  *key, PyObject  *value)\n",
      "2507 {\n",
      "2508     int verbose = 0;\n",
      "2509     if (verbose) fprintf(stderr, \"CudaNdarray_setitem start\\n\");\n",
      "2510     // We try to copy directly into this CudaNdarray from the ndarray\n",
      "2511     CudaNdarray* rval = (CudaNdarray*)CudaNdarray_Subscript(o, key);\n",
      "2512     CudaNdarray* new_value = NULL;\n",
      "2513 \n",
      "2514     if(!rval){\n",
      "2515         // CudaNdarray_Subscript failed and set the error msg.\n",
      "2516         Py_XDECREF(rval);\n",
      "2517         return -1;\n",
      "2518     }\n",
      "2519 \n",
      "2520     if(rval != (CudaNdarray*)o &&\n",
      "2521                 (rval->data_allocated ||\n",
      "2522                  // The new array should have a base\n",
      "2523                  !(((CudaNdarray*)rval)->base) ||\n",
      "2524                  // If the original array has no base, the base of the new\n",
      "2525                  // array should be the original one\n",
      "2526                  (!((CudaNdarray*)o)->base && ((CudaNdarray*)rval)->base != o) ||\n",
      "2527                  // Else, the two arrays should have the same base\n",
      "2528                  (((CudaNdarray*)o)->base && ((CudaNdarray*)rval)->base != ((CudaNdarray*)o)->base)))\n",
      "2529     {\n",
      "2530         // This case shouldn't happen, based on what I see in Subscript\n",
      "2531         // but just in case it happens sometime in the future\n",
      "2532 \n",
      "2533         PyErr_Format(PyExc_RuntimeError,\n",
      "2534                      \"__getitem__ must return a CudaNdarray that refers to\"\n",
      "2535                      \" the original CudaNdarray, not a copy. rval.base=%p\"\n",
      "2536                      \" o.base=%p o=%p\",\n",
      "2537                      (((CudaNdarray*)rval)->base), ((CudaNdarray*)o)->base, o);\n",
      "2538         Py_DECREF(rval);\n",
      "2539         return -1;\n",
      "2540     }\n",
      "2541 \n",
      "2542     PyObject * intobj = NULL;\n",
      "2543     if (CudaNdarray_Check(o)  && PyArray_Check(value)){\n",
      "2544         if (verbose)\n",
      "2545             fprintf(stderr,\n",
      "2546                     \"CudaNdarray_setitem dest is a CudaNdarray and\"\n",
      "2547                     \" value is a ndarray\\n\");\n",
      "2548         new_value = (CudaNdarray*) CudaNdarray_New();\n",
      "2549         if(!new_value)\n",
      "2550         {\n",
      "2551             return -1;\n",
      "2552         }\n",
      "2553         if (CudaNdarray_CopyFromArray(new_value, (PyArrayObject *) value))\n",
      "2554         {\n",
      "2555             Py_XDECREF(new_value);\n",
      "2556             Py_XDECREF(rval);\n",
      "2557             return -1;\n",
      "2558         }\n",
      "2559         value = (PyObject *) new_value;\n",
      "2560     }\n",
      "2561     else if ((intobj=PyNumber_Int(value)))\n",
      "2562     {\n",
      "2563         if (verbose)\n",
      "2564             fprintf(stderr,\n",
      "2565                     \"CudaNdarray_setitem dest and value is a python number\\n\");\n",
      "2566         if(! CudaNdarray_is_c_contiguous(rval)){\n",
      "2567             PyErr_SetString(PyExc_NotImplementedError,\n",
      "2568                  \"CudaNdarray.__setitem__: When the new value is a scalar\"\n",
      "2569                  \" of value 0 the part where we copy to must be c contiguous.\");\n",
      "2570             Py_XDECREF(rval);\n",
      "2571             return -1;\n",
      "2572         }\n",
      "2573 \n",
      "2574         long val = PyInt_AsLong(intobj);\n",
      "2575         Py_DECREF(intobj); intobj=NULL;\n",
      "2576         if (val == 0)\n",
      "2577         {\n",
      "2578             cudaError_t err = cudaMemset(rval->devdata, 0,\n",
      "2579                                          CudaNdarray_SIZE(rval) * sizeof(real));\n",
      "2580             Py_XDECREF(rval);\n",
      "2581             if (err)\n",
      "2582             {\n",
      "2583                 // Clear the error flag, cudaMemset doesn't do it.\n",
      "2584                 // Currently this returns the same thing as err, but if in future\n",
      "2585                 // it returns something else I still don't see why we should ignore\n",
      "2586                 // it.  All we want to do here is reset the flag.\n",
      "2587                 cudaGetLastError();\n",
      "2588                 PyErr_SetString(PyExc_RuntimeError,\n",
      "2589                                 \"CudaNdarray.__setitem__: cudaMemset failed\");\n",
      "2590                 return -1;\n",
      "2591             }\n",
      "2592             return 0;\n",
      "2593         } else {\n",
      "2594             Py_XDECREF(rval);\n",
      "2595             PyErr_SetString(PyExc_NotImplementedError,\n",
      "2596                   \"CudaNdarray.__setitem__: we support setting only python\"\n",
      "2597                   \" scalar of value 0, numpy nd array and CudaNdarray.\");\n",
      "2598                 return -1;\n",
      "2599         }\n",
      "2600     }\n",
      "2601 \n",
      "2602     PyErr_Clear(); // clear PyNumber_Int error.\n",
      "2603 \n",
      "2604     if(!CudaNdarray_Check(o) || !CudaNdarray_Check(value))\n",
      "2605     {\n",
      "2606         PyErr_SetString(PyExc_TypeError,\n",
      "2607           \"CudaNdarray.__setitem__: left must be a CudaNdarrays and right\"\n",
      "2608           \" must be a CudaNdarrays, an ndarray or a python scalar of value 0.\");\n",
      "2609         Py_XDECREF(new_value);\n",
      "2610         return -1;\n",
      "2611     }\n",
      "2612 \n",
      "2613     if (verbose)\n",
      "2614         fprintf(stderr, \"CudaNdarray_setitem dest and value are CudaNdarray\\n\");\n",
      "2615 \n",
      "2616     if (cnda_copy_structure_to_device(rval))\n",
      "2617     {\n",
      "2618         PyErr_SetString(PyExc_RuntimeError,\n",
      "2619                 \"CudaNdarray.__setitem__: syncing structure to device failed\");\n",
      "2620         Py_DECREF(rval);\n",
      "2621         Py_XDECREF(new_value);\n",
      "2622 \n",
      "2623         if (verbose)\n",
      "2624             fprintf(stderr, \"CudaNdarray_setitem error end\\n\");\n",
      "2625         return -1;\n",
      "2626     }\n",
      "2627 \n",
      "2628     PyObject *baseSavedForComparison = rval->base;\n",
      "2629 \n",
      "2630     if (CudaNdarray_CopyFromCudaNdarray(rval, (CudaNdarray*)value, true))\n",
      "2631     {\n",
      "2632         Py_DECREF((PyObject*)rval);\n",
      "2633         Py_XDECREF(new_value);\n",
      "2634 \n",
      "2635         if (verbose)\n",
      "2636             fprintf(stderr, \"CudaNdarray_setitem error end\\n\");\n",
      "2637         return -1;\n",
      "2638     }\n",
      "2639 \n",
      "2640     assert (rval->base == baseSavedForComparison);\n",
      "2641     assert (rval->dev_structure_fresh);\n",
      "2642 \n",
      "2643     // Clean up locally-created references\n",
      "2644     Py_DECREF(rval);\n",
      "2645     Py_XDECREF(new_value);\n",
      "2646 \n",
      "2647     return 0;\n",
      "2648 }\n",
      "2649 \n",
      "2650 \n",
      "2651 PyMappingMethods CudaNdarrayMappingMethods = {\n",
      "2652     CudaNdarray_len, //lenfunc mp_length;               __len__\n",
      "2653     CudaNdarray_Subscript, //binaryfunc mp_subscript;   __getitem__\n",
      "2654     CudaNdarray_setitem //objobjargproc mp_ass_subscript;                __setitem__\n",
      "2655 };\n",
      "2656 \n",
      "2657 ////////////////////\n",
      "2658 //\n",
      "2659 ////////////////////\n",
      "2660 \n",
      "2661 static PyObject *\n",
      "2662 CudaNdarray_get_shape(CudaNdarray *self, void *closure)\n",
      "2663 {\n",
      "2664     if (self->nd < 0)\n",
      "2665     {\n",
      "2666         PyErr_SetString(PyExc_ValueError, \"CudaNdarray not initialized\");\n",
      "2667         return NULL;\n",
      "2668     }\n",
      "2669     PyObject * rval = PyTuple_New(self->nd);\n",
      "2670     for (int i = 0; i < self->nd; ++i)\n",
      "2671     {\n",
      "2672         if (!rval || PyTuple_SetItem(rval, i, PyInt_FromLong(CudaNdarray_HOST_DIMS(self)[i])))\n",
      "2673         {\n",
      "2674             Py_XDECREF(rval);\n",
      "2675             return NULL;\n",
      "2676         }\n",
      "2677 \n",
      "2678     }\n",
      "2679     return rval;\n",
      "2680 }\n",
      "2681 \n",
      "2682 static int\n",
      "2683 CudaNdarray_set_shape(CudaNdarray *self, PyObject *value, void *closure)\n",
      "2684 {\n",
      "2685     PyErr_SetString(PyExc_NotImplementedError, \"TODO: call reshape\");\n",
      "2686     return -1;\n",
      "2687 }\n",
      "2688 \n",
      "2689 static PyObject *\n",
      "2690 CudaNdarray_get_strides(CudaNdarray *self, void *closure)\n",
      "2691 {\n",
      "2692     if (self->nd < 0)\n",
      "2693     {\n",
      "2694         PyErr_SetString(PyExc_ValueError, \"CudaNdarray not initialized\");\n",
      "2695         return NULL;\n",
      "2696     }\n",
      "2697     PyObject * rval = PyTuple_New(self->nd);\n",
      "2698     for (int i = 0; i < self->nd; ++i)\n",
      "2699     {\n",
      "2700         if (!rval || PyTuple_SetItem(rval, i, PyInt_FromLong(CudaNdarray_HOST_STRIDES(self)[i])))\n",
      "2701         {\n",
      "2702             Py_XDECREF(rval);\n",
      "2703             return NULL;\n",
      "2704         }\n",
      "2705 \n",
      "2706     }\n",
      "2707     return rval;\n",
      "2708 }\n",
      "2709 \n",
      "2710 static int\n",
      "2711 CudaNdarray_set_strides(CudaNdarray *self, PyObject *value, void *closure)\n",
      "2712 {\n",
      "2713     //npy_intp newstrides_bytes[PyTuple_Size(value)];\n",
      "2714     if (PyTuple_Check(value)){\n",
      "2715         if (PyTuple_Size(value) != CudaNdarray_NDIM(self)){\n",
      "2716             PyErr_SetString(PyExc_ValueError,\n",
      "2717                             \"The new strides tuple must have the same length\"\n",
      "2718                             \" as the number of dimensions\");\n",
      "2719             return -1;\n",
      "2720         }\n",
      "2721     }else if (PyList_Check(value)){\n",
      "2722         if (PyList_Size(value) != CudaNdarray_NDIM(self)){\n",
      "2723             PyErr_SetString(PyExc_ValueError,\n",
      "2724                             \"The new strides list must have the same length\"\n",
      "2725                             \" as the number of dimensions\");\n",
      "2726             return -1;\n",
      "2727         }\n",
      "2728     }else{\n",
      "2729         PyErr_SetString(PyExc_ValueError,\n",
      "2730                         \"The new strides need to be encoded in a tuple or list\");\n",
      "2731         return -1;\n",
      "2732     }\n",
      "2733     npy_intp* newstrides = (npy_intp*) alloca(CudaNdarray_NDIM(self) * sizeof(npy_intp));\n",
      "2734     if (PyTuple_Check(value)){\n",
      "2735         for(int i=0; i < CudaNdarray_NDIM(self); i++){\n",
      "2736             newstrides[i] = PyInt_AsLong(PyTuple_GetItem(value, Py_ssize_t(i)));\n",
      "2737             //newstrides_bytes[i] = newstrides[i] * 4;\n",
      "2738         }\n",
      "2739     }else if (PyList_Check(value)){\n",
      "2740         for(int i=0; i < CudaNdarray_NDIM(self); i++){\n",
      "2741             newstrides[i] = PyInt_AsLong(PyList_GetItem(value, Py_ssize_t(i)));\n",
      "2742             //newstrides_bytes[i] = newstrides[i] * 4;\n",
      "2743         }\n",
      "2744     }\n",
      "2745     /*\n",
      "2746     // Do not do this check, as ExtractDiag needs that, and NumPy does not seem\n",
      "2747     // to do it.\n",
      "2748     npy_intp dims[PyTuple_Size(value)];\n",
      "2749     for(int i=0; i < CudaNdarray_NDIM(self); i++){\n",
      "2750         dims[i] = CudaNdarray_HOST_DIMS(self)[i];\n",
      "2751     }\n",
      "2752     if (!PyArray_CheckStrides(4,\n",
      "2753                               CudaNdarray_NDIM(self),\n",
      "2754                               0, 0,\n",
      "2755                               dims,\n",
      "2756                               newstrides_bytes)){\n",
      "2757         PyErr_SetString(PyExc_ValueError, \"bad new strides\");\n",
      "2758         return -1;\n",
      "2759         }\n",
      "2760     */\n",
      "2761     for(int i=0; i < CudaNdarray_NDIM(self); i++){\n",
      "2762         CudaNdarray_set_stride(self, i, newstrides[i]);\n",
      "2763     }\n",
      "2764     return 0;\n",
      "2765 }\n",
      "2766 \n",
      "2767 static PyObject *\n",
      "2768 CudaNdarray_get_dev_data(CudaNdarray *self, void *closure)\n",
      "2769 {\n",
      "2770     float * p =  CudaNdarray_DEV_DATA(self);\n",
      "2771     //printf(\"get_dev_data %p %li \\n\", p, (long int)p );\n",
      "2772     return PyInt_FromSize_t((size_t) CudaNdarray_DEV_DATA(self));\n",
      "2773 }\n",
      "2774 \n",
      "2775 static int\n",
      "2776 CudaNdarray_set_dev_data(CudaNdarray *self, PyObject *value, void *closure)\n",
      "2777 {\n",
      "2778     Py_ssize_t newdevdata = PyInt_AsSsize_t(value);\n",
      "2779     //printf(\"set_dev_data %p %li \\n\",(float*)newdevdata ,newdevdata);\n",
      "2780     if (PyErr_Occurred())\n",
      "2781     {\n",
      "2782         return -1;\n",
      "2783     }\n",
      "2784     return  CudaNdarray_set_device_data(self, (float*)newdevdata, (CudaNdarray*)self->base);\n",
      "2785 }\n",
      "2786 \n",
      "2787 static PyObject *\n",
      "2788 CudaNdarray_get_dtype(CudaNdarray *self, void *closure)\n",
      "2789 {\n",
      "2790     return PyString_FromString(\"float32\");\n",
      "2791 }\n",
      "2792 \n",
      "2793 static PyObject *\n",
      "2794 CudaNdarray_get_ndim(CudaNdarray *self, void *closure)\n",
      "2795 {\n",
      "2796     return PyInt_FromLong(self->nd);\n",
      "2797 }\n",
      "2798 \n",
      "2799 static PyObject *\n",
      "2800 CudaNdarray_get_base(CudaNdarray *self, void *closure)\n",
      "2801 {\n",
      "2802     PyObject * base = self->base;\n",
      "2803     if (!base)\n",
      "2804     {\n",
      "2805         // We cannot return a NULL pointer, use None instead\n",
      "2806         base = Py_None;\n",
      "2807     }\n",
      "2808     Py_INCREF(base);\n",
      "2809     return base;\n",
      "2810 }\n",
      "2811 \n",
      "2812 void put_in_dict(PyObject * dict, const char * key, int val)\n",
      "2813 {\n",
      "2814   PyObject * k = PyString_FromString(key);\n",
      "2815   PyObject * v = PyInt_FromLong(val);\n",
      "2816   PyDict_SetItem(dict, k, v);\n",
      "2817   Py_DECREF(k);\n",
      "2818   Py_DECREF(v);\n",
      "2819 }\n",
      "2820 \n",
      "2821 PyObject *\n",
      "2822 GetDeviceProperties(PyObject* _unused, PyObject* args)\n",
      "2823 {\n",
      "2824   int dev_id = -1;\n",
      "2825   if (! PyArg_ParseTuple(args, \"i\", &dev_id))\n",
      "2826     return NULL;\n",
      "2827   cudaDeviceProp deviceProp;\n",
      "2828   cudaGetDeviceProperties(&deviceProp, dev_id);\n",
      "2829 \n",
      "2830   PyObject * dict = PyDict_New();\n",
      "2831   PyObject * str= PyString_FromString(\"name\");\n",
      "2832   PyObject * i = PyString_FromString(deviceProp.name);\n",
      "2833   PyDict_SetItem(dict, str, i);\n",
      "2834   Py_DECREF(str);\n",
      "2835   Py_DECREF(i);\n",
      "2836 \n",
      "2837   put_in_dict(dict, \"major\", deviceProp.major);\n",
      "2838   put_in_dict(dict, \"minor\", deviceProp.minor);\n",
      "2839 #if CUDART_VERSION >= 2020\n",
      "2840   int driverVersion = 0, runtimeVersion = 0;\n",
      "2841   cudaDriverGetVersion(&driverVersion);\n",
      "2842   cudaRuntimeGetVersion(&runtimeVersion);\n",
      "2843   put_in_dict(dict, \"driverVersion\", driverVersion);\n",
      "2844   put_in_dict(dict, \"runtimeVersion\", runtimeVersion);\n",
      "2845 #endif\n",
      "2846 #if CUDART_VERSION >= 2000\n",
      "2847 \n",
      "2848   put_in_dict(dict, \"multiProcessorCount\", deviceProp.multiProcessorCount);\n",
      "2849   //if ConvertSMVer2Cores is not defined in cuda_runtime_api.h, the run time is too old.\n",
      "2850   int sm_cores = -1;\n",
      "2851   if(deviceProp.major==1)\n",
      "2852     sm_cores = 32;\n",
      "2853   else if(deviceProp.major==2 && deviceProp.minor==0)\n",
      "2854     sm_cores = 32;\n",
      "2855   else if(deviceProp.major==2 && deviceProp.minor==1)\n",
      "2856     sm_cores = 48;\n",
      "2857   put_in_dict(dict, \"coresCount\", sm_cores * deviceProp.multiProcessorCount);\n",
      "2858 #endif\n",
      "2859   put_in_dict(dict, \"totalConstMem\", deviceProp.totalConstMem);\n",
      "2860   put_in_dict(dict, \"sharedMemPerBlock\", deviceProp.sharedMemPerBlock);\n",
      "2861   put_in_dict(dict, \"regsPerBlock\", deviceProp.regsPerBlock);\n",
      "2862   put_in_dict(dict, \"warpSize\", deviceProp.warpSize);\n",
      "2863   put_in_dict(dict, \"maxThreadsPerBlock\", deviceProp.maxThreadsPerBlock);\n",
      "2864   put_in_dict(dict, \"maxThreadsDim0\", deviceProp.maxThreadsDim[0]);\n",
      "2865   put_in_dict(dict, \"maxThreadsDim1\", deviceProp.maxThreadsDim[1]);\n",
      "2866   put_in_dict(dict, \"maxThreadsDim2\", deviceProp.maxThreadsDim[2]);\n",
      "2867   put_in_dict(dict, \"maxGridSize0\", deviceProp.maxGridSize[0]);\n",
      "2868   put_in_dict(dict, \"maxGridSize1\", deviceProp.maxGridSize[1]);\n",
      "2869   put_in_dict(dict, \"maxGridSize2\", deviceProp.maxGridSize[2]);\n",
      "2870   put_in_dict(dict, \"memPitch\", deviceProp.memPitch);\n",
      "2871   put_in_dict(dict, \"textureAlignment\", deviceProp.textureAlignment);\n",
      "2872   put_in_dict(dict, \"clockRate\", deviceProp.clockRate);\n",
      "2873 #if CUDART_VERSION >= 2000\n",
      "2874   put_in_dict(dict, \"deviceOverlap\", deviceProp.deviceOverlap);\n",
      "2875 #endif\n",
      "2876 #if CUDART_VERSION >= 2020\n",
      "2877   put_in_dict(dict, \"kernelExecTimeoutEnabled\", deviceProp.kernelExecTimeoutEnabled);\n",
      "2878   put_in_dict(dict, \"integrated\", deviceProp.integrated);\n",
      "2879   put_in_dict(dict, \"canMapHostMemory\", deviceProp.canMapHostMemory);\n",
      "2880   put_in_dict(dict, \"computeMode\", deviceProp.computeMode);\n",
      "2881   //in the doc of this fct tell that 0 - Normal mode, 1 - only 1 context, 2 - no context\n",
      "2882 #endif\n",
      "2883 #if CUDART_VERSION >= 3000\n",
      "2884   put_in_dict(dict, \"concurrentKernels\", deviceProp.concurrentKernels);\n",
      "2885 #endif\n",
      "2886 #if CUDART_VERSION >= 3010\n",
      "2887   put_in_dict(dict, \"ECCEnabled\", deviceProp.ECCEnabled);\n",
      "2888 #endif\n",
      "2889 #if CUDART_VERSION >= 3020\n",
      "2890   put_in_dict(dict, \"tccDriver\", deviceProp.tccDriver);\n",
      "2891 #endif\n",
      "2892 \n",
      "2893   return dict;\n",
      "2894 }\n",
      "2895 \n",
      "2896 /*\n",
      "2897  * Returns in *free and *total respectively, the free and total amount of memory available for allocation by the device in bytes.\n",
      "2898  */\n",
      "2899 PyObject *\n",
      "2900 GetDeviceMemInfo(PyObject* _unused, PyObject* dummy)\n",
      "2901 {\n",
      "2902     size_t free = 0, total = 0;\n",
      "2903     if(g_gpu_context_active == 0){\n",
      "2904         PyErr_Format(PyExc_RuntimeError, \"No gpu device selected yet. Please make sure the gpu device was initialized by Theano before.\");\n",
      "2905         return NULL;\n",
      "2906     }\n",
      "2907 \n",
      "2908     cudaError_t err = cudaMemGetInfo(&free, &total);\n",
      "2909     if (err != cudaSuccess){\n",
      "2910         // Clear the error flag, cudaMemGetInfo doesn't do it.\n",
      "2911         // Currently this returns the same thing as err, but if in future\n",
      "2912         // it returns something else I still don't see why we should ignore\n",
      "2913         // it.  All we want to do here is reset the flag.\n",
      "2914         cudaGetLastError();\n",
      "2915         PyErr_Format(PyExc_RuntimeError,\n",
      "2916                      \"Error while getting memory info about the gpu: %s\",\n",
      "2917                      cudaGetErrorString(err));\n",
      "2918         return NULL;\n",
      "2919     }\n",
      "2920     return PyTuple_Pack(2, PyLong_FromSize_t(free), PyLong_FromSize_t(total));\n",
      "2921 }\n",
      "2922 \n",
      "2923 /*\n",
      "2924  * Synchronize with all the gpu device stream.\n",
      "2925  */\n",
      "2926 PyObject *\n",
      "2927 CudaNdarray_synchronize(PyObject* _unused, PyObject* dummy)\n",
      "2928 {\n",
      "2929     CNDA_BEGIN_ALLOW_THREADS\n",
      "2930     cudaThreadSynchronize();\n",
      "2931     CNDA_END_ALLOW_THREADS\n",
      "2932     Py_INCREF(Py_None);\n",
      "2933     return Py_None;\n",
      "2934 }\n",
      "2935 \n",
      "2936 /*\n",
      "2937  * Exist and return true if we link with cublas v2.\n",
      "2938  */\n",
      "2939 PyObject *\n",
      "2940 CudaNdarray_cublasv2(PyObject* _unused, PyObject* dummy)\n",
      "2941 {\n",
      "2942     Py_INCREF(Py_True);\n",
      "2943     return Py_True;\n",
      "2944 }\n",
      "2945 \n",
      "2946 PyObject *\n",
      "2947 CudaNdarray_select_a_gpu(PyObject* _unused, PyObject* dummy)\n",
      "2948 {\n",
      "2949     void * rval = NULL;\n",
      "2950     cudaError_t err;\n",
      "2951     int num_gpus = 0;\n",
      "2952 \n",
      "2953     err = cudaGetDeviceCount(&num_gpus);\n",
      "2954     if (cudaSuccess != err){\n",
      "2955         printf(\"ERR!\\\\n\");\n",
      "2956             PyErr_Format(PyExc_RuntimeError,\n",
      "2957                          \"Not able to get number of GPUs (%s).\",\n",
      "2958                          cudaGetErrorString(err));\n",
      "2959             return NULL;\n",
      "2960     }\n",
      "2961 \n",
      "2962     for (int device = 0; device < num_gpus; device++) {\n",
      "2963         cudaSetDevice(device);\n",
      "2964         err = cudaDeviceSynchronize(); // << CUDA context gets created here.\n",
      "2965         cudaGetLastError(); // reset the error state\n",
      "2966         if (cudaSuccess == err)\n",
      "2967             break;\n",
      "2968     }\n",
      "2969 \n",
      "2970     if (cudaSuccess != err){\n",
      "2971             printf(\"ERR!\\\\n\");\n",
      "2972                 PyErr_Format(PyExc_RuntimeError,\n",
      "2973                              \"Not able to select available GPU from %d cards (%s).\",\n",
      "2974                              num_gpus, cudaGetErrorString(err));\n",
      "2975                 return NULL;\n",
      "2976     }\n",
      "2977 \n",
      "2978     Py_INCREF(Py_None);\n",
      "2979     return Py_None;\n",
      "2980 }\n",
      "2981 \n",
      "2982 #if COMPUTE_GPU_MEM_USED\n",
      "2983 /*\n",
      "2984  * Return the size in bytes that Theano currently have allocated on the gpu.\n",
      "2985  */\n",
      "2986 PyObject *\n",
      "2987 GetTheanoAllocInfo(PyObject* _unused, PyObject* dummy)\n",
      "2988 {\n",
      "2989     PyObject* a = PyLong_FromSize_t(_allocated_size);\n",
      "2990     PyObject* b = PyLong_FromSize_t(_max_allocated_size);\n",
      "2991 \n",
      "2992     PyObject* tuple = PyTuple_New(2);\n",
      "2993     PyTuple_SetItem(tuple, 0, a);\n",
      "2994     PyTuple_SetItem(tuple, 1, b);\n",
      "2995     return tuple;\n",
      "2996 }\n",
      "2997 #endif\n",
      "2998 \n",
      "2999 static PyGetSetDef CudaNdarray_getset[] = {\n",
      "3000     {\"shape\",\n",
      "3001         (getter)CudaNdarray_get_shape,\n",
      "3002         (setter)CudaNdarray_set_shape,\n",
      "3003         \"shape of this ndarray (tuple)\",\n",
      "3004         NULL},\n",
      "3005     {\"_strides\",\n",
      "3006         (getter)CudaNdarray_get_strides,\n",
      "3007         (setter)CudaNdarray_set_strides,\n",
      "3008         \"data pointer strides (in elements)\",\n",
      "3009         NULL},\n",
      "3010     {\"strides\",\n",
      "3011         (getter)CudaNdarray_get_strides,\n",
      "3012         (setter)CudaNdarray_set_strides,\n",
      "3013         \"data pointer strides (in elements)\",\n",
      "3014         NULL},\n",
      "3015     //gpudata is needed to allow calling pycuda fct with CudaNdarray input.\n",
      "3016     {\"gpudata\",\n",
      "3017         (getter)CudaNdarray_get_dev_data,\n",
      "3018         NULL,\n",
      "3019         \"device data pointer\",\n",
      "3020         NULL},\n",
      "3021     {\"_dev_data\",\n",
      "3022         (getter)CudaNdarray_get_dev_data,\n",
      "3023         (setter)CudaNdarray_set_dev_data,\n",
      "3024         \"device data pointer\",\n",
      "3025         NULL},\n",
      "3026     {\"dtype\",\n",
      "3027         (getter)CudaNdarray_get_dtype,\n",
      "3028         NULL,\n",
      "3029         \"The dtype of the element. Now always float32\",\n",
      "3030         NULL},\n",
      "3031     {\"size\",\n",
      "3032         (getter)CudaNdarray_SIZE_Object,\n",
      "3033         NULL,\n",
      "3034         \"The number of elements in this object.\",\n",
      "3035         NULL},\n",
      "3036     //mem_size is neede for pycuda.elementwise.ElementwiseKernel Why do they use size and mem_size of the same value?\n",
      "3037     {\"mem_size\",\n",
      "3038         (getter)CudaNdarray_SIZE_Object,\n",
      "3039         NULL,\n",
      "3040         \"The number of elements in this object.\",\n",
      "3041         NULL},\n",
      "3042     {\"ndim\",\n",
      "3043         (getter)CudaNdarray_get_ndim,\n",
      "3044         NULL,\n",
      "3045         \"The number of dimensions in this object.\",\n",
      "3046         NULL},\n",
      "3047     {\"base\",\n",
      "3048         (getter)CudaNdarray_get_base,\n",
      "3049         NULL,\n",
      "3050         \"If this ndarray is a view, base is the original ndarray.\",\n",
      "3051         NULL},\n",
      "3052 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3053     {NULL, NULL, NULL, NULL}  /* Sentinel */\n",
      "3054 };\n",
      "3055 \n",
      "3056 PyObject *CudaNdarray_repr(PyObject *self)\n",
      "3057 {\n",
      "3058     CudaNdarray *object = (CudaNdarray *)self;\n",
      "3059     PyObject * np_object = CudaNdarray_CreateArrayObj(object);\n",
      "3060     PyObject * str = PyObject_Str((PyObject *) np_object);\n",
      "3061     char * cstr = PyString_AsString(str);\n",
      "3062     PyObject * out = PyString_FromFormat(\"%s%s%s\",\n",
      "3063                         \"CudaNdarray(\",\n",
      "3064                         cstr,\n",
      "3065                         \")\");\n",
      "3066     Py_DECREF(str);\n",
      "3067     Py_DECREF(np_object);\n",
      "3068     #if PY_MAJOR_VERSION >= 3\n",
      "3069     // In Python 3 PyString_FromFormat return a Bytes object\n",
      "3070     PyObject* out2 = PyObject_Str(out);\n",
      "3071     Py_DECREF(out);\n",
      "3072     return out2;\n",
      "3073     #endif\n",
      "3074     return out;\n",
      "3075 }\n",
      "3076 \n",
      "3077 static PyTypeObject CudaNdarrayType =\n",
      "3078 {\n",
      "3079 #if PY_MAJOR_VERSION >= 3\n",
      "3080     PyVarObject_HEAD_INIT(NULL, 0)\n",
      "3081 #else\n",
      "3082     PyObject_HEAD_INIT(NULL)\n",
      "3083     0,                         /*ob_size*/\n",
      "3084 #endif\n",
      "3085     \"CudaNdarray\",             /*tp_name*/\n",
      "3086     sizeof(CudaNdarray),       /*tp_basicsize*/\n",
      "3087     0,                         /*tp_itemsize*/\n",
      "3088     (destructor)CudaNdarray_dealloc, /*tp_dealloc*/\n",
      "3089     0,                         /*tp_print*/\n",
      "3090     0,                         /*tp_getattr*/\n",
      "3091     0,                         /*tp_setattr*/\n",
      "3092     0,                         /*tp_compare*/\n",
      "3093     CudaNdarray_repr,          /*tp_repr*/\n",
      "3094     &CudaNdarrayNumberMethods, /*tp_as_number*/\n",
      "3095     0,                         /*tp_as_sequence*/\n",
      "3096     &CudaNdarrayMappingMethods,/*tp_as_mapping*/\n",
      "3097     0,                         /*tp_hash */\n",
      "3098     0,                         /*tp_call*/\n",
      "3099     0,                         /*tp_str*/\n",
      "3100     0,                         /*tp_getattro*/\n",
      "3101     0,                         /*tp_setattro*/\n",
      "3102     0,                         /*tp_as_buffer*/\n",
      "3103 #if PY_MAJOR_VERSION >= 3\n",
      "3104     // Py_TPFLAGS_CHECKTYPES is always true and was removed in Python 3.\n",
      "3105     Py_TPFLAGS_DEFAULT | Py_TPFLAGS_BASETYPE, /*tp_flags*/\n",
      "3106 #else\n",
      "3107     Py_TPFLAGS_DEFAULT | Py_TPFLAGS_BASETYPE | Py_TPFLAGS_CHECKTYPES, /*tp_flags*/\n",
      "3108 #endif\n",
      "3109     \"CudaNdarray objects\",     /* tp_doc */\n",
      "3110     0,                         /* tp_traverse */\n",
      "3111     0,                         /* tp_clear */\n",
      "3112     0,                         /* tp_richcompare */\n",
      "3113     0,                         /* tp_weaklistoffset */\n",
      "3114     0,                         /* tp_iter */\n",
      "3115     0,                         /* tp_iternext */\n",
      "3116     CudaNdarray_methods,       /* tp_methods */\n",
      "3117     CudaNdarray_members,       /* tp_members */\n",
      "3118     CudaNdarray_getset,        /* tp_getset */\n",
      "3119     0,                         /* tp_base */\n",
      "3120     0,                         /* tp_dict */\n",
      "3121     0,                         /* tp_descr_get */\n",
      "3122     0,                         /* tp_descr_set */\n",
      "3123     0,                         /* tp_dictoffset */\n",
      "3124     (initproc)CudaNdarray_init,/* tp_init */\n",
      "3125     0,                         /* tp_alloc */\n",
      "3126     CudaNdarray_new,           /* tp_new */\n",
      "3127 };\n",
      "3128 \n",
      "3129 static __global__ void get_gpu_ptr_size(int* dst)\n",
      "3130 {\n",
      "3131     dst[0] = sizeof(float*);\n",
      "3132     dst[1] = sizeof(int);\n",
      "3133 }\n",
      "3134 \n",
      "3135 PyObject *\n",
      "3136 CudaNdarray_ptr_int_size(PyObject* _unused, PyObject* args)\n",
      "3137 {\n",
      "3138     int *gpu_data = (int*)device_malloc(sizeof(int)*2);\n",
      "3139     if(gpu_data == NULL){\n",
      "3140         return NULL;\n",
      "3141     }\n",
      "3142     get_gpu_ptr_size<<<1,1>>>(gpu_data);\n",
      "3143 \n",
      "3144     cudaError_t cudaErr = cudaGetLastError();\n",
      "3145     if (cudaSuccess != cudaErr){\n",
      "3146 \n",
      "3147         device_free(gpu_data);\n",
      "3148         return PyErr_Format(PyExc_RuntimeError,\n",
      "3149                             \"CudaNdarray_ptr_int_size: error when calling the gpu code. (%s)\",\n",
      "3150                             cudaGetErrorString(cudaErr));\n",
      "3151     }\n",
      "3152 \n",
      "3153     // Transfer the result to cpu\n",
      "3154     int gpu_sizes[] = {-1,-1};\n",
      "3155     cublasStatus_t err;\n",
      "3156     err = cublasGetVector(2, sizeof(int), gpu_data, 1, gpu_sizes, 1);\n",
      "3157     device_free(gpu_data);\n",
      "3158 \n",
      "3159     if (CUBLAS_STATUS_SUCCESS != err){\n",
      "3160         PyErr_SetString(PyExc_RuntimeError, \"error copying data to from memory\");\n",
      "3161         return NULL;\n",
      "3162     }\n",
      "3163     return Py_BuildValue(\"iiii\", (int) gpu_sizes[0], (int)sizeof(float*),\n",
      "3164                          (int)sizeof(int), (int) gpu_sizes[1]);\n",
      "3165 }\n",
      "3166 \n",
      "3167 static int cublas_init();\n",
      "3168 static void cublas_shutdown();\n",
      "3169 // Initialize the gpu.\n",
      "3170 // Takes two optional parameters, the device number and if we should use cnmem.\n",
      "3171 // If the device number is provided, it sets that device to be the active device.\n",
      "3172 // If not provided (usually just to test whether the gpu is available at all),\n",
      "3173 // it does not set an active device.\n",
      "3174 // Raises EnvironmentError or ValueError (as appropriate) if the initialization failed.\n",
      "3175 // cnmem is threaded like a bool. If converted to 0, don't use cnmem. Otherwise, use it.\n",
      "3176 PyObject *\n",
      "3177 CudaNdarray_gpu_init(PyObject* _unused, PyObject* args)\n",
      "3178 {\n",
      "3179     int card_nb = 0;\n",
      "3180     int card_number_provided = 1;\n",
      "3181     float cnmem = 0; // Theano flag lib.cnmem\n",
      "3182     // if we're given something wildly invalid, this will throw a TypeError\n",
      "3183     if(!PyArg_ParseTuple(args, \"|if\", &card_nb, &cnmem))\n",
      "3184         return NULL;\n",
      "3185     if(cnmem)\n",
      "3186         g_use_cnmem = true;\n",
      "3187 \n",
      "3188     if(PyTuple_Size(args) == 0) {\n",
      "3189         card_number_provided = 0;\n",
      "3190         card_nb = 0;\n",
      "3191     }\n",
      "3192 \n",
      "3193     int deviceCount;\n",
      "3194     cudaError err = cudaGetDeviceCount(&deviceCount);\n",
      "3195     if(cudaSuccess != err) {\n",
      "3196         return PyErr_Format(PyExc_EnvironmentError,\n",
      "3197                             \"Unable to get the number of gpus available: %s\",\n",
      "3198                             cudaGetErrorString(cudaGetLastError()));\n",
      "3199     }\n",
      "3200 \n",
      "3201     // as soon as the first successful call to a cuda* function is made, a\n",
      "3202     // gpu context has been created\n",
      "3203     g_gpu_context_active = 1;\n",
      "3204 \n",
      "3205     if(deviceCount <= 0) {\n",
      "3206         return PyErr_Format(PyExc_EnvironmentError,\n",
      "3207                             \"Can't use the GPU, no devices support CUDA\");\n",
      "3208     }\n",
      "3209     if(card_number_provided && (card_nb < 0 || card_nb > (deviceCount - 1))) {\n",
      "3210         return PyErr_Format(PyExc_ValueError,\n",
      "3211                             \"Bad device number %d. Only %d devices available.\",\n",
      "3212                             card_nb,\n",
      "3213                             deviceCount);\n",
      "3214     }\n",
      "3215 \n",
      "3216     cudaDeviceProp deviceProp;\n",
      "3217     err = cudaGetDeviceProperties(&deviceProp, card_nb);\n",
      "3218     if(cudaSuccess != err) {\n",
      "3219         return PyErr_Format(PyExc_EnvironmentError,\n",
      "3220                             \"Unable to get properties of gpu %i: %s\",\n",
      "3221                             card_nb,\n",
      "3222                             cudaGetErrorString(cudaGetLastError()));\n",
      "3223     }\n",
      "3224 \n",
      "3225     if(deviceProp.major == 9999 && deviceProp.minor == 9999 ){\n",
      "3226         return PyErr_Format(PyExc_EnvironmentError,\n",
      "3227                             \"There is no device that supports CUDA\");\n",
      "3228     }\n",
      "3229 \n",
      "3230     if(card_number_provided) {\n",
      "3231         err = cudaSetDevice(card_nb);\n",
      "3232         if(cudaSuccess != err) {\n",
      "3233             return PyErr_Format(PyExc_EnvironmentError,\n",
      "3234                                 \"Unable to set device %i: %s\",\n",
      "3235                                 card_nb,\n",
      "3236                                 cudaGetErrorString(cudaGetLastError()));\n",
      "3237         }\n",
      "3238         if (cublas_init() == -1)\n",
      "3239             return NULL;\n",
      "3240     }\n",
      "3241     if(card_number_provided && g_use_cnmem) {\n",
      "3242         size_t mem = 0;\n",
      "3243         if (cnmem > 1)\n",
      "3244             mem = cnmem * 1024 * 1024;\n",
      "3245         else{\n",
      "3246             // Clip to 95% to let memory for the driver.\n",
      "3247             // 98% didn't worked in some cases.\n",
      "3248             if (cnmem > .95){\n",
      "3249                 cnmem = .95;\n",
      "3250             }\n",
      "3251             size_t free = 0, total = 0;\n",
      "3252             cudaError_t err = cudaMemGetInfo(&free, &total);\n",
      "3253             if (err != cudaSuccess){\n",
      "3254                 // Clear the error flag, cudaMemGetInfo doesn't do it.\n",
      "3255                 // Currently this returns the same thing as err, but if in future\n",
      "3256                 // it returns something else I still don't see why we should ignore\n",
      "3257                 // it.  All we want to do here is reset the flag.\n",
      "3258                 cudaGetLastError();\n",
      "3259                 PyErr_Format(PyExc_RuntimeError,\n",
      "3260                              \"Error while getting memory info about the gpu: %s\",\n",
      "3261                              cudaGetErrorString(err));\n",
      "3262                 return NULL;\n",
      "3263             }\n",
      "3264             mem = total * cnmem;\n",
      "3265         }\n",
      "3266         if(initCnmem(card_number_provided, card_nb, mem) == -1){\n",
      "3267             return NULL;\n",
      "3268         }\n",
      "3269     }\n",
      "3270 \n",
      "3271     Py_INCREF(Py_None);\n",
      "3272     return Py_None;\n",
      "3273 }\n",
      "3274 \n",
      "3275 PyObject *\n",
      "3276 CudaNdarray_active_device_number(PyObject* _unused, PyObject* _unused_args) {\n",
      "3277     // NB: No cuda error checking here; keeps things simple, and it's not\n",
      "3278     // really necessary.\n",
      "3279     int currentDevice;\n",
      "3280     cudaGetDevice(&currentDevice);\n",
      "3281     return PyInt_FromLong(currentDevice);\n",
      "3282 }\n",
      "3283 \n",
      "3284 PyObject *\n",
      "3285 CudaNdarray_active_device_name(PyObject* _unused, PyObject* _unused_args) {\n",
      "3286     // NB: No cuda error checking here; keeps things simple, and it's not\n",
      "3287     // really necessary.\n",
      "3288     int currentDevice;\n",
      "3289     cudaGetDevice(&currentDevice);\n",
      "3290 \n",
      "3291     cudaDeviceProp deviceProp;\n",
      "3292     cudaGetDeviceProperties(&deviceProp, currentDevice);\n",
      "3293     return PyString_FromString(deviceProp.name);\n",
      "3294 }\n",
      "3295 \n",
      "3296 PyObject *\n",
      "3297 CudaNdarray_gpu_shutdown(PyObject* _unused, PyObject* _unused_args) {\n",
      "3298     // Don't handle errors here\n",
      "3299     cublas_shutdown();\n",
      "3300     g_gpu_context_active = 0; // context has now been closed down\n",
      "3301     if(g_use_cnmem) {\n",
      "3302         cnmemStatus_t status = cnmemFinalize();\n",
      "3303         if(status != CNMEM_STATUS_SUCCESS) {\n",
      "3304             fprintf(stderr, \"CudaNdarray_gpu_shutdown: cnmemFinalize failed! Reason=%s\\n\",\n",
      "3305                     cnmemGetErrorString(status));\n",
      "3306             if(status == CNMEM_STATUS_CUDA_ERROR) {\n",
      "3307                 fprintf(stderr, \"  Cuda-Reason=%s\\n\",\n",
      "3308                         cudaGetErrorString(cudaGetLastError()));\n",
      "3309             }\n",
      "3310         }\n",
      "3311     }\n",
      "3312 \n",
      "3313     Py_INCREF(Py_None);\n",
      "3314     return Py_None;\n",
      "3315 }\n",
      "3316 \n",
      "3317 /*\n",
      "3318  * This function is tested in theano/misc/test_pycuda_theano_simple.py\n",
      "3319  */\n",
      "3320 PyObject *\n",
      "3321 CudaNdarray_from_gpu_pointer(PyObject* _unused, PyObject* args)\n",
      "3322 {\n",
      "3323     int verbose = 0;\n",
      "3324     PyObject *gpu_ptr = NULL;\n",
      "3325     PyObject *shapes = NULL;\n",
      "3326     PyObject *strides = NULL;\n",
      "3327     PyObject *base = NULL;\n",
      "3328     PyObject *rval = NULL;\n",
      "3329 \n",
      "3330     //args should consist of 3 python objects\n",
      "3331     //The first is the gpu ptr\n",
      "3332     //The second if the shape\n",
      "3333     //The third if the strides\n",
      "3334     if (! PyArg_ParseTuple(args, \"OOOO\", &gpu_ptr, &shapes, &strides, &base))\n",
      "3335         return NULL;\n",
      "3336 \n",
      "3337     if (verbose) printf(\"In CudaNdarray_from_gpu_pointer\\n\");\n",
      "3338     if (!PyLong_Check(gpu_ptr))\n",
      "3339     {\n",
      "3340         PyErr_Format(PyExc_Exception, \"CudaNdarray_from_gpu_pointer: The gpu pointor is not an long\");\n",
      "3341         return NULL;\n",
      "3342     }\n",
      "3343 \n",
      "3344     Py_ssize_t nd =  PyObject_Length(shapes);\n",
      "3345     if (nd < 0)\n",
      "3346     {\n",
      "3347         PyErr_SetString(PyExc_TypeError, \"CudaNdarray_from_gpu_pointer: Couldn't get length of second argument\");\n",
      "3348         return NULL;\n",
      "3349     }\n",
      "3350     Py_ssize_t nd_stride =  PyObject_Length(strides);\n",
      "3351     if (nd_stride < 0)\n",
      "3352     {\n",
      "3353         PyErr_SetString(PyExc_TypeError, \"CudaNdarray_from_gpu_pointer: Couldn't get length of third argument\");\n",
      "3354         return NULL;\n",
      "3355     }\n",
      "3356 \n",
      "3357     if (nd != nd_stride)\n",
      "3358     {\n",
      "3359         PyErr_SetString(PyExc_TypeError, \"CudaNdarray_from_gpu_pointer: We need the same number of shapes and strides\");\n",
      "3360         return NULL;\n",
      "3361     }\n",
      "3362 \n",
      "3363     rval = CudaNdarray_New();\n",
      "3364 \n",
      "3365     if (CudaNdarray_set_nd((CudaNdarray *)rval, nd))\n",
      "3366     {\n",
      "3367         //CudaNdarray_set_nd set the error msg\n",
      "3368         return NULL;\n",
      "3369     }\n",
      "3370     // set gpu pointeur\n",
      "3371     assert(((CudaNdarray *)rval)->data_allocated == 0);\n",
      "3372     if (CudaNdarray_set_device_data((CudaNdarray *)rval, (float *)PyInt_AsLong(gpu_ptr), base))\n",
      "3373     {\n",
      "3374         PyErr_SetString(PyExc_TypeError, \"CudaNdarray_from_gpu_pointer: Error while setting the gpu pointor\");\n",
      "3375         return NULL;\n",
      "3376 \n",
      "3377     }\n",
      "3378 \n",
      "3379     // Set dims and strides\n",
      "3380     for (int i = nd-1; i >= 0; --i)\n",
      "3381     {\n",
      "3382         PyObject * idx = PyLong_FromLong(i);\n",
      "3383         if (idx == NULL)\n",
      "3384         {\n",
      "3385             PyErr_SetString(PyExc_Exception, \"CudaNdarray_from_gpu_pointer: Couldn't make long object to loop over list/tuple\");\n",
      "3386             return NULL;\n",
      "3387         }\n",
      "3388         PyObject* dim_ = PyObject_GetItem(shapes, idx);\n",
      "3389         PyObject* strd_ = PyObject_GetItem(strides, idx);\n",
      "3390         if (!PyInt_Check(dim_))\n",
      "3391         {\n",
      "3392             PyErr_Format(PyExc_Exception, \"CudaNdarray_from_gpu_pointer: shapes[%d] is not an int\", i);\n",
      "3393             return NULL;\n",
      "3394         }\n",
      "3395         if (!PyInt_Check(strd_))\n",
      "3396         {\n",
      "3397             PyErr_Format(PyExc_Exception, \"CudaNdarray_from_gpu_pointer: strides[%d] is not an int\", i);\n",
      "3398             return NULL;\n",
      "3399         }\n",
      "3400         int dim = PyInt_AsLong(dim_);\n",
      "3401         int strd = PyInt_AsLong(strd_);\n",
      "3402         CudaNdarray_set_stride((CudaNdarray *)rval, i, strd);\n",
      "3403         CudaNdarray_set_dim((CudaNdarray *)rval, i, dim);\n",
      "3404         Py_DECREF(idx);\n",
      "3405         Py_DECREF(dim_);\n",
      "3406         Py_DECREF(strd_);\n",
      "3407     }\n",
      "3408     if (verbose) printf(\"CudaNdarray_from_gpu_pointer normal return\\n\");\n",
      "3409     return rval;\n",
      "3410 }\n",
      "3411 \n",
      "3412 PyObject *\n",
      "3413 CudaNdarray_Dot(PyObject* _unused, PyObject* args)\n",
      "3414 {\n",
      "3415     PyObject *l=NULL;\n",
      "3416     PyObject *r=NULL;\n",
      "3417     PyObject * rval = NULL;\n",
      "3418 \n",
      "3419     //args should consist of two python objects (\"OO\")\n",
      "3420     if (! PyArg_ParseTuple(args, \"OO\", &l, &r))\n",
      "3421         return NULL;\n",
      "3422 \n",
      "3423     if (!CudaNdarray_Check(l) || !CudaNdarray_Check(r))\n",
      "3424     {\n",
      "3425         PyErr_SetString(PyExc_TypeError, \"CudaNdarray arguments required \");\n",
      "3426         goto CudaNdarray_dot_fail;\n",
      "3427     }\n",
      "3428     if (((CudaNdarray*)l)->nd != 2)\n",
      "3429     {\n",
      "3430         PyErr_SetString(PyExc_TypeError, \"need 2d CudaNdarray arg for now\");\n",
      "3431         goto CudaNdarray_dot_fail;\n",
      "3432     }\n",
      "3433     if (((CudaNdarray*)r)->nd != 2)\n",
      "3434     {\n",
      "3435         PyErr_SetString(PyExc_TypeError, \"need 2d CudaNdarray arg for now\");\n",
      "3436         goto CudaNdarray_dot_fail;\n",
      "3437     }\n",
      "3438     rval = CudaNdarray_New();\n",
      "3439     if (!rval)\n",
      "3440     {\n",
      "3441         goto CudaNdarray_dot_fail;\n",
      "3442     }\n",
      "3443     int dims[2];\n",
      "3444     dims[0] = CudaNdarray_HOST_DIMS((CudaNdarray*)l)[0];\n",
      "3445     dims[1] = CudaNdarray_HOST_DIMS((CudaNdarray*)r)[1];\n",
      "3446     if (CudaNdarray_alloc_contiguous((CudaNdarray*)rval, 2, dims))\n",
      "3447     {\n",
      "3448         goto CudaNdarray_dot_fail;\n",
      "3449     }\n",
      "3450     if (CudaNdarray_gemm(1.0, (CudaNdarray*)l, (CudaNdarray*)r, 0.0, (CudaNdarray*)rval))\n",
      "3451     {\n",
      "3452         goto CudaNdarray_dot_fail;\n",
      "3453     }\n",
      "3454 \n",
      "3455     return rval;\n",
      "3456 \n",
      "3457     CudaNdarray_dot_fail:\n",
      "3458     Py_XDECREF(rval);\n",
      "3459     return NULL;\n",
      "3460 }\n",
      "3461 \n",
      "3462 static PyObject *\n",
      "3463 filter(PyObject* __unsed_self, PyObject *args) // args = (data, broadcastable, strict, storage)\n",
      "3464 {\n",
      "3465     /*\n",
      "3466      * TODO: DOC what this function should do in the various cases of\n",
      "3467      * What is 'strict' supposed to mean in the context of this function?\n",
      "3468      * What do we do with input that could be interpreted as matching the broadcastable pattern in strict vs. non-strict cases?\n",
      "3469      *\n",
      "3470      */\n",
      "3471     PyObject *py_data=NULL;\n",
      "3472     PyArrayObject * data = NULL;\n",
      "3473     int strict = 0;\n",
      "3474     PyObject * broadcastable=NULL;\n",
      "3475     PyObject * storage=NULL;\n",
      "3476     CudaNdarray * rval=NULL;\n",
      "3477 \n",
      "3478     //Python object references which are provided to the caller are borrowed references\n",
      "3479     if (!PyArg_ParseTuple(args, \"OOiO\", &py_data, &broadcastable, &strict, &storage)) return NULL;\n",
      "3480 \n",
      "3481     if (!PyTuple_Check(broadcastable)){\n",
      "3482         PyErr_SetString(PyExc_TypeError, \"broadcastable arg should be a tuple of int.\");\n",
      "3483         return NULL;\n",
      "3484     }\n",
      "3485     Py_INCREF(py_data);\n",
      "3486     Py_INCREF(broadcastable);\n",
      "3487 \n",
      "3488     CudaNdarray * cnda = (CudaNdarray*)py_data;\n",
      "3489 \n",
      "3490     if (strict || CudaNdarray_Check(py_data))\n",
      "3491     {\n",
      "3492         //TODO: support non-strict \"casting\" from a vt to the broadcastable/type/size that we need.\n",
      "3493         if (!CudaNdarray_Check(py_data))\n",
      "3494         {\n",
      "3495             Py_DECREF(py_data);\n",
      "3496             Py_DECREF(broadcastable);\n",
      "3497             PyErr_SetString(PyExc_TypeError, \"strict mode requires CudaNdarray\");\n",
      "3498             return NULL;\n",
      "3499         }\n",
      "3500         if (cnda->nd != PyTuple_Size(broadcastable))\n",
      "3501         {\n",
      "3502             Py_DECREF(py_data);\n",
      "3503             Py_DECREF(broadcastable);\n",
      "3504             PyErr_Format(PyExc_TypeError, \"Wrong rank: %i vs %li\", cnda->nd, (long)PyTuple_Size(broadcastable));\n",
      "3505             return NULL;\n",
      "3506         }\n",
      "3507         for (int i = 0; i < cnda->nd; ++i)\n",
      "3508         {\n",
      "3509             if ((CudaNdarray_HOST_DIMS(cnda)[i] > 1) && PyInt_AsLong(PyTuple_GetItem(broadcastable, Py_ssize_t(i))))\n",
      "3510             {\n",
      "3511                 PyErr_Format(PyExc_TypeError, \"Non-unit size in broadcastable vt dimension %i\", i);\n",
      "3512                 Py_DECREF(py_data);\n",
      "3513                 Py_DECREF(broadcastable);\n",
      "3514                 return NULL;\n",
      "3515             }else if (CudaNdarray_HOST_DIMS(cnda)[i] == 1 && CudaNdarray_HOST_STRIDES(cnda)[i] != 0){\n",
      "3516                 PyErr_Format(PyExc_TypeError, \"Non-zeros strides(%d) on dimension %d of size 1\",\n",
      "3517                              CudaNdarray_HOST_STRIDES(cnda)[i], i);\n",
      "3518                 Py_DECREF(py_data);\n",
      "3519                 Py_DECREF(broadcastable);\n",
      "3520                 return NULL;\n",
      "3521             }\n",
      "3522         }\n",
      "3523         Py_DECREF(broadcastable);\n",
      "3524         return py_data;\n",
      "3525     }\n",
      "3526     else\n",
      "3527     {\n",
      "3528         data = (PyArrayObject*)PyArray_FromObject(py_data, REAL_TYPENUM, PyTuple_Size(broadcastable), PyTuple_Size(broadcastable));\n",
      "3529         if (!data)\n",
      "3530         {\n",
      "3531             //err message already defined\n",
      "3532             Py_DECREF(py_data);\n",
      "3533             Py_DECREF(broadcastable);\n",
      "3534             return NULL;\n",
      "3535         }\n",
      "3536         for (int i = 0; i < PyArray_NDIM(data); ++i)\n",
      "3537         {\n",
      "3538             if ((PyArray_DIMS(data)[i] > 1) && PyInt_AsLong(PyTuple_GetItem(broadcastable, Py_ssize_t(i))))\n",
      "3539             {\n",
      "3540                 PyErr_Format(PyExc_TypeError, \"Non-unit size in broadcastable dimension %i\", i);\n",
      "3541                 Py_DECREF(data);\n",
      "3542                 Py_DECREF(py_data);\n",
      "3543                 Py_DECREF(broadcastable);\n",
      "3544                 return NULL;\n",
      "3545             }\n",
      "3546         }\n",
      "3547         if (storage && CudaNdarray_Check(storage))\n",
      "3548         {\n",
      "3549             rval = (CudaNdarray*) storage;\n",
      "3550             Py_INCREF(rval);\n",
      "3551         }\n",
      "3552         else\n",
      "3553         {\n",
      "3554             rval = (CudaNdarray*) CudaNdarray_New();\n",
      "3555         }\n",
      "3556         if (rval)\n",
      "3557         {\n",
      "3558             if (CudaNdarray_CopyFromArray(rval, data))\n",
      "3559             {\n",
      "3560                 Py_DECREF(rval);\n",
      "3561                 rval = NULL;\n",
      "3562             }\n",
      "3563         }\n",
      "3564         Py_DECREF(data);\n",
      "3565         Py_DECREF(py_data);\n",
      "3566         Py_DECREF(broadcastable);\n",
      "3567         return (PyObject*)rval;\n",
      "3568     }\n",
      "3569 }\n",
      "3570 \n",
      "3571 //TODO-- CudaNdarray_Dot and CudaNdarray_active_device_name are following different capitalization conventions.\n",
      "3572 //       Pick one and standardize it, this file is already annoying enough to grep through\n",
      "3573 static PyMethodDef module_methods[] = {\n",
      "3574     {\"dimshuffle\", CudaNdarray_Dimshuffle, METH_VARARGS, \"Returns the dimshuffle of a CudaNdarray.\"},\n",
      "3575     {\"dot\", CudaNdarray_Dot, METH_VARARGS, \"Returns the matrix product of two CudaNdarray arguments.\"},\n",
      "3576     {\"gpu_init\", CudaNdarray_gpu_init, METH_VARARGS, \"Select the gpu card to use; also usable to test whether CUDA is available.\"},\n",
      "3577     {\"select_a_gpu\", CudaNdarray_select_a_gpu, METH_NOARGS, \"Call this method if you want to select a GPU before gpu_init call and let the driver choose the GPU.\"},\n",
      "3578     {\"active_device_name\", CudaNdarray_active_device_name, METH_VARARGS, \"Get the name of the active device.\"},\n",
      "3579     {\"active_device_number\", CudaNdarray_active_device_number, METH_VARARGS, \"Get the number of the active device.\"},\n",
      "3580     {\"gpu_shutdown\", CudaNdarray_gpu_shutdown, METH_VARARGS, \"Shut down the gpu.\"},\n",
      "3581     {\"device_properties\", GetDeviceProperties, METH_VARARGS, \"Return a dictionary with the device properties.\"},\n",
      "3582     {\"mem_info\", GetDeviceMemInfo, METH_NOARGS, \"Return a tuple with the free and total memory on the gpu in bytes.\"},\n",
      "3583 #if COMPUTE_GPU_MEM_USED\n",
      "3584     {\"theano_allocated\", GetTheanoAllocInfo, METH_NOARGS, \"Return the size in bytes of memory Theano currently have allocated on the gpu.\"},\n",
      "3585 #endif\n",
      "3586     {\"ptr_int_size\", CudaNdarray_ptr_int_size, METH_VARARGS, \"Return a tuple with the size of gpu pointer, cpu pointer and int in bytes.\"},\n",
      "3587     {\"filter\", filter, METH_VARARGS, \"filter(obj, broadcastable, strict, storage) returns a CudaNdarray initialized to obj if it matches the constraints of broadcastable.  strict=True prevents any numeric casting. If storage is a CudaNdarray it may be overwritten and used as the return value.\"},\n",
      "3588     {\"outstanding_mallocs\", outstanding_mallocs, METH_VARARGS, \"how many more mallocs have been called than free's\"},\n",
      "3589     {\"from_gpu_pointer\", CudaNdarray_from_gpu_pointer, METH_VARARGS, \"Used to create a CudaNdarray from already allocated memory on the gpu.(example by pycuda)\"},\n",
      "3590     {\"synchronize\", CudaNdarray_synchronize, METH_NOARGS, \"Used to synchronize the device\"},\n",
      "3591     {\"cublas_v2\", CudaNdarray_cublasv2, METH_NOARGS,\n",
      "3592      \"Used to know if this version of cuda_ndarray is linked with cublas v2.\"},\n",
      "3593     {NULL, NULL, NULL, NULL}  /* Sentinel */\n",
      "3594 };\n",
      "3595 \n",
      "3596 #define CNDA_MOD_NAME \"cuda_ndarray\"\n",
      "3597 #define CNDA_DOCSTRING \"CUDA implementation of a numpy ndarray-like object.\"\n",
      "3598 \n",
      "3599 #if PY_MAJOR_VERSION == 3\n",
      "3600 static struct PyModuleDef cuda_ndarray_moduledef =\n",
      "3601 {\n",
      "3602     PyModuleDef_HEAD_INIT,\n",
      "3603     CNDA_MOD_NAME,\n",
      "3604     CNDA_DOCSTRING,\n",
      "3605     -1,     /* size of per-interpreter state of the module,\n",
      "3606                or -1 if the module keeps state in global variables. */\n",
      "3607     module_methods\n",
      "3608 };\n",
      "3609 \n",
      "3610 PyMODINIT_FUNC\n",
      "3611 PyInit_cuda_ndarray(void)\n",
      "3612 #else\n",
      "3613 PyMODINIT_FUNC\n",
      "3614 initcuda_ndarray(void)\n",
      "3615 #endif\n",
      "3616 {\n",
      "3617     import_array();\n",
      "3618 \n",
      "3619     PyObject* m;\n",
      "3620 \n",
      "3621     if (PyType_Ready(&CudaNdarrayType) < 0) {\n",
      "3622 #if PY_MAJOR_VERSION == 3\n",
      "3623         return NULL;\n",
      "3624 #else\n",
      "3625         return;\n",
      "3626 #endif\n",
      "3627     }\n",
      "3628 \n",
      "3629 #if PY_MAJOR_VERSION == 3\n",
      "3630     m = PyModule_Create(&cuda_ndarray_moduledef);\n",
      "3631 #else\n",
      "3632     m = Py_InitModule3(CNDA_MOD_NAME, module_methods, CNDA_DOCSTRING);\n",
      "3633 #endif\n",
      "3634 \n",
      "3635     if (m == NULL) {\n",
      "3636 #if PY_MAJOR_VERSION == 3\n",
      "3637         return NULL;\n",
      "3638 #else\n",
      "3639         return;\n",
      "3640 #endif\n",
      "3641     }\n",
      "3642 \n",
      "3643     Py_INCREF(&CudaNdarrayType);\n",
      "3644     PyModule_AddObject(m, \"CudaNdarray\", (PyObject *)&CudaNdarrayType);\n",
      "3645 #if COMPUTE_GPU_MEM_USED\n",
      "3646     for(int i=0;i<TABLE_SIZE;i++){\n",
      "3647         _alloc_size_table[i].ptr=NULL;\n",
      "3648         _alloc_size_table[i].size=0;\n",
      "3649     }\n",
      "3650 #endif\n",
      "3651     //    cublasInit();\n",
      "3652     //if (0&&CUBLAS_STATUS_SUCCESS != cublasGetError())\n",
      "3653     //{\n",
      "3654         //std::cerr << \"WARNING: initcuda_ndarray: error initializing device\\n\";\n",
      "3655     //}\n",
      "3656     if (0) //TODO: is this necessary?\n",
      "3657     {\n",
      "3658         int deviceId = 0; // TODO: what number goes here?\n",
      "3659         cudaSetDevice(deviceId);\n",
      "3660         cudaError_t err = cudaGetLastError();\n",
      "3661         if( cudaSuccess != err)\n",
      "3662         {\n",
      "3663             std::cerr << \"Error in SetDevice:\" << cudaGetErrorString(err) << \"\\n\";\n",
      "3664         }\n",
      "3665     }\n",
      "3666 \n",
      "3667 #if PY_MAJOR_VERSION == 3\n",
      "3668     return m;\n",
      "3669 #endif\n",
      "3670 }\n",
      "3671 \n",
      "3672 \n",
      "3673 //////////////////////////////////////\n",
      "3674 //\n",
      "3675 // C API FOR CudaNdarray\n",
      "3676 //\n",
      "3677 //////////////////////////////////////\n",
      "3678 \n",
      "3679 int\n",
      "3680 CudaNdarray_Check(const PyObject * ob)\n",
      "3681 {\n",
      "3682     //TODO: doesn't work with inheritance\n",
      "3683     return CudaNdarray_CheckExact(ob);\n",
      "3684 }\n",
      "3685 int\n",
      "3686 CudaNdarray_CheckExact(const PyObject * ob)\n",
      "3687 {\n",
      "3688     return ((Py_TYPE(ob) == &CudaNdarrayType) ? 1 : 0);\n",
      "3689 }\n",
      "3690 \n",
      "3691 PyObject *\n",
      "3692 CudaNdarray_New(int nd)\n",
      "3693 {\n",
      "3694     CudaNdarray *self = (CudaNdarray *)CudaNdarrayType.tp_alloc(&CudaNdarrayType, 0);\n",
      "3695     if (self == NULL)\n",
      "3696     {\n",
      "3697         PyErr_SetString(PyExc_RuntimeError, \"CudaNdarray_New failed to allocate self\");\n",
      "3698         return NULL;\n",
      "3699     }\n",
      "3700     CudaNdarray_null_init(self);\n",
      "3701 \n",
      "3702     if (nd == 0)\n",
      "3703     {\n",
      "3704         self->nd = 0;\n",
      "3705     }\n",
      "3706     else if (nd > 0)\n",
      "3707     {\n",
      "3708         if (CudaNdarray_set_nd(self, nd))\n",
      "3709         {\n",
      "3710             Py_DECREF(self);\n",
      "3711             return NULL;\n",
      "3712         }\n",
      "3713     }\n",
      "3714     ++_outstanding_mallocs[1];\n",
      "3715     return (PyObject *)self;\n",
      "3716 }\n",
      "3717 \n",
      "3718 \n",
      "3719 \n",
      "3720 //////////////////////////////\n",
      "3721 //\n",
      "3722 // Published helper functions\n",
      "3723 //\n",
      "3724 //////////////////////////////\n",
      "3725 \n",
      "3726 static int\n",
      "3727 cublas_init()\n",
      "3728 {\n",
      "3729     cublasStatus_t err;\n",
      "3730     err = cublasCreate(&handle);\n",
      "3731     if (CUBLAS_STATUS_SUCCESS != err)\n",
      "3732     {\n",
      "3733         if(CUBLAS_STATUS_NOT_INITIALIZED == err)\n",
      "3734             PyErr_SetString(PyExc_RuntimeError,\n",
      "3735                             \"cublasCreate() returned this error \"\n",
      "3736                             \"'the CUDA Runtime initialization failed'\");\n",
      "3737         else if(CUBLAS_STATUS_ALLOC_FAILED == err)\n",
      "3738             PyErr_SetString(PyExc_RuntimeError,\n",
      "3739                             \"cublasCreate() returned this error \"\n",
      "3740                             \"'the resources could not be allocated'\");\n",
      "3741         else\n",
      "3742             PyErr_SetString(PyExc_RuntimeError,\n",
      "3743                             \"unknow error during returned by cublasCreate()\");\n",
      "3744         return -1;\n",
      "3745     }\n",
      "3746     // Set the default stream as the one to execute on (default)\n",
      "3747     cublasSetStream(handle, NULL);\n",
      "3748     // Pointer to scalars are on the host (also default)\n",
      "3749     cublasSetPointerMode(handle, CUBLAS_POINTER_MODE_HOST);\n",
      "3750 #if CUDA_VERSION >= 5000\n",
      "3751     // atomics can be used in kernels to speed up operations (not default)\n",
      "3752     // This may lead to a slight variance from run to run in some operations\n",
      "3753     cublasSetAtomicsMode(handle, CUBLAS_ATOMICS_ALLOWED);\n",
      "3754 #endif\n",
      "3755     return 0;\n",
      "3756 }\n",
      "3757 \n",
      "3758 static void\n",
      "3759 cublas_shutdown()\n",
      "3760 {\n",
      "3761     if (handle != NULL)\n",
      "3762         cublasDestroy(handle);\n",
      "3763     // No point in handling any errors here\n",
      "3764     handle = NULL;\n",
      "3765 }\n",
      "3766 \n",
      "3767 int\n",
      "3768 CudaNdarray_CopyFromArray(CudaNdarray * self, PyArrayObject*obj)\n",
      "3769 {\n",
      "3770     int err = CudaNdarray_alloc_contiguous(self, PyArray_NDIM(obj),\n",
      "3771                                            PyArray_DIMS(obj));\n",
      "3772     if (err) {\n",
      "3773         return err;\n",
      "3774     }\n",
      "3775 \n",
      "3776     int typenum = PyArray_TYPE(obj);\n",
      "3777     if (typenum != REAL_TYPENUM)\n",
      "3778     {\n",
      "3779         PyErr_SetString(PyExc_TypeError, \"can only copy from float arrays\");\n",
      "3780         return -1;\n",
      "3781     }\n",
      "3782     assert( 4 ==  PyArray_ITEMSIZE(obj));\n",
      "3783     PyArrayObject * py_src = (PyArrayObject *)PyArray_ContiguousFromAny(\n",
      "3784         (PyObject*)obj, typenum, self->nd, self->nd);\n",
      "3785     if (!py_src) {\n",
      "3786         return -1;\n",
      "3787     }\n",
      "3788     npy_intp py_src_size = PyArray_SIZE(py_src);\n",
      "3789     void *py_src_data = PyArray_DATA(py_src);\n",
      "3790     cudaError_t cerr;\n",
      "3791     CNDA_BEGIN_ALLOW_THREADS;\n",
      "3792     cerr = cudaMemcpy(self->devdata, py_src_data,\n",
      "3793                       py_src_size * sizeof(real),\n",
      "3794                       cudaMemcpyHostToDevice);\n",
      "3795     //CNDA_THREAD_SYNC;  // unneeded because cudaMemcpy is blocking anyway\n",
      "3796     CNDA_END_ALLOW_THREADS;\n",
      "3797     if (cudaSuccess != cerr)\n",
      "3798     {\n",
      "3799         PyErr_Format(PyExc_RuntimeError,\n",
      "3800                      \"Cuda error '%s' while copying %lli data element\"\n",
      "3801                      \" to device memory. str ptr=%p. dst ptr=%p\",\n",
      "3802                      cudaGetErrorString(cerr),\n",
      "3803                      (long long)py_src_size,\n",
      "3804                      py_src_data,\n",
      "3805                      self->devdata);\n",
      "3806         Py_DECREF(py_src);\n",
      "3807         return -1;\n",
      "3808     }\n",
      "3809     Py_DECREF(py_src);\n",
      "3810     return 0;\n",
      "3811 }\n",
      "3812 \n",
      "3813 PyObject *\n",
      "3814 CudaNdarray_new_nd(int nd)\n",
      "3815 {\n",
      "3816     CudaNdarray * rval = (CudaNdarray*) CudaNdarray_New();\n",
      "3817     if (!rval || CudaNdarray_set_nd(rval, nd))\n",
      "3818     {\n",
      "3819         Py_XDECREF(rval);\n",
      "3820         rval = NULL;\n",
      "3821     }\n",
      "3822     return (PyObject *) rval;\n",
      "3823 }\n",
      "3824 \n",
      "3825 \n",
      "3826 /**\n",
      "3827  * Initialize 'self' as a view of 'base', with memory storage 'data'\n",
      "3828  */\n",
      "3829 \n",
      "3830 int CudaNdarray_set_device_data(CudaNdarray * self, float * data, PyObject * base)\n",
      "3831 {\n",
      "3832     if (self->data_allocated)\n",
      "3833     {\n",
      "3834         assert(self->devdata);\n",
      "3835         if (device_free(self->devdata))\n",
      "3836         {\n",
      "3837             self->devdata = NULL;\n",
      "3838             self->data_allocated = 0;\n",
      "3839             return -1;\n",
      "3840         }\n",
      "3841     }\n",
      "3842     // Get the original base object (base.base.base...)\n",
      "3843     PyObject * orig_base = base;\n",
      "3844     // base is not always a CudaNdarray. It can be a GpuArray from pycuda, ...\n",
      "3845     while (orig_base && CudaNdarray_Check(orig_base) && ((CudaNdarray*) orig_base)->base)\n",
      "3846     {\n",
      "3847         // base_base is itself a view\n",
      "3848         orig_base = ((CudaNdarray*) orig_base)->base;\n",
      "3849     }\n",
      "3850     //N.B. XDECREF and XINCREF are no-ops for NULL pointers\n",
      "3851     if (self->base != orig_base)\n",
      "3852     {\n",
      "3853         Py_XDECREF(self->base);\n",
      "3854         self->base = orig_base;\n",
      "3855         Py_XINCREF(self->base);\n",
      "3856     }\n",
      "3857     self->data_allocated = 0;\n",
      "3858     self->devdata = data;\n",
      "3859     return 0;\n",
      "3860 }\n",
      "3861 \n",
      "3862 static __global__ void k_copy_1d(const int N, const float * x, const int sx, float * y, const int sy)\n",
      "3863 {\n",
      "3864     for (int i = threadIdx.x + blockIdx.x * blockDim.x; i < N; i += gridDim.x*blockDim.x)\n",
      "3865     {\n",
      "3866         y[i*sy] = x[i*sx];\n",
      "3867     }\n",
      "3868 }\n",
      "3869 \n",
      "3870 // N1 through N4 are the size of y\n",
      "3871 static __global__ void k_copy_4d(const int N1,\n",
      "3872         const int N2, const int N3, const int N4,\n",
      "3873         const float * x, const int sx1, const int sx2, const int sx3,\n",
      "3874         const int sx4,  float * y, const int sy1, const int sy2,\n",
      "3875         const int sy3, const int sy4)\n",
      "3876 {\n",
      "3877     // These must be made int instead of unsigned int due to a bug in nvcc\n",
      "3878     int bx = blockIdx.x;\n",
      "3879     int by = blockIdx.y;\n",
      "3880 \n",
      "3881     for (int i = bx; i < N1; i += gridDim.x)\n",
      "3882     {\n",
      "3883         for (int j = by; j < N2; j += gridDim.y)\n",
      "3884         {\n",
      "3885             for (int k = threadIdx.x; k < N3; k += (int) blockDim.x)\n",
      "3886             {\n",
      "3887                 for (int l = threadIdx.y; l < N4; l += (int) blockDim.y)\n",
      "3888                 {\n",
      "3889                     y[i * sy1 + j * sy2 + k * sy3 + l * sy4] =\n",
      "3890                         x[i * sx1 + j * sx2 + k * sx3 + l * sx4];\n",
      "3891                 }\n",
      "3892             }\n",
      "3893         }\n",
      "3894     }\n",
      "3895 }\n",
      "3896 \n",
      "3897 //copy from other into self\n",
      "3898 int CudaNdarray_CopyFromCudaNdarray(CudaNdarray * self,\n",
      "3899                                     const CudaNdarray * other,\n",
      "3900                                     bool unbroadcast)\n",
      "3901 {\n",
      "3902     int verbose = 0;\n",
      "3903     if (verbose>1) fprintf(stderr, \"CudaNdarray_CopyFromCudaNdarray\\n\");\n",
      "3904 \n",
      "3905     //standard elemwise size checks\n",
      "3906     if (self->nd == -1)\n",
      "3907     {\n",
      "3908         PyErr_SetString(PyExc_TypeError,\n",
      "3909                         \"can't copy into un-initialized CudaNdarray\");\n",
      "3910         return -1;\n",
      "3911     }\n",
      "3912     CudaNdarray * new_other = NULL;\n",
      "3913 \n",
      "3914     if (self->nd < other->nd)\n",
      "3915     {\n",
      "3916         PyErr_Format(PyExc_NotImplementedError,\n",
      "3917             \"CudaNdarray_CopyFromCudaNdarray: The number of dimensions of the \"\n",
      "3918             \"destination needs to be >= the number of dimensions of the \"\n",
      "3919             \"source. Got %d and %d.\", self->nd, other->nd);\n",
      "3920         return -1;\n",
      "3921     }\n",
      "3922     else if (self->nd != other->nd)\n",
      "3923     {\n",
      "3924         new_other = (CudaNdarray *) CudaNdarray_View(other);\n",
      "3925         int added_dims = self->nd - other->nd;\n",
      "3926         int* pattern = (int*) alloca(self->nd * sizeof(int));\n",
      "3927         for(int i = 0; i < added_dims; i++)\n",
      "3928             pattern[i] = -1;\n",
      "3929         for(int i = 0; i < other->nd; i++)\n",
      "3930             pattern[i + added_dims] = i;\n",
      "3931         CudaNdarray_dimshuffle(new_other, self->nd, pattern);\n",
      "3932         other = new_other;\n",
      "3933     }\n",
      "3934     assert(self->nd == other->nd);\n",
      "3935     //standard elemwise dim checks (also compute total size)\n",
      "3936     unsigned int size = 1;\n",
      "3937     unsigned int size_source = 1;\n",
      "3938     for (int i = 0; i< self->nd; ++i)\n",
      "3939     {\n",
      "3940         if ((CudaNdarray_HOST_DIMS(self)[i] != CudaNdarray_HOST_DIMS(other)[i])\n",
      "3941             && (1!=CudaNdarray_HOST_DIMS(other)[i] || !unbroadcast) )\n",
      "3942         {\n",
      "3943           PyErr_Format(PyExc_ValueError,\n",
      "3944                        \"CudaNdarray_CopyFromCudaNdarray:\"\n",
      "3945                        \" need same dimensions for dim %d,\"\n",
      "3946                        \" destination=%d, source=%d\",\n",
      "3947                        i, CudaNdarray_HOST_DIMS(self)[i],\n",
      "3948                        CudaNdarray_HOST_DIMS(other)[i]);\n",
      "3949           Py_XDECREF(new_other);\n",
      "3950           return -1;\n",
      "3951         }\n",
      "3952         size *= (unsigned int) CudaNdarray_HOST_DIMS(self)[i];\n",
      "3953         size_source *= (unsigned int) CudaNdarray_HOST_DIMS(other)[i];\n",
      "3954     }\n",
      "3955     if (0 == size)\n",
      "3956     {\n",
      "3957         Py_XDECREF(new_other);\n",
      "3958         return 0; //nothing to copy, we're done.\n",
      "3959     }\n",
      "3960     if (CudaNdarray_is_c_contiguous(self) &&\n",
      "3961         CudaNdarray_is_c_contiguous(other) &&\n",
      "3962         size == size_source)\n",
      "3963     {\n",
      "3964         if (verbose)\n",
      "3965             fprintf(stderr, \"Copying contiguous vector with cublasScopy\\n\");\n",
      "3966 \n",
      "3967         cublasStatus_t err;\n",
      "3968         err = cublasScopy(handle, size, CudaNdarray_DEV_DATA(other), 1,\n",
      "3969                           CudaNdarray_DEV_DATA(self), 1);\n",
      "3970         CNDA_THREAD_SYNC;\n",
      "3971         Py_XDECREF(new_other);\n",
      "3972         if (CUBLAS_STATUS_SUCCESS != err)\n",
      "3973         {\n",
      "3974             PyErr_SetString(PyExc_RuntimeError, \"Error copying memory\");\n",
      "3975             return -1;\n",
      "3976         }\n",
      "3977         return 0;\n",
      "3978     }\n",
      "3979     //TODO: rewrite these copy operations to be more efficient\n",
      "3980     //      See, for example the transpose example in the cuda_sdk.\n",
      "3981     switch (self->nd)\n",
      "3982     {\n",
      "3983         case 0: // scalar\n",
      "3984             {\n",
      "3985                 // THIS CASE SHOULD NEVER HAPPEN BECAUSE SCALARS ARE ALWAYS C CONTIGUOUS\n",
      "3986                 assert(0);\n",
      "3987             }; break;\n",
      "3988         case 1: // vector\n",
      "3989             {\n",
      "3990                 if (verbose) fprintf(stderr, \"Copying non-contiguous vector\\n\");\n",
      "3991                 if (verbose) fprint_CudaNdarray(stderr, other);\n",
      "3992                 unsigned int n_blocks = std::min(size,\n",
      "3993                                                  (unsigned int)NUM_VECTOR_OP_BLOCKS);\n",
      "3994                 unsigned int n_threads = std::min(ceil_intdiv(size, n_blocks),\n",
      "3995                                                   (unsigned int)NUM_VECTOR_OP_THREADS_PER_BLOCK);\n",
      "3996                 k_copy_1d<<<n_blocks, n_threads>>>(size,\n",
      "3997                                             CudaNdarray_DEV_DATA(other),\n",
      "3998                                             CudaNdarray_HOST_STRIDES(other)[0],\n",
      "3999                                             CudaNdarray_DEV_DATA(self),\n",
      "4000                                             CudaNdarray_HOST_STRIDES(self)[0]);\n",
      "4001                 CNDA_THREAD_SYNC;\n",
      "4002                 cudaError_t err = cudaGetLastError();\n",
      "4003                 if( cudaSuccess != err)\n",
      "4004                 {\n",
      "4005                     PyErr_Format(PyExc_RuntimeError,\n",
      "4006                                  \"Cuda error: %s: %s. (n_blocks=%i,\"\n",
      "4007                                  \" n_threads_per_block=%i)\\n\", \"k_copy_1d\",\n",
      "4008                                  cudaGetErrorString(err), n_blocks, n_threads);\n",
      "4009                     Py_XDECREF(new_other);\n",
      "4010                     return -1;\n",
      "4011                 }\n",
      "4012             }; break;\n",
      "4013         case 4: // 4-tensor\n",
      "4014             {\n",
      "4015                 if (verbose)\n",
      "4016                 {\n",
      "4017                     if (0 != fprint_CudaNdarray(stderr, other))\n",
      "4018                     {\n",
      "4019                         Py_XDECREF(new_other);\n",
      "4020                         return -1;\n",
      "4021                     }\n",
      "4022                 }\n",
      "4023 \n",
      "4024                 // The blocks implement the looping over the first two axes so\n",
      "4025                 // this needs to be (N1, N2)\n",
      "4026                 dim3 n_blocks( std::min(CudaNdarray_HOST_DIMS(self)[0],\n",
      "4027                                         NUM_VECTOR_OP_BLOCKS),\n",
      "4028                                std::min(CudaNdarray_HOST_DIMS(self)[1],\n",
      "4029                                         NUM_VECTOR_OP_BLOCKS));\n",
      "4030                 // For the threads, just make as many as possible\n",
      "4031                 dim3 n_threads( std::min( (unsigned int) CudaNdarray_HOST_DIMS(self)[2],\n",
      "4032                                  (unsigned int) NUM_VECTOR_OP_THREADS_PER_BLOCK),\n",
      "4033                                 std::min( (unsigned int) CudaNdarray_HOST_DIMS(self)[3],\n",
      "4034                                     (unsigned int) NUM_VECTOR_OP_THREADS_PER_BLOCK));\n",
      "4035 \n",
      "4036                 n_threads.x = std::min( (unsigned int) 32, (unsigned int) n_threads.x);\n",
      "4037                 n_threads.y = std::min( n_threads.y, NUM_VECTOR_OP_THREADS_PER_BLOCK / n_threads.x);\n",
      "4038 \n",
      "4039                 k_copy_4d<<<n_blocks, n_threads>>>(\n",
      "4040                                             // size of y\n",
      "4041                                             (unsigned int) CudaNdarray_HOST_DIMS(self)[0], // N1\n",
      "4042                                             (unsigned int) CudaNdarray_HOST_DIMS(self)[1], // N2\n",
      "4043                                             (unsigned int) CudaNdarray_HOST_DIMS(self)[2], // N3\n",
      "4044                                             (unsigned int) CudaNdarray_HOST_DIMS(self)[3], // N4\n",
      "4045                                             CudaNdarray_DEV_DATA(other), // x\n",
      "4046                                             // x strides\n",
      "4047                                             CudaNdarray_HOST_STRIDES(other)[0],\n",
      "4048                                             CudaNdarray_HOST_STRIDES(other)[1],\n",
      "4049                                             CudaNdarray_HOST_STRIDES(other)[2],\n",
      "4050                                             CudaNdarray_HOST_STRIDES(other)[3],\n",
      "4051                                             CudaNdarray_DEV_DATA(self), // y\n",
      "4052                                             // y strides\n",
      "4053                                             CudaNdarray_HOST_STRIDES(self)[0],\n",
      "4054                                             CudaNdarray_HOST_STRIDES(self)[1],\n",
      "4055                                             CudaNdarray_HOST_STRIDES(self)[2],\n",
      "4056                                             CudaNdarray_HOST_STRIDES(self)[3]\n",
      "4057                                             );\n",
      "4058                 CNDA_THREAD_SYNC;\n",
      "4059                 cudaError_t err = cudaGetLastError();\n",
      "4060                 if( cudaSuccess != err)\n",
      "4061                 {\n",
      "4062                     PyErr_Format(PyExc_RuntimeError,\n",
      "4063                                  \"Cuda error: %s: %s.\",\n",
      "4064                                  \"k_copy_4d\",\n",
      "4065                                  cudaGetErrorString(err));\n",
      "4066                     Py_XDECREF(new_other);\n",
      "4067                     return -1;\n",
      "4068                 }\n",
      "4069             }; break;\n",
      "4070         default:\n",
      "4071             {\n",
      "4072                 cudaError_t err = cudaGetLastError();\n",
      "4073                 if(cudaSuccess != err){\n",
      "4074                     PyErr_Format(PyExc_RuntimeError,\n",
      "4075                                  \"Unexpected Cuda error: %s: %s\\n\",\n",
      "4076                                  \"CudaNdarray_CopyFromCudaNdarray\",\n",
      "4077                                  cudaGetErrorString(err));\n",
      "4078                     Py_XDECREF(new_other);\n",
      "4079                     return -1;\n",
      "4080                 }\n",
      "4081 \n",
      "4082                 if (verbose)\n",
      "4083                     fprintf(stderr,\n",
      "4084                             \"Copying with default version unbroadcast=%d\\n\",\n",
      "4085                             unbroadcast);\n",
      "4086                 // call worker routine\n",
      "4087                 unsigned int threads_per_block = std::min(size,\n",
      "4088                                                           (unsigned int)NUM_VECTOR_OP_THREADS_PER_BLOCK);\n",
      "4089                 unsigned int n_blocks = std::min(ceil_intdiv(size, threads_per_block),\n",
      "4090                                                  (unsigned int)NUM_VECTOR_OP_BLOCKS);\n",
      "4091                 const CudaNdarray * cuda_dims = other;\n",
      "4092                 if(unbroadcast)\n",
      "4093                     cuda_dims = self;\n",
      "4094                 //copy from other into self\n",
      "4095                 k_elemwise_unary_rowmajor_copy<<<n_blocks, threads_per_block>>>(\n",
      "4096                         size,\n",
      "4097                         (unsigned int)other->nd,\n",
      "4098                         (const int *)CudaNdarray_DEV_DIMS(cuda_dims),\n",
      "4099                         (const float*)CudaNdarray_DEV_DATA(other),\n",
      "4100                         (const int *)CudaNdarray_DEV_STRIDES(other),\n",
      "4101                         CudaNdarray_DEV_DATA(self),\n",
      "4102                         (const int *)CudaNdarray_DEV_STRIDES(self));\n",
      "4103                 CNDA_THREAD_SYNC;\n",
      "4104                 err = cudaGetLastError();\n",
      "4105                 if(verbose>1)\n",
      "4106                     fprintf(stderr,\n",
      "4107                             \"INFO k_elemwise_unary_rowmaj (n_blocks=%i,\"\n",
      "4108                             \" n_threads_per_block=%i)\\n\",\n",
      "4109                             n_blocks, threads_per_block);\n",
      "4110                 if( cudaSuccess != err)\n",
      "4111                 {\n",
      "4112                     //fprint_CudaNdarray(stderr, self);\n",
      "4113                     //fprint_CudaNdarray(stderr, other);\n",
      "4114                     PyErr_Format(PyExc_RuntimeError,\n",
      "4115                                  \"Cuda error: %s: %s. (n_blocks=%i,\"\n",
      "4116                                  \" n_threads_per_block=%i)\\n\",\n",
      "4117                                  \"k_elemwise_unary_rowmajor_copy\",\n",
      "4118                                  cudaGetErrorString(err), n_blocks,\n",
      "4119                                  threads_per_block);\n",
      "4120                     Py_XDECREF(new_other);\n",
      "4121                     return -1;\n",
      "4122                 }\n",
      "4123             }\n",
      "4124     };\n",
      "4125     Py_XDECREF(new_other);\n",
      "4126     return 0;\n",
      "4127 }\n",
      "4128 \n",
      "4129 int CudaNdarray_gemm(float alpha, const CudaNdarray * A, const CudaNdarray * B, float beta, CudaNdarray * C)\n",
      "4130 {\n",
      "4131     if (A->nd != 2)\n",
      "4132     {\n",
      "4133         PyErr_SetString(PyExc_ValueError, \"non-matrix arg A to gemm\");\n",
      "4134         return -1;\n",
      "4135     }\n",
      "4136     if (B->nd != 2)\n",
      "4137     {\n",
      "4138         PyErr_SetString(PyExc_ValueError, \"non-matrix arg B to gemm\");\n",
      "4139         return -1;\n",
      "4140     }\n",
      "4141     if (C->nd != 2)\n",
      "4142     {\n",
      "4143         PyErr_SetString(PyExc_ValueError, \"non-matrix arg C to gemm\");\n",
      "4144         return -1;\n",
      "4145     }\n",
      "4146 \n",
      "4147     // We must allow dimensions to be zeros.\n",
      "4148     if ((CudaNdarray_HOST_DIMS(A)[1] != CudaNdarray_HOST_DIMS(B)[0])\n",
      "4149             || (CudaNdarray_HOST_DIMS(A)[0] != CudaNdarray_HOST_DIMS(C)[0])\n",
      "4150             || (CudaNdarray_HOST_DIMS(B)[1] != CudaNdarray_HOST_DIMS(C)[1]))\n",
      "4151     {\n",
      "4152         PyErr_Format(PyExc_ValueError, \"dimension mismatch in args to gemm (%i,%i)x(%i,%i)->(%i,%i)\",\n",
      "4153                 CudaNdarray_HOST_DIMS(A)[0],\n",
      "4154                 CudaNdarray_HOST_DIMS(A)[1],\n",
      "4155                 CudaNdarray_HOST_DIMS(B)[0],\n",
      "4156                 CudaNdarray_HOST_DIMS(B)[1],\n",
      "4157                 CudaNdarray_HOST_DIMS(C)[0],\n",
      "4158                 CudaNdarray_HOST_DIMS(C)[1]);\n",
      "4159         return -1;\n",
      "4160     }\n",
      "4161 \n",
      "4162     // If matrix A or B has non-unit size and non-unit stride in both\n",
      "4163     // dimensions, we can make a copy.\n",
      "4164     CudaNdarray * A_new = NULL;\n",
      "4165     CudaNdarray * B_new = NULL;\n",
      "4166     if (((CudaNdarray_HOST_DIMS(A)[0] > 1)\n",
      "4167          && (CudaNdarray_HOST_STRIDES(A)[0] != 1)\n",
      "4168          && (CudaNdarray_HOST_DIMS(A)[1] > 1)\n",
      "4169          && (CudaNdarray_HOST_STRIDES(A)[1] != 1))\n",
      "4170         || (CudaNdarray_HOST_STRIDES(A)[0] < 0)\n",
      "4171         || (CudaNdarray_HOST_STRIDES(A)[1] < 0))\n",
      "4172     {\n",
      "4173         A_new = (CudaNdarray*) CudaNdarray_Copy(A);\n",
      "4174         if (!A_new)\n",
      "4175             return -1;\n",
      "4176         A = A_new;\n",
      "4177     }\n",
      "4178 \n",
      "4179     if (((CudaNdarray_HOST_DIMS(B)[0] > 1)\n",
      "4180          && (CudaNdarray_HOST_STRIDES(B)[0] != 1)\n",
      "4181          && (CudaNdarray_HOST_DIMS(B)[1] > 1)\n",
      "4182          && (CudaNdarray_HOST_STRIDES(B)[1] != 1))\n",
      "4183         || (CudaNdarray_HOST_STRIDES(B)[0] < 0)\n",
      "4184         || (CudaNdarray_HOST_STRIDES(B)[1] < 0))\n",
      "4185     {\n",
      "4186         B_new = (CudaNdarray*) CudaNdarray_Copy(B);\n",
      "4187         if (!B_new)\n",
      "4188         {\n",
      "4189             // If A_new is NULL, meaning A was not copied nothing happens\n",
      "4190             Py_XDECREF(A_new);\n",
      "4191             return -1;\n",
      "4192         }\n",
      "4193         B = B_new;\n",
      "4194     }\n",
      "4195 \n",
      "4196     // If matrix C has non-unit size and non-unit stride in both\n",
      "4197     // dimensions, or negative strides, we can't operate. We cannot copy\n",
      "4198     // C either, because the calling code will expect the result to be\n",
      "4199     // in the original C container.\n",
      "4200     if (((CudaNdarray_HOST_DIMS(C)[0] > 1)\n",
      "4201          && (CudaNdarray_HOST_STRIDES(C)[0] != 1)\n",
      "4202          && (CudaNdarray_HOST_DIMS(C)[1] > 1)\n",
      "4203          && (CudaNdarray_HOST_STRIDES(C)[1] != 1))\n",
      "4204         || (CudaNdarray_HOST_STRIDES(C)[0] < 0)\n",
      "4205         || (CudaNdarray_HOST_STRIDES(C)[1] < 0))\n",
      "4206     {\n",
      "4207         PyErr_Format(PyExc_AssertionError,\n",
      "4208                      \"non-unit or negative stride in gemm arg C (%i,%i) of shape (%i,%i)\",\n",
      "4209                      CudaNdarray_HOST_STRIDES(C)[0],\n",
      "4210                      CudaNdarray_HOST_STRIDES(C)[1],\n",
      "4211                      CudaNdarray_HOST_DIMS(C)[0],\n",
      "4212                      CudaNdarray_HOST_DIMS(C)[1]);\n",
      "4213         Py_XDECREF(A_new);\n",
      "4214         Py_XDECREF(B_new);\n",
      "4215         return -1;\n",
      "4216     }\n",
      "4217 \n",
      "4218     // the unit integer is divided logically into three fields of 4 bits\n",
      "4219     // the lowermost 4 bits encode the stride pattern of the output\n",
      "4220     // the next higher 4 bits encode the B variable (or y)\n",
      "4221     // the next higher 4 bits encode the C variable (or x)\n",
      "4222     //\n",
      "4223     // the stride pattern for each input is encoded as 0 for unit stride from col to col (Row major)\n",
      "4224     //                                                 1 for unit stride from row to row (Col major)\n",
      "4225 \n",
      "4226     // a stride of 0 implies a dimension of 1 - so we can actually define\n",
      "4227     // a stride of 0 as a 'unit' stride because gemm will never use it.\n",
      "4228     // If a dimension is 0, its stride will not be used either, so we can\n",
      "4229     // consider it a 'unit' stride too.\n",
      "4230     int unit = 0;\n",
      "4231     if (CudaNdarray_HOST_STRIDES(A)[1] == 1 || CudaNdarray_HOST_DIMS(A)[1] <= 1) {\n",
      "4232         unit |= (0x0 << 8);\n",
      "4233     } else if (CudaNdarray_HOST_STRIDES(A)[0] == 1 || CudaNdarray_HOST_DIMS(A)[0] <= 1) {\n",
      "4234         unit |= (0x1 << 8);\n",
      "4235     } else {\n",
      "4236         unit |= (0x2 << 8);\n",
      "4237     }\n",
      "4238     if (CudaNdarray_HOST_STRIDES(B)[1] == 1 || CudaNdarray_HOST_DIMS(B)[1] <= 1) {\n",
      "4239         unit |= (0x0 << 4);\n",
      "4240     } else if (CudaNdarray_HOST_STRIDES(B)[0] == 1 || CudaNdarray_HOST_DIMS(B)[0] <= 1) {\n",
      "4241         unit |= (0x1 << 4);\n",
      "4242     } else {\n",
      "4243         unit |= (0x2 << 4);\n",
      "4244     }\n",
      "4245     if (CudaNdarray_HOST_STRIDES(C)[1] == 1 || CudaNdarray_HOST_DIMS(C)[1] <= 1) {\n",
      "4246         unit |= (0x0 << 0);\n",
      "4247     } else if (CudaNdarray_HOST_STRIDES(C)[0] == 1 || CudaNdarray_HOST_DIMS(C)[0] <= 1) {\n",
      "4248         unit |= (0x1 << 0);\n",
      "4249     } else {\n",
      "4250         unit |= (0x2 << 0);\n",
      "4251     }\n",
      "4252 \n",
      "4253     /* create appropriate strides for malformed matrices that are row or column\n",
      "4254      * vectors\n",
      "4255      */\n",
      "4256     int sa_0 = (CudaNdarray_HOST_DIMS(A)[0] > 1) ? CudaNdarray_HOST_STRIDES(A)[0] : CudaNdarray_HOST_DIMS(A)[1];\n",
      "4257     int sa_1 = (CudaNdarray_HOST_DIMS(A)[1] > 1) ? CudaNdarray_HOST_STRIDES(A)[1] : CudaNdarray_HOST_DIMS(A)[0];\n",
      "4258     int sb_0 = (CudaNdarray_HOST_DIMS(B)[0] > 1) ? CudaNdarray_HOST_STRIDES(B)[0] : CudaNdarray_HOST_DIMS(B)[1];\n",
      "4259     int sb_1 = (CudaNdarray_HOST_DIMS(B)[1] > 1) ? CudaNdarray_HOST_STRIDES(B)[1] : CudaNdarray_HOST_DIMS(B)[0];\n",
      "4260     int sc_0 = (CudaNdarray_HOST_DIMS(C)[0] > 1) ? CudaNdarray_HOST_STRIDES(C)[0] : CudaNdarray_HOST_DIMS(C)[1];\n",
      "4261     int sc_1 = (CudaNdarray_HOST_DIMS(C)[1] > 1) ? CudaNdarray_HOST_STRIDES(C)[1] : CudaNdarray_HOST_DIMS(C)[0];\n",
      "4262 \n",
      "4263     float* a = CudaNdarray_DEV_DATA(A);\n",
      "4264     float* b = CudaNdarray_DEV_DATA(B);\n",
      "4265     float* c = CudaNdarray_DEV_DATA(C);\n",
      "4266     cublasOperation_t N = CUBLAS_OP_N;\n",
      "4267     cublasOperation_t T = CUBLAS_OP_T;\n",
      "4268     //std::cerr << (unit/256) MOD 16 << (unit / 16) MOD 16 << unit MOD 16<< '\\\\n';\n",
      "4269     // There should be no negative stride at that point\n",
      "4270 #define CHK_STRIDE_SGEMM(T0, T1, D0, D1, D2, a, x, sx, y, sy, b, z, sz) \\\n",
      "4271     if (sx == 0){sx = 1;}\\\n",
      "4272     if (sy == 0){sy = 1;}\\\n",
      "4273     if (sz == 0){sz = 1;}\\\n",
      "4274     if ((sx > 0) && (sy > 0) && (sz > 0)) { \\\n",
      "4275         err = cublasSgemm(handle, T0, T1, D0, D1, D2, &a, x, sx, y, sy, &b, z, sz); \\\n",
      "4276     } else { \\\n",
      "4277         PyErr_SetString(PyExc_AssertionError, \"negative stride to sGemm\");\\\n",
      "4278         Py_XDECREF(A_new);\\\n",
      "4279         Py_XDECREF(B_new);\\\n",
      "4280         return -1; \\\n",
      "4281     }\n",
      "4282 \n",
      "4283     cublasStatus_t err;\n",
      "4284     switch(unit)\n",
      "4285     {\n",
      "4286         case 0x000: CHK_STRIDE_SGEMM(N, N, CudaNdarray_HOST_DIMS(C)[1], CudaNdarray_HOST_DIMS(C)[0], CudaNdarray_HOST_DIMS(A)[1], alpha, b, sb_0, a, sa_0, beta, c, sc_0); break;\n",
      "4287         case 0x100: CHK_STRIDE_SGEMM(N, T, CudaNdarray_HOST_DIMS(C)[1], CudaNdarray_HOST_DIMS(C)[0], CudaNdarray_HOST_DIMS(A)[1], alpha, b, sb_0, a, sa_1, beta, c, sc_0); break;\n",
      "4288         case 0x010: CHK_STRIDE_SGEMM(T, N, CudaNdarray_HOST_DIMS(C)[1], CudaNdarray_HOST_DIMS(C)[0], CudaNdarray_HOST_DIMS(A)[1], alpha, b, sb_1, a, sa_0, beta, c, sc_0); break;\n",
      "4289         case 0x110: CHK_STRIDE_SGEMM(T, T, CudaNdarray_HOST_DIMS(C)[1], CudaNdarray_HOST_DIMS(C)[0], CudaNdarray_HOST_DIMS(A)[1], alpha, b, sb_1, a, sa_1, beta, c, sc_0); break;\n",
      "4290         case 0x001: CHK_STRIDE_SGEMM(T, T, CudaNdarray_HOST_DIMS(C)[0], CudaNdarray_HOST_DIMS(C)[1], CudaNdarray_HOST_DIMS(A)[1], alpha, a, sa_0, b, sb_0, beta, c, sc_1); break;\n",
      "4291         case 0x101: CHK_STRIDE_SGEMM(N, T, CudaNdarray_HOST_DIMS(C)[0], CudaNdarray_HOST_DIMS(C)[1], CudaNdarray_HOST_DIMS(A)[1], alpha, a, sa_1, b, sb_0, beta, c, sc_1); break;\n",
      "4292         case 0x011: CHK_STRIDE_SGEMM(T, N, CudaNdarray_HOST_DIMS(C)[0], CudaNdarray_HOST_DIMS(C)[1], CudaNdarray_HOST_DIMS(A)[1], alpha, a, sa_0, b, sb_1, beta, c, sc_1); break;\n",
      "4293         case 0x111: CHK_STRIDE_SGEMM(N, N, CudaNdarray_HOST_DIMS(C)[0], CudaNdarray_HOST_DIMS(C)[1], CudaNdarray_HOST_DIMS(A)[1], alpha, a, sa_1, b, sb_1, beta, c, sc_1); break;\n",
      "4294         default: PyErr_Format(PyExc_ValueError, \"some matrix has no unit stride (unit=%x)\", unit);\n",
      "4295                  return -1;\n",
      "4296     };\n",
      "4297     CNDA_THREAD_SYNC;\n",
      "4298     Py_XDECREF(A_new);\n",
      "4299     Py_XDECREF(B_new);\n",
      "4300 \n",
      "4301     if (CUBLAS_STATUS_SUCCESS != err)\n",
      "4302     {\n",
      "4303         PyErr_Format(PyExc_RuntimeError,\n",
      "4304                      \"cublasSgemm failed (%i) %s\\n\"\n",
      "4305                      \" unit=%x N=%d, c.dims=[%d %d], a.dim=[%d %d], alpha=%f, beta=%f, a=%p, b=%p, c=%p\"\n",
      "4306                      \" sa_0=%d, sa_1=%d, sb_0=%d, sb_1=%d, sc_0=%d, sc_1=%d\",\n",
      "4307                      err,  cublasGetErrorString(err),\n",
      "4308                      unit, N,\n",
      "4309                      CudaNdarray_HOST_DIMS(C)[0],\n",
      "4310                      CudaNdarray_HOST_DIMS(C)[1],\n",
      "4311                      CudaNdarray_HOST_DIMS(A)[0], CudaNdarray_HOST_DIMS(A)[1],\n",
      "4312                      alpha, beta, a, b, c, sa_0, sa_1, sb_0, sb_1, sc_0, sc_1);\n",
      "4313 \n",
      "4314         return -1;\n",
      "4315     }\n",
      "4316     return 0;\n",
      "4317 }\n",
      "4318 \n",
      "4319 int CudaNdarray_sgemv(float alpha, const CudaNdarray * A, const CudaNdarray * B, float beta, CudaNdarray * C)\n",
      "4320 {\n",
      "4321     /**\n",
      "4322     * C <- alpha A B + beta C\n",
      "4323     *    A : matrix\n",
      "4324     *    B, C: vector\n",
      "4325     *    alpha, beta: scalars\n",
      "4326     */\n",
      "4327     if (A->nd != 2) { PyErr_SetString(PyExc_ValueError, \"non-matrix arg to gemv\"); return -1; }\n",
      "4328     if (B->nd != 1) { PyErr_SetString(PyExc_ValueError, \"non-vector arg to gemv\"); return -1; }\n",
      "4329     if (C->nd != 1) { PyErr_SetString(PyExc_ValueError, \"non-vector arg to gemv\"); return -1; }\n",
      "4330 \n",
      "4331     // We must allow dimensions to be zeros.\n",
      "4332     if ((CudaNdarray_HOST_DIMS(A)[1] != CudaNdarray_HOST_DIMS(B)[0])\n",
      "4333             || (CudaNdarray_HOST_DIMS(A)[0] != CudaNdarray_HOST_DIMS(C)[0]))\n",
      "4334     {\n",
      "4335         PyErr_Format(PyExc_ValueError, \"dimension mismatch in args to gemv (%i,%i)x(%i)->(%i)\",\n",
      "4336                 CudaNdarray_HOST_DIMS(A)[0],\n",
      "4337                 CudaNdarray_HOST_DIMS(A)[1],\n",
      "4338                 CudaNdarray_HOST_DIMS(B)[0],\n",
      "4339                 CudaNdarray_HOST_DIMS(C)[0]);\n",
      "4340         return -1;\n",
      "4341     }\n",
      "4342 \n",
      "4343     // If matrix A has non-unit size and non-unit stride in both\n",
      "4344     // dimensions, or negative strides, we cannot operate, but we can\n",
      "4345     // make a copy.\n",
      "4346     CudaNdarray * A_new = NULL;\n",
      "4347     CudaNdarray * B_new = NULL;\n",
      "4348     if (((CudaNdarray_HOST_DIMS(A)[0] > 1)\n",
      "4349          && (CudaNdarray_HOST_STRIDES(A)[0] != 1)\n",
      "4350          && (CudaNdarray_HOST_DIMS(A)[1] > 1)\n",
      "4351          && (CudaNdarray_HOST_STRIDES(A)[1] != 1))\n",
      "4352         || (CudaNdarray_HOST_STRIDES(A)[0] < 0)\n",
      "4353         || (CudaNdarray_HOST_STRIDES(A)[1] < 0))\n",
      "4354     {\n",
      "4355         A_new = (CudaNdarray*) CudaNdarray_Copy(A);\n",
      "4356         if (!A_new)\n",
      "4357             return -1;\n",
      "4358         A = A_new;\n",
      "4359     }\n",
      "4360 \n",
      "4361     // If vector B as a negative stride, we also have to make a copy.\n",
      "4362     if (CudaNdarray_HOST_STRIDES(B)[0] < 0)\n",
      "4363     {\n",
      "4364         B_new = (CudaNdarray*) CudaNdarray_Copy(B);\n",
      "4365         if (!B_new)\n",
      "4366         {\n",
      "4367             // If A was not copied, A_new is NULL, and Py_XDECREF does not\n",
      "4368             // do anything\n",
      "4369             Py_XDECREF(A_new);\n",
      "4370             return -1;\n",
      "4371         }\n",
      "4372         B = B_new;\n",
      "4373     }\n",
      "4374 \n",
      "4375     // cudablas does not handle negative strides as expected\n",
      "4376     if (   (CudaNdarray_HOST_STRIDES(A)[0] < 0)\n",
      "4377         || (CudaNdarray_HOST_STRIDES(A)[1] < 0))\n",
      "4378     {\n",
      "4379         PyErr_Format(PyExc_ValueError, \"illegal strides in args to gemv (%i,%i)\",\n",
      "4380                 CudaNdarray_HOST_STRIDES(A)[0],\n",
      "4381                 CudaNdarray_HOST_STRIDES(A)[1]);\n",
      "4382         Py_XDECREF(A_new);\n",
      "4383         Py_XDECREF(B_new);\n",
      "4384         return -1;\n",
      "4385     }\n",
      "4386 \n",
      "4387     /* create appropriate strides for malformed matrices that are row or column\n",
      "4388      * vectors\n",
      "4389      */\n",
      "4390     int sa_0 = (CudaNdarray_HOST_DIMS(A)[0] > 1) ? CudaNdarray_HOST_STRIDES(A)[0] : CudaNdarray_HOST_DIMS(A)[1];\n",
      "4391     int sa_1 = (CudaNdarray_HOST_DIMS(A)[1] > 1) ? CudaNdarray_HOST_STRIDES(A)[1] : CudaNdarray_HOST_DIMS(A)[0];\n",
      "4392     int sb_0 = (CudaNdarray_HOST_DIMS(B)[0] > 1) ? CudaNdarray_HOST_STRIDES(B)[0] : 1;\n",
      "4393     int sc_0 = (CudaNdarray_HOST_DIMS(C)[0] > 1) ? CudaNdarray_HOST_STRIDES(C)[0] : 1;\n",
      "4394 \n",
      "4395     if (sa_0 == 0) sa_0 = 1;\n",
      "4396     if (sa_1 == 0) sa_1 = 1;\n",
      "4397 \n",
      "4398     int used_dot = 0;\n",
      "4399 \n",
      "4400     // This is important because we can end up not calling Sgemv at all\n",
      "4401     cublasStatus_t err = CUBLAS_STATUS_SUCCESS;\n",
      "4402     if (CudaNdarray_SIZE(C)) {\n",
      "4403         // A is row vector & alpha==1 & beta==0 -> use cublasSdot\n",
      "4404         if (CudaNdarray_HOST_DIMS(A)[0] == 1 && alpha==1.f && beta==0.f) {\n",
      "4405             //replace this with custom inner product kernel with alpha and beta parameter?\n",
      "4406             cublasPointerMode_t pmode;\n",
      "4407             //set pointer mode to make sure cublas not storing on host pointer\n",
      "4408             cublasGetPointerMode(handle, &pmode);\n",
      "4409             cublasSetPointerMode(handle, CUBLAS_POINTER_MODE_DEVICE);\n",
      "4410             err = cublasSdot(\n",
      "4411                     handle, CudaNdarray_HOST_DIMS(A)[1],\n",
      "4412                     CudaNdarray_DEV_DATA(A), sa_1,\n",
      "4413                     CudaNdarray_DEV_DATA(B), sb_0,\n",
      "4414                     CudaNdarray_DEV_DATA(C));\n",
      "4415             cublasSetPointerMode(handle, pmode);\n",
      "4416             used_dot = 1;\n",
      "4417         }\n",
      "4418         // A is row-contiguous | row vector\n",
      "4419         else if ((CudaNdarray_HOST_DIMS(A)[0] <= 1)\n",
      "4420             || ((CudaNdarray_HOST_STRIDES(A)[0] == 1)\n",
      "4421                 && (CudaNdarray_HOST_STRIDES(A)[1] > 0)))\n",
      "4422         {\n",
      "4423             err = cublasSgemv(handle, CUBLAS_OP_N,\n",
      "4424                     CudaNdarray_HOST_DIMS(A)[0], CudaNdarray_HOST_DIMS(A)[1],\n",
      "4425                     &alpha,\n",
      "4426                     CudaNdarray_DEV_DATA(A), sa_1,\n",
      "4427                     CudaNdarray_DEV_DATA(B), sb_0,\n",
      "4428                     &beta,\n",
      "4429                     CudaNdarray_DEV_DATA(C), sc_0);\n",
      "4430         }\n",
      "4431         // A is column-contiguous | column vector\n",
      "4432         else if ((CudaNdarray_HOST_DIMS(A)[1] <= 1)\n",
      "4433                 || ((CudaNdarray_HOST_STRIDES(A)[1] == 1)\n",
      "4434                     && (CudaNdarray_HOST_STRIDES(A)[0] > 0)))\n",
      "4435         {\n",
      "4436             err = cublasSgemv(handle, CUBLAS_OP_T,\n",
      "4437                     CudaNdarray_HOST_DIMS(A)[1], CudaNdarray_HOST_DIMS(A)[0],\n",
      "4438                     &alpha,\n",
      "4439                     CudaNdarray_DEV_DATA(A), sa_0,\n",
      "4440                     CudaNdarray_DEV_DATA(B), sb_0,\n",
      "4441                     &beta,\n",
      "4442                     CudaNdarray_DEV_DATA(C), sc_0);\n",
      "4443         }\n",
      "4444         // A is non vector and have malformed strides\n",
      "4445         else\n",
      "4446         {\n",
      "4447             PyErr_Format(PyExc_AssertionError,\n",
      "4448                          \"Unexpected stride pattern in gemv: (%i, %i) x %i -> %i.\\n\"\n",
      "4449                          \"Shapes are: (%i, %i) x %i -> %i\\n\",\n",
      "4450                          CudaNdarray_HOST_STRIDES(A)[0],\n",
      "4451                          CudaNdarray_HOST_STRIDES(A)[1],\n",
      "4452                          CudaNdarray_HOST_STRIDES(B)[0],\n",
      "4453                          CudaNdarray_HOST_STRIDES(C)[0],\n",
      "4454                          CudaNdarray_HOST_DIMS(A)[0],\n",
      "4455                          CudaNdarray_HOST_DIMS(A)[1],\n",
      "4456                          CudaNdarray_HOST_DIMS(B)[0],\n",
      "4457                          CudaNdarray_HOST_DIMS(C)[0]);\n",
      "4458             Py_XDECREF(A_new);\n",
      "4459             Py_XDECREF(B_new);\n",
      "4460             return -1;\n",
      "4461         }\n",
      "4462     }\n",
      "4463 \n",
      "4464     CNDA_THREAD_SYNC;\n",
      "4465     Py_XDECREF(A_new);\n",
      "4466     Py_XDECREF(B_new);\n",
      "4467 \n",
      "4468     if (CUBLAS_STATUS_SUCCESS != err)\n",
      "4469     {\n",
      "4470         if (!used_dot)\n",
      "4471         {\n",
      "4472             PyErr_Format(PyExc_RuntimeError,\n",
      "4473                          \"cublasSgemv failed (%i)\",\n",
      "4474                          err);\n",
      "4475         } else {\n",
      "4476         PyErr_Format(PyExc_RuntimeError,\n",
      "4477                      \"cublasSdot failed (%i)\",\n",
      "4478                      err);\n",
      "4479         }\n",
      "4480         return -1;\n",
      "4481     }\n",
      "4482     return 0;\n",
      "4483 }\n",
      "4484 \n",
      "4485 int CudaNdarray_sger(float alpha, const CudaNdarray * x, const CudaNdarray * y, CudaNdarray * A) {\n",
      "4486     if (x->nd != 1) { PyErr_SetString(PyExc_ValueError, \"non-vector arg x to sger\"); return -1; }\n",
      "4487     if (y->nd != 1) { PyErr_SetString(PyExc_ValueError, \"non-vector arg y to sger\"); return -1; }\n",
      "4488     if (A->nd != 2) { PyErr_SetString(PyExc_ValueError, \"non-matrix arg A to sger\"); return -1; }\n",
      "4489 \n",
      "4490     if ((CudaNdarray_HOST_DIMS(A)[0] != CudaNdarray_HOST_DIMS(x)[0])\n",
      "4491         || (CudaNdarray_HOST_DIMS(A)[1] != CudaNdarray_HOST_DIMS(y)[0])) {\n",
      "4492         PyErr_Format(PyExc_ValueError,\n",
      "4493                      \"dimension mismatch in args to sger (%i)x(%i)->(%i,%i)\",\n",
      "4494                      CudaNdarray_HOST_DIMS(x)[0],\n",
      "4495                      CudaNdarray_HOST_DIMS(y)[0],\n",
      "4496                      CudaNdarray_HOST_DIMS(A)[0],\n",
      "4497                      CudaNdarray_HOST_DIMS(A)[1]);\n",
      "4498         return -1;\n",
      "4499     }\n",
      "4500 \n",
      "4501     int x_strides = CudaNdarray_HOST_STRIDES(x)[0];\n",
      "4502     CudaNdarray * x_new = NULL;\n",
      "4503     if(x_strides == 0){\n",
      "4504         if(CudaNdarray_HOST_DIMS(x)[0] != 1){\n",
      "4505             PyErr_Format(PyExc_RuntimeError,\n",
      "4506                          \"CudaNdarray_sger: Invalid input x (should not happen).\"\n",
      "4507                          \" We received a CudaNdarray vector with a stride of 0\"\n",
      "4508                          \" that has more than 1 element!\");\n",
      "4509             return -1;\n",
      "4510         }\n",
      "4511         x_strides = 1;\n",
      "4512     } else if(x_strides < 0){\n",
      "4513         x_new = (CudaNdarray*) CudaNdarray_Copy(x);\n",
      "4514         x = x_new;\n",
      "4515         x_strides = CudaNdarray_HOST_STRIDES(x)[0];\n",
      "4516     }\n",
      "4517 \n",
      "4518     int y_strides = CudaNdarray_HOST_STRIDES(y)[0];\n",
      "4519     CudaNdarray * y_new = NULL;\n",
      "4520     if(y_strides == 0){\n",
      "4521         if(CudaNdarray_HOST_DIMS(y)[0] != 1){\n",
      "4522             PyErr_Format(PyExc_RuntimeError,\n",
      "4523                          \"CudaNdarray_sger: Invalid input y (should not happen).\"\n",
      "4524                          \" We received a CudaNdarray vector with a stride of 0\"\n",
      "4525                          \" that has more than 1 elements!\");\n",
      "4526             Py_XDECREF(x_new);\n",
      "4527             return -1;\n",
      "4528         }\n",
      "4529         y_strides = 1;\n",
      "4530     } else if(y_strides < 0){\n",
      "4531         y_new = (CudaNdarray*) CudaNdarray_Copy(y);\n",
      "4532         y = y_new;\n",
      "4533         y_strides = CudaNdarray_HOST_STRIDES(y)[0];\n",
      "4534     }\n",
      "4535 \n",
      "4536     // Create appropriate strides if A is a row or column vector\n",
      "4537     int sa_0 = (CudaNdarray_HOST_DIMS(A)[0] > 1) ? CudaNdarray_HOST_STRIDES(A)[0]\n",
      "4538                                                  : CudaNdarray_HOST_DIMS(A)[1];\n",
      "4539     int sa_1 = (CudaNdarray_HOST_DIMS(A)[1] > 1) ? CudaNdarray_HOST_STRIDES(A)[1]\n",
      "4540                                                  : CudaNdarray_HOST_DIMS(A)[0];\n",
      "4541 \n",
      "4542     // This is important because we can end up not calling Sger at all\n",
      "4543     cublasStatus_t err = CUBLAS_STATUS_SUCCESS;\n",
      "4544     if(CudaNdarray_SIZE(A)){\n",
      "4545         // If A is in col-major\n",
      "4546         if ((CudaNdarray_HOST_DIMS(A)[0] <= 1)\n",
      "4547             || ((CudaNdarray_HOST_STRIDES(A)[0] == 1)\n",
      "4548                 && (CudaNdarray_HOST_STRIDES(A)[1] > 0)))\n",
      "4549         {\n",
      "4550             err = cublasSger(handle, CudaNdarray_HOST_DIMS(x)[0], CudaNdarray_HOST_DIMS(y)[0], &alpha,\n",
      "4551                        CudaNdarray_DEV_DATA(x), x_strides,\n",
      "4552                        CudaNdarray_DEV_DATA(y), y_strides,\n",
      "4553                        CudaNdarray_DEV_DATA(A), sa_1);\n",
      "4554         }\n",
      "4555         // Since Sger expects A in col-major, we invert x and y to fake this.\n",
      "4556         else if ((CudaNdarray_HOST_DIMS(A)[1] <= 1)\n",
      "4557                 || ((CudaNdarray_HOST_STRIDES(A)[1] == 1)\n",
      "4558                     && (CudaNdarray_HOST_STRIDES(A)[0] > 0)))\n",
      "4559         {\n",
      "4560             err = cublasSger(handle, CudaNdarray_HOST_DIMS(y)[0], CudaNdarray_HOST_DIMS(x)[0], &alpha,\n",
      "4561                        CudaNdarray_DEV_DATA(y), y_strides,\n",
      "4562                        CudaNdarray_DEV_DATA(x), x_strides,\n",
      "4563                        CudaNdarray_DEV_DATA(A), sa_0);\n",
      "4564         }\n",
      "4565         // A has to be either c- or f-contiguous, with no negative strides\n",
      "4566         else\n",
      "4567         {\n",
      "4568             PyErr_SetString(PyExc_NotImplementedError,\n",
      "4569                             \"non-contiguous A, or negative strides, in sger\");\n",
      "4570             Py_XDECREF(x_new);\n",
      "4571             Py_XDECREF(y_new);\n",
      "4572             return -1;\n",
      "4573         }\n",
      "4574     }\n",
      "4575     CNDA_THREAD_SYNC;\n",
      "4576     Py_XDECREF(x_new);\n",
      "4577     Py_XDECREF(y_new);\n",
      "4578 \n",
      "4579     if (CUBLAS_STATUS_SUCCESS != err)\n",
      "4580     {\n",
      "4581         PyErr_Format(PyExc_RuntimeError,\n",
      "4582                      \"cublasSger failed (%i)\",\n",
      "4583                      err);\n",
      "4584         return -1;\n",
      "4585     }\n",
      "4586 \n",
      "4587     return 0;\n",
      "4588 }\n",
      "4589 \n",
      "4590 /**\n",
      "4591  *\n",
      "4592  * Precondition:\n",
      "4593  *  a->dim[d] == (dims_a[d]==0) ? (1 << log2_dims_a[d]) : dims_a[d]\n",
      "4594  *  z->dim[d] == (z_str[d]==0) ? 1 : dims_a[d];\n",
      "4595  *\n",
      "4596  *  TODO: templatize this function to support other reductions.\n",
      "4597  *  All that needs to change is the initial value for sum, and the reduction operator.\n",
      "4598  */\n",
      "4599 \n",
      "4600 static __global__ void kernel_reduce_sum(const unsigned int size_z,\n",
      "4601         const unsigned int nd,\n",
      "4602         const int * dims_a,\n",
      "4603         const int * log2_dims_a,\n",
      "4604         const int * a_str,\n",
      "4605         const float * a_data,\n",
      "4606         const int * z_str,\n",
      "4607         float * z_data)\n",
      "4608 {\n",
      "4609     const unsigned int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
      "4610     const unsigned int numThreads = blockDim.x * gridDim.x;\n",
      "4611 \n",
      "4612     //structure data contains the strides and dimensions of both a and z\n",
      "4613     // a_dim[0], a_dim[1], ... a_dim[nd-1],\n",
      "4614     // a_log2dim[0], a_log2dim[1], ... a_log2dim[nd-1],\n",
      "4615     // a_str[0], ... a_str[nd-1],\n",
      "4616     // z_str[0], ... z_str[nd-1]\n",
      "4617     extern __shared__ int structure_data[];\n",
      "4618     for (unsigned int i = threadIdx.x; i < nd; i += blockDim.x)\n",
      "4619     {\n",
      "4620         structure_data[i+0*nd] = dims_a[i];\n",
      "4621         structure_data[i+1*nd] = log2_dims_a[i];\n",
      "4622         structure_data[i+2*nd] = a_str[i];\n",
      "4623         structure_data[i+3*nd] = z_str[i];\n",
      "4624     }\n",
      "4625     dims_a = structure_data;\n",
      "4626     log2_dims_a = structure_data + nd;\n",
      "4627     a_str = structure_data + 2*nd;\n",
      "4628     z_str = structure_data + 3*nd;\n",
      "4629 \n",
      "4630     __syncthreads(); //wait for all the shared structure to be loaded\n",
      "4631 \n",
      "4632     for (unsigned int i = idx; i < size_z; i += numThreads)\n",
      "4633     {\n",
      "4634         unsigned int ii = i;\n",
      "4635         const float * a_data_i = a_data;\n",
      "4636         float * z_data_i = z_data;\n",
      "4637         unsigned int n_reduce_elements = 1;\n",
      "4638         unsigned int n_reduce_dims = 0;\n",
      "4639         unsigned int reduce_dim0 = nd-1;\n",
      "4640 \n",
      "4641 \n",
      "4642         //In this loop, we locate the initial element of the slice that we'd like to reduce with this thread\n",
      "4643         //  At the same time, we [re]calculate the size of that slice (n_reduce_elements)\n",
      "4644         for (unsigned int d = 0; d < nd; ++d)\n",
      "4645         {\n",
      "4646             if (a_str[d] && (!z_str[d])) // this means 'd' is a dimension we are reducing over\n",
      "4647             {\n",
      "4648                 n_reduce_elements *= dims_a[d];\n",
      "4649                 n_reduce_dims += 1;\n",
      "4650                 reduce_dim0 = (d < reduce_dim0) ? d : reduce_dim0;\n",
      "4651             }\n",
      "4652             else //'d' is not a dimension that we are reducing over\n",
      "4653             {\n",
      "4654                 unsigned int pos_d;\n",
      "4655                 if (log2_dims_a[d]==-1) //TODO: when things are working, use this switch\n",
      "4656                 {\n",
      "4657                     // this branch is not preferred,\n",
      "4658                     // because the manual said that integer mod and div operations are slow on gpu\n",
      "4659                     pos_d = (ii % dims_a[d]);\n",
      "4660                     ii = (ii / dims_a[d]);\n",
      "4661                 }\n",
      "4662                 else\n",
      "4663                 {\n",
      "4664                     pos_d = (ii & ((1 << log2_dims_a[d])-1)); //take the lower log2_dims bits\n",
      "4665                     ii = (ii >> log2_dims_a[d]);  //shift those lower log2_dims bits off of ii\n",
      "4666                 }\n",
      "4667                 a_data_i += pos_d * a_str[d];\n",
      "4668                 z_data_i += pos_d * z_str[d];\n",
      "4669             }\n",
      "4670         }\n",
      "4671         // now we've got pointers a_data_i and z_data_i into element 0 of the slice over which we are reducing\n",
      "4672         // do a similar loop\n",
      "4673 \n",
      "4674         float sum = 0.0f;\n",
      "4675         switch(n_reduce_dims)\n",
      "4676         {\n",
      "4677             case 0:\n",
      "4678                 {\n",
      "4679                     sum = a_data_i[0];\n",
      "4680                 }\n",
      "4681                 break;\n",
      "4682             case 1:\n",
      "4683                 {\n",
      "4684                     const int stride = a_str[reduce_dim0];\n",
      "4685                     const float * a_data_i_max = a_data_i + dims_a[reduce_dim0] * stride;\n",
      "4686                     while (a_data_i != a_data_i_max)\n",
      "4687                     {\n",
      "4688                         sum += a_data_i[0];\n",
      "4689                         a_data_i += stride;\n",
      "4690                     }\n",
      "4691                 }\n",
      "4692                 break;\n",
      "4693             case 2:\n",
      "4694                 {\n",
      "4695                     int rd = reduce_dim0+1;\n",
      "4696                     for (; rd < nd; ++rd)\n",
      "4697                     {\n",
      "4698                         if (a_str[rd] && (!z_str[rd])) // this means 'rd' is a dimension we are reducing over\n",
      "4699                             break;\n",
      "4700                     }\n",
      "4701                     const int stride0 = a_str[reduce_dim0];\n",
      "4702                     const int stride1 = a_str[rd];\n",
      "4703                     for (int ii = 0; ii < dims_a[rd]; ++ii)\n",
      "4704                     {\n",
      "4705                         const float * a_data_ri = a_data_i + ii * stride1;\n",
      "4706                         const float * a_data_ri_max = a_data_ri + dims_a[reduce_dim0] * stride0;\n",
      "4707                         while (a_data_ri != a_data_ri_max)\n",
      "4708                         {\n",
      "4709                             sum += a_data_ri[0];\n",
      "4710                             a_data_ri += stride0;\n",
      "4711                         }\n",
      "4712                     }\n",
      "4713                 };\n",
      "4714                 break;\n",
      "4715             default:\n",
      "4716                 {\n",
      "4717                     for (unsigned int reduce_i = 0; reduce_i < n_reduce_elements; ++reduce_i)\n",
      "4718                     {\n",
      "4719                         //TODO: optimize this loop to work more like theano's Elemwise.  It's serial code.\n",
      "4720                         unsigned int reduce_ii = reduce_i;\n",
      "4721                         const float * a_data_ri = a_data_i;\n",
      "4722 \n",
      "4723                         //This loop finds the element in the a slice to add.\n",
      "4724                         for (unsigned int rd = reduce_dim0; rd < nd; ++rd)\n",
      "4725                         {\n",
      "4726                             unsigned int pos_d;\n",
      "4727                             if (a_str[rd] && (!z_str[rd])) // this means 'd' is a dimension we are reducing over\n",
      "4728                             {\n",
      "4729                                 if (log2_dims_a[rd]==-1)\n",
      "4730                                 {\n",
      "4731                                     // this branch is not preferred,\n",
      "4732                                     // because the manual said that integer mod and div operations are slow on gpu\n",
      "4733                                     pos_d = (reduce_ii % dims_a[rd]);\n",
      "4734                                     reduce_ii = (reduce_ii / dims_a[rd]);\n",
      "4735                                 }\n",
      "4736                                 else\n",
      "4737                                 {\n",
      "4738                                     pos_d = (reduce_ii & ((1 << log2_dims_a[rd])-1)); //take the lower log2_dims bits\n",
      "4739                                     reduce_ii = (reduce_ii >> log2_dims_a[rd]);  //shift those lower log2_dims bits off of ii\n",
      "4740                                 }\n",
      "4741                                 a_data_ri += pos_d * a_str[rd];\n",
      "4742                             }\n",
      "4743                         }\n",
      "4744                         sum += a_data_ri[0];\n",
      "4745                     }\n",
      "4746                 }\n",
      "4747         }\n",
      "4748         z_data_i[0] = sum;\n",
      "4749     }\n",
      "4750 }\n",
      "4751 \n",
      "4752 static __global__ void kernel_reduce_sum_1011(\n",
      "4753         const unsigned int d0,\n",
      "4754         const unsigned int d1,\n",
      "4755         const unsigned int d2,\n",
      "4756         const unsigned int d3,\n",
      "4757         const float *A, const int sA0, const int sA1, const int sA2, const int sA3,\n",
      "4758         float * Z, const int sZ0)\n",
      "4759 {\n",
      "4760     const int threadCount = blockDim.x * blockDim.y * blockDim.z;\n",
      "4761     const int threadNum = threadIdx.z * blockDim.x * blockDim.y + threadIdx.y * blockDim.x + threadIdx.x;\n",
      "4762     extern __shared__ float buf[];\n",
      "4763     float mysum = 0.0f;\n",
      "4764 \n",
      "4765     if (warpSize != 32)\n",
      "4766     {\n",
      "4767         return;  //TODO: set error code\n",
      "4768     }\n",
      "4769 \n",
      "4770     for (int i0 = threadIdx.z; i0 < d0; i0 += blockDim.z)\n",
      "4771     {\n",
      "4772         float Ai = A[i0 * sA0 + blockIdx.x * sA1 + threadIdx.y * sA2 + threadIdx.x * sA3];\n",
      "4773         mysum += Ai;\n",
      "4774     }\n",
      "4775     buf[threadNum] = mysum;\n",
      "4776     __syncthreads();\n",
      "4777 \n",
      "4778     // rest of function is handled by one warp\n",
      "4779     if (threadNum < warpSize)\n",
      "4780     {\n",
      "4781         for (int i = threadNum + warpSize; i < threadCount; i += warpSize)\n",
      "4782         {\n",
      "4783             mysum += buf[i];\n",
      "4784         }\n",
      "4785         buf[threadNum] = mysum;\n",
      "4786         if (threadNum < 16)\n",
      "4787         {\n",
      "4788             //reduce so that threadNum 0 has the sum of everything\n",
      "4789             if(threadNum + 16 < threadCount) buf[threadNum] += buf[threadNum+16];\n",
      "4790             if(threadNum + 8 < threadCount) buf[threadNum] += buf[threadNum+8];\n",
      "4791             if(threadNum + 4 < threadCount) buf[threadNum] += buf[threadNum+4];\n",
      "4792             if(threadNum + 2 < threadCount) buf[threadNum] += buf[threadNum+2];\n",
      "4793             if(threadNum + 1 < threadCount) buf[threadNum] += buf[threadNum+1];\n",
      "4794             if (threadNum == 0)\n",
      "4795             {\n",
      "4796                 Z[blockIdx.x*sZ0] = buf[0];\n",
      "4797             }\n",
      "4798         }\n",
      "4799     }\n",
      "4800 }\n",
      "4801 /**\n",
      "4802  * Dimensions in which the self has size 1 and A has size > 1 are considered summing dimensions\n",
      "4803  * Dimensions in which self has size > 1 and A has size > 1 are considered non-summing dimensions, and in this case their sizes must be equal.\n",
      "4804  */\n",
      "4805 int\n",
      "4806 CudaNdarray_reduce_sum(CudaNdarray * self, CudaNdarray * A)\n",
      "4807 {\n",
      "4808     int verbose = 0;\n",
      "4809     //check input rank\n",
      "4810     if (self->nd != A->nd)\n",
      "4811     {\n",
      "4812         PyErr_Format(PyExc_TypeError, \"Rank mismatch in CudaNdarray_sum: %i vs %i\", self->nd, A->nd);\n",
      "4813         return -1;\n",
      "4814     }\n",
      "4815     for (int i = 0; i < self->nd; ++i)\n",
      "4816     {\n",
      "4817         if ((CudaNdarray_HOST_DIMS(self)[i] > 1) && (CudaNdarray_HOST_DIMS(self)[i] != CudaNdarray_HOST_DIMS(A)[i]))\n",
      "4818         {\n",
      "4819             PyErr_Format(PyExc_TypeError, \"Dimension mismatch in CudaNdarray_sum: self->dim[%i] == %i , A->dim[%i] = %i\",\n",
      "4820                     i, CudaNdarray_HOST_DIMS(self)[i], i, CudaNdarray_HOST_DIMS(A)[i]);\n",
      "4821             return -1;\n",
      "4822         }\n",
      "4823     }\n",
      "4824 \n",
      "4825     int n_summations = (unsigned int)CudaNdarray_SIZE(self);\n",
      "4826     if (verbose)\n",
      "4827     {\n",
      "4828         std::cerr << \"reduce_sum n_summations \" << n_summations  << '\\n';\n",
      "4829         std::cerr << \"reduce_sum nd \" << self->nd  << '\\n';\n",
      "4830         fprint_CudaNdarray(stderr, A);\n",
      "4831         fprint_CudaNdarray(stderr, self);\n",
      "4832     }\n",
      "4833     if (0 && (A->nd == 4) //check to see if kernel_reduce_sum_1011 applies\n",
      "4834             && (CudaNdarray_HOST_DIMS(self)[0] == 1)\n",
      "4835             && (CudaNdarray_HOST_DIMS(self)[2] == 1)\n",
      "4836             && (CudaNdarray_HOST_DIMS(self)[3] == 1)\n",
      "4837        )\n",
      "4838     {\n",
      "4839         dim3 n_threads(CudaNdarray_HOST_DIMS(A)[3], CudaNdarray_HOST_DIMS(A)[2]);\n",
      "4840         dim3 n_blocks(CudaNdarray_HOST_DIMS(A)[1]);\n",
      "4841         while (n_threads.x * n_threads.y * n_threads.z < NUM_VECTOR_OP_THREADS_PER_BLOCK) ++n_threads.z;\n",
      "4842         n_threads.z -= 1;\n",
      "4843         if (n_threads.z > 64) n_threads.z = 64;\n",
      "4844         if (n_threads.z)\n",
      "4845         {\n",
      "4846             if (verbose) printf(\"trying kernel_reduce_sum_1011\\n\");\n",
      "4847             int n_shared = sizeof(float) * n_threads.x * n_threads.y * n_threads.z;\n",
      "4848             kernel_reduce_sum_1011<<<n_blocks, n_threads, n_shared>>>(\n",
      "4849                     CudaNdarray_HOST_DIMS(A)[0],\n",
      "4850                     CudaNdarray_HOST_DIMS(A)[1],\n",
      "4851                     CudaNdarray_HOST_DIMS(A)[2],\n",
      "4852                     CudaNdarray_HOST_DIMS(A)[3],\n",
      "4853                     CudaNdarray_DEV_DATA(A),\n",
      "4854                     CudaNdarray_HOST_STRIDES(A)[0],\n",
      "4855                     CudaNdarray_HOST_STRIDES(A)[1],\n",
      "4856                     CudaNdarray_HOST_STRIDES(A)[2],\n",
      "4857                     CudaNdarray_HOST_STRIDES(A)[3],\n",
      "4858                     CudaNdarray_DEV_DATA(self),\n",
      "4859                     CudaNdarray_HOST_STRIDES(self)[1]);\n",
      "4860             CNDA_THREAD_SYNC;\n",
      "4861             if (cudaSuccess == cudaGetLastError()) return 0;\n",
      "4862             if (verbose) printf(\"failed, falling back to kernel_reduce_sum\\n\");\n",
      "4863         }\n",
      "4864     }\n",
      "4865 \n",
      "4866     int n_threads_per_block = std::min(n_summations,\n",
      "4867             NUM_VECTOR_OP_THREADS_PER_BLOCK);\n",
      "4868     int n_blocks = std::min(ceil_intdiv(n_summations,n_threads_per_block),\n",
      "4869             NUM_VECTOR_OP_BLOCKS);\n",
      "4870     int n_structure_cache = self->nd * 4 * sizeof(int);\n",
      "4871 \n",
      "4872     if (verbose)\n",
      "4873     {\n",
      "4874         std::cerr << \"n_blocks, n_threads_per_block \" << n_blocks << ' ' << n_threads_per_block  << '\\n';\n",
      "4875     }\n",
      "4876     assert (self->nd > 0);\n",
      "4877     assert (self->nd == A->nd);\n",
      "4878     kernel_reduce_sum<<<n_blocks, n_threads_per_block, n_structure_cache>>>(\n",
      "4879             n_summations,\n",
      "4880             self->nd,\n",
      "4881             CudaNdarray_DEV_DIMS(A),\n",
      "4882             CudaNdarray_DEV_LOG2DIMS(A),\n",
      "4883             CudaNdarray_DEV_STRIDES(A),\n",
      "4884             CudaNdarray_DEV_DATA(A),\n",
      "4885             CudaNdarray_DEV_STRIDES(self),\n",
      "4886             CudaNdarray_DEV_DATA(self));\n",
      "4887     CNDA_THREAD_SYNC;\n",
      "4888     cudaError_t err = cudaGetLastError();\n",
      "4889     if (cudaSuccess != err)\n",
      "4890     {\n",
      "4891         PyErr_Format(PyExc_RuntimeError, \"Cuda error: %s: %s.\\n\", \"kernel_reduce_sum\", cudaGetErrorString(err));\n",
      "4892         return -1;\n",
      "4893     }\n",
      "4894     return 0;\n",
      "4895 }\n",
      "4896 int\n",
      "4897 CudaNdarray_reduce_prod(CudaNdarray * self, const CudaNdarray * A)\n",
      "4898 {\n",
      "4899     PyErr_SetString(PyExc_NotImplementedError, \"\");\n",
      "4900     return -1;\n",
      "4901 }\n",
      "4902 int\n",
      "4903 CudaNdarray_reduce_min(CudaNdarray * self, const CudaNdarray * A)\n",
      "4904 {\n",
      "4905     PyErr_SetString(PyExc_NotImplementedError, \"\");\n",
      "4906     return -1;\n",
      "4907 }\n",
      "4908 int\n",
      "4909 CudaNdarray_reduce_max(CudaNdarray * self, const CudaNdarray * A)\n",
      "4910 {\n",
      "4911     PyErr_SetString(PyExc_NotImplementedError, \"\");\n",
      "4912     return -1;\n",
      "4913 }\n",
      "4914 \n",
      "4915 \n",
      "4916 /**\n",
      "4917  *\n",
      "4918  *  pattern is a permutation of [0, 1, ... self->nd-1] with the following twists:\n",
      "4919  *  - an element 'd' of the permutation can be dropped if CudaNdarray_HOST_DIMS(self)[d] == 1\n",
      "4920  *  - any number of '-1' elements can be in the pattern, and they will cause new ranks (with dim==1) to be inserted.\n",
      "4921  *\n",
      "4922  *  For example, if CudaNdarray_HOST_DIMS(self) == [4, 5, 1, 6], and pattern = [0,3,-1,-1, 1], then CudaNdarray_HOST_DIMS(self) would be modified to become:\n",
      "4923  *     [4, 6, 1, 1, 5] (we dropped the original dim[2]==1, and inserted two singleton dimensions with the -1s.\n",
      "4924  */\n",
      "4925 int\n",
      "4926 CudaNdarray_dimshuffle(CudaNdarray * self, unsigned int len, const int * pattern)\n",
      "4927 {\n",
      "4928     //TODO: pass a workspace pointer to avoid the internal malloc\n",
      "4929     int * newdims = (int *)malloc(sizeof(int) * (len + len + self->nd)); //we tack on the taken buffer here for speed of not having to malloc twice.\n",
      "4930     int * newstrides = newdims + len;\n",
      "4931     int * dims_taken = newstrides + len;\n",
      "4932     if (!newdims)\n",
      "4933     {\n",
      "4934         PyErr_SetString(PyExc_MemoryError, \"CudaNdarray_dimshuffle: Failed to allocate temporary space\");\n",
      "4935         return -1;\n",
      "4936     }\n",
      "4937     for (int i = 0; i < self->nd; ++i)\n",
      "4938     {\n",
      "4939         dims_taken[i] = 0;\n",
      "4940     }\n",
      "4941     for (int i = 0; i < len; ++i)\n",
      "4942     {\n",
      "4943         if (pattern[i] < 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4944         {\n",
      "4945             newdims[i] = 1;\n",
      "4946             newstrides[i] = 0;\n",
      "4947         }\n",
      "4948         else if(dims_taken[pattern[i]])\n",
      "4949         {\n",
      "4950             PyErr_Format(PyExc_ValueError, \"Cudandarray_dimshuffle: invalid pattern for Cudandarray_dimshuffle. You used the dimensions %d multiple time\",\n",
      "4951                          pattern[i]);\n",
      "4952             free(newdims);\n",
      "4953             return -1;\n",
      "4954         }\n",
      "4955         else if (pattern[i]>= self->nd)\n",
      "4956         {\n",
      "4957             PyErr_Format(PyExc_ValueError, \"Cudandarray_dimshuffle: invalid pattern for Cudandarray_dimshuffle. You asked for a dimensions that don't exist %d for a %d dims CudaNdarray\",\n",
      "4958                          pattern[i], self->nd);\n",
      "4959             free(newdims);\n",
      "4960             return -1;\n",
      "4961         }\n",
      "4962         else\n",
      "4963         {\n",
      "4964             newdims[i] = CudaNdarray_HOST_DIMS(self)[pattern[i]];\n",
      "4965             newstrides[i] = CudaNdarray_HOST_STRIDES(self)[pattern[i]];\n",
      "4966             dims_taken[pattern[i]] = 1;\n",
      "4967         }\n",
      "4968     }\n",
      "4969     //Check if we dropped not broadcastable dims\n",
      "4970     for (int i = 0; i < self->nd; ++i)\n",
      "4971     {\n",
      "4972         if (dims_taken[i]==0 && CudaNdarray_HOST_DIMS(self)[i]!=1)\n",
      "4973         {\n",
      "4974             PyErr_SetString(PyExc_ValueError, \"Cudandarray_dimshuffle: You cannot drop a non-broadcastable dimension.\");\n",
      "4975             free(newdims);\n",
      "4976             return -1;\n",
      "4977         }\n",
      "4978     }\n",
      "4979     //swap this structure in for the one in self, and sync to the card\n",
      "4980     if (CudaNdarray_set_nd(self, len))\n",
      "4981     {\n",
      "4982         free(newdims);\n",
      "4983         return -1;\n",
      "4984     }\n",
      "4985     for (int i = 0; i < len; ++i)\n",
      "4986     {\n",
      "4987         CudaNdarray_set_dim(self, i, newdims[i]);\n",
      "4988         CudaNdarray_set_stride(self, i, newstrides[i]);\n",
      "4989     }\n",
      "4990     if (cnda_copy_structure_to_device(self))\n",
      "4991     {\n",
      "4992         free(newdims);\n",
      "4993         return -1;\n",
      "4994     }\n",
      "4995     free(newdims);\n",
      "4996     return 0;\n",
      "4997 }\n",
      "4998 \n",
      "4999 \n",
      "5000 \n",
      "5001 /**\n",
      "5002  *\n",
      "5003  *  This is the function that bind to python.\n",
      "5004  *  See CudaNdarray_dimshuffle to call from C.\n",
      "5005  *  We use -1 to mean 'x' as in Tensor Dimshuffle.\n",
      "5006  */\n",
      "5007 PyObject *\n",
      "5008 CudaNdarray_Dimshuffle(PyObject* _unused, PyObject* args)\n",
      "5009 {\n",
      "5010     PyObject * self = NULL;\n",
      "5011     PyObject * pattern_object = NULL;\n",
      "5012     int * pattern = NULL;\n",
      "5013     PyObject * rval = NULL;\n",
      "5014     int success = -1;\n",
      "5015     //const int * dims = NULL;\n",
      "5016 \n",
      "5017     //args should consist of two python objects (\"OO\")\n",
      "5018     if (! PyArg_ParseTuple(args, \"OO\", &self, &pattern_object))\n",
      "5019         return NULL;\n",
      "5020 \n",
      "5021     if (!CudaNdarray_Check(self) )\n",
      "5022     {\n",
      "5023         PyErr_SetString(PyExc_TypeError, \"First argument to cuda_ndarray.dimshuffle must be a CudaNdarray\");\n",
      "5024         return NULL;\n",
      "5025     }\n",
      "5026 \n",
      "5027     //parse pattern_object into int * pattern\n",
      "5028 \n",
      "5029     Py_ssize_t pattern_dim =  PyObject_Length(pattern_object);\n",
      "5030 \n",
      "5031     if (pattern_dim < 0)\n",
      "5032     {\n",
      "5033         PyErr_SetString(PyExc_TypeError, \"Couldn't get length of third argument to cuda_ndarray.dimshuffle\");\n",
      "5034         return NULL;\n",
      "5035     }\n",
      "5036 \n",
      "5037     pattern = (int *) malloc( pattern_dim * sizeof(int));\n",
      "5038 \n",
      "5039     for (Py_ssize_t i = 0; i < pattern_dim; i++)\n",
      "5040     {\n",
      "5041         PyObject * idx = PyLong_FromSsize_t(i);\n",
      "5042 \n",
      "5043         if (idx == NULL)\n",
      "5044         {\n",
      "5045             PyErr_SetString(PyExc_Exception, \"Couldn't make long object to loop over list/tuple\");\n",
      "5046             goto CudaNdarray_dimshuffle_fail;\n",
      "5047         }\n",
      "5048 \n",
      "5049         long elem_value = 0;\n",
      "5050 \n",
      "5051         PyObject * elem = PyObject_GetItem(pattern_object, idx);\n",
      "5052 \n",
      "5053         if (elem == NULL)\n",
      "5054         {\n",
      "5055             Py_XDECREF( elem);\n",
      "5056             PyErr_SetString(PyExc_ValueError, \"Third argument to dimshuffle must be list or tuple of integers\");\n",
      "5057             goto CudaNdarray_dimshuffle_fail;\n",
      "5058         }\n",
      "5059 \n",
      "5060         elem_value = PyInt_AsLong(elem);\n",
      "5061 \n",
      "5062         if (elem_value == -1 && PyErr_Occurred() )\n",
      "5063         {\n",
      "5064             Py_XDECREF(elem);\n",
      "5065             PyErr_SetString(PyExc_ValueError, \"Third argument to dimshuffle must be list or tuple of integers\");\n",
      "5066             goto CudaNdarray_dimshuffle_fail;\n",
      "5067         }\n",
      "5068 \n",
      "5069         pattern[i] = elem_value;\n",
      "5070 \n",
      "5071         Py_XDECREF( elem );\n",
      "5072         Py_XDECREF( idx );\n",
      "5073     }\n",
      "5074 \n",
      "5075     //allocate rval\n",
      "5076     rval =  (PyObject *) CudaNdarray_View((CudaNdarray *) self);\n",
      "5077 \n",
      "5078     if (rval == NULL)\n",
      "5079     {\n",
      "5080         //CudaNdarray_New should have set the exception string\n",
      "5081         goto CudaNdarray_dimshuffle_fail;\n",
      "5082     }\n",
      "5083 \n",
      "5084 \n",
      "5085     //printf(\"pattern_dim: %d\\n\",pattern_dim);\n",
      "5086     //printf(\"pattern: %d %d\\n\",pattern[0],pattern[1]);\n",
      "5087     //dims = CudaNdarray_HOST_DIMS( (CudaNdarray *) self);\n",
      "5088     //printf(\"dims before: %d %d\\n\",dims[0],dims[1]);\n",
      "5089 \n",
      "5090     success = CudaNdarray_dimshuffle((CudaNdarray *) rval, pattern_dim, pattern);\n",
      "5091 \n",
      "5092     if (success != 0)\n",
      "5093     {\n",
      "5094         //Exception string should already be set by CudaNdarray_dimshuffle\n",
      "5095         goto CudaNdarray_dimshuffle_fail;\n",
      "5096     }\n",
      "5097 \n",
      "5098     free(pattern);\n",
      "5099 \n",
      "5100     return rval;\n",
      "5101 \n",
      "5102     CudaNdarray_dimshuffle_fail:\n",
      "5103 \n",
      "5104     if (pattern != NULL)\n",
      "5105         free(pattern);\n",
      "5106 \n",
      "5107     Py_XDECREF(rval);\n",
      "5108     return NULL;\n",
      "5109 }\n",
      "5110 \n",
      "5111 \n",
      "5112 int\n",
      "5113 cnda_structure_size(int nd)\n",
      "5114 {\n",
      "5115     // dim0, dim1, ...\n",
      "5116     // str0, str1, ...\n",
      "5117     // log2(dim0), log2(dim1), ...\n",
      "5118     return nd + nd + nd;\n",
      "5119 }\n",
      "5120 \n",
      "5121 const int *\n",
      "5122 CudaNdarray_HOST_DIMS(const CudaNdarray * self)\n",
      "5123 {\n",
      "5124     return self->host_structure;\n",
      "5125 }\n",
      "5126 \n",
      "5127 const int *\n",
      "5128 CudaNdarray_HOST_STRIDES(const CudaNdarray * self)\n",
      "5129 {\n",
      "5130     return self->host_structure + self->nd;\n",
      "5131 }\n",
      "5132 const int *\n",
      "5133 CudaNdarray_HOST_LOG2DIMS(const CudaNdarray * self)\n",
      "5134 {\n",
      "5135     return self->host_structure + 2*self->nd;\n",
      "5136 }\n",
      "5137 \n",
      "5138 int\n",
      "5139 CudaNdarray_EqualAndIgnore(CudaNdarray *cnda1, CudaNdarray *cnda2, int ignoreSync, int ignoreBase)\n",
      "5140 {\n",
      "5141     int verbose = 0;\n",
      "5142 \n",
      "5143     if (!ignoreSync && cnda1->dev_structure_fresh != cnda2->dev_structure_fresh)\n",
      "5144     {\n",
      "5145         if(verbose) fprintf(stdout, \"CUDANDARRAY_EQUAL FAILED : 1\\n\");\n",
      "5146         return 0;\n",
      "5147     }\n",
      "5148 \n",
      "5149     if (cnda1->nd != cnda2->nd)\n",
      "5150     {\n",
      "5151         if(verbose) fprintf(stdout, \"CUDANDARRAY_EQUAL FAILED : 2\\n\");\n",
      "5152         return 0;\n",
      "5153     }\n",
      "5154 \n",
      "5155     for (int i=0; i < 2*cnda1->nd; i++)\n",
      "5156     {\n",
      "5157         if (cnda1->host_structure[i] != cnda2->host_structure[i])\n",
      "5158         {\n",
      "5159             if(verbose)\n",
      "5160                 fprintf(stdout, \"CUDANDARRAY_EQUAL : host_structure : %d, %d, %d\\n\", i, cnda1->host_structure[i], cnda2->host_structure[i]);\n",
      "5161             return 0;\n",
      "5162         }\n",
      "5163     }\n",
      "5164 \n",
      "5165     if (!ignoreBase && cnda1->base != cnda2->base)\n",
      "5166     {\n",
      "5167         if(verbose) fprintf(stdout, \"CUDANDARRAY_EQUAL FAILED : 4\");\n",
      "5168         return 0;\n",
      "5169     }\n",
      "5170     else if (cnda1->data_allocated != cnda2->data_allocated)\n",
      "5171     {\n",
      "5172         if(verbose) fprintf(stdout, \"CUDANDARRAY_EQUAL FAILED : 5\");\n",
      "5173         return 0;\n",
      "5174     }\n",
      "5175     else if (cnda1->data_allocated && cnda1->devdata != cnda2->devdata)\n",
      "5176     {\n",
      "5177         if(verbose) fprintf(stdout, \"CUDANDARRAY_EQUAL FAILED : 6\");\n",
      "5178         // no need to check devdata if data is not allocated\n",
      "5179         return 0;\n",
      "5180     }\n",
      "5181 \n",
      "5182     return 1;\n",
      "5183 }\n",
      "5184 \n",
      "5185 \n",
      "5186 int\n",
      "5187 CudaNdarray_Equal(CudaNdarray *cnda1, CudaNdarray *cnda2)\n",
      "5188 {\n",
      "5189     return CudaNdarray_EqualAndIgnore(cnda1, cnda2, 0, 0);\n",
      "5190 }\n",
      "5191 \n",
      "5192 int\n",
      "5193 cnda_copy_structure_to_device(const CudaNdarray * self)\n",
      "5194 {\n",
      "5195     //If the device structure do not exists, create it.\n",
      "5196     //We allocate it here as we do not need it often.\n",
      "5197     //In fact, we need it so infrequently that we expect\n",
      "5198     //that most object won't need it. Not allocating it\n",
      "5199     //save a significant when creating object.\n",
      "5200     //This speed up a benchmark by 8% with the gc.\n",
      "5201     if (!self->dev_structure)\n",
      "5202     {\n",
      "5203         int struct_size = cnda_structure_size(self->nd);\n",
      "5204         if (struct_size)\n",
      "5205         {\n",
      "5206             self->dev_structure = (int*)device_malloc(struct_size* sizeof(int));\n",
      "5207             if (NULL == self->dev_structure)\n",
      "5208             {\n",
      "5209                 return -1;\n",
      "5210             }\n",
      "5211         }\n",
      "5212     }\n",
      "5213     if (cublasSetVector(cnda_structure_size(self->nd),\n",
      "5214                         sizeof(int),\n",
      "5215                         self->host_structure,\n",
      "5216                         1,\n",
      "5217                         self->dev_structure,\n",
      "5218                         1) != CUBLAS_STATUS_SUCCESS)\n",
      "5219     {\n",
      "5220         PyErr_SetString(PyExc_RuntimeError, \"error copying structure to device memory\");\n",
      "5221         return -1;\n",
      "5222     }\n",
      "5223     self->dev_structure_fresh = 1;\n",
      "5224     return 0;\n",
      "5225 }\n",
      "5226 \n",
      "5227 const int *\n",
      "5228 CudaNdarray_DEV_DIMS(const CudaNdarray * self)\n",
      "5229 {\n",
      "5230     if (!self->dev_structure_fresh)\n",
      "5231     {\n",
      "5232         if (cnda_copy_structure_to_device(self))\n",
      "5233             return NULL;\n",
      "5234     }\n",
      "5235     return self->dev_structure;\n",
      "5236 }\n",
      "5237 const int *\n",
      "5238 CudaNdarray_DEV_STRIDES(const CudaNdarray * self)\n",
      "5239 {\n",
      "5240     if (!self->dev_structure_fresh)\n",
      "5241     {\n",
      "5242         if (cnda_copy_structure_to_device(self))\n",
      "5243             return NULL;\n",
      "5244     }\n",
      "5245     return self->dev_structure + self->nd;\n",
      "5246 }\n",
      "5247 const int *\n",
      "5248 CudaNdarray_DEV_LOG2DIMS(const CudaNdarray * self)\n",
      "5249 {\n",
      "5250     if (!self->dev_structure_fresh)\n",
      "5251     {\n",
      "5252         if (cnda_copy_structure_to_device(self))\n",
      "5253             return NULL;\n",
      "5254     }\n",
      "5255     return self->dev_structure + 2*self->nd;\n",
      "5256 }\n",
      "5257 float *\n",
      "5258 CudaNdarray_DEV_DATA(const CudaNdarray * self)\n",
      "5259 {\n",
      "5260     return self->devdata;\n",
      "5261 }\n",
      "5262 \n",
      "5263 /**\n",
      "5264  * Return the number of elements in the ndarray (product of the dimensions)\n",
      "5265  */\n",
      "5266 size_t\n",
      "5267 CudaNdarray_SIZE(const CudaNdarray *self)\n",
      "5268 {\n",
      "5269     if (self->nd == -1) return 0;\n",
      "5270     size_t size = 1;\n",
      "5271     for (int i = 0; i < self->nd; ++i)\n",
      "5272     {\n",
      "5273         size *= CudaNdarray_HOST_DIMS(self)[i];\n",
      "5274     }\n",
      "5275     return size;\n",
      "5276 }\n",
      "5277 \n",
      "5278 PyObject *\n",
      "5279 CudaNdarray_SIZE_Object(const CudaNdarray *self, void *closure)\n",
      "5280 {\n",
      "5281     return PyInt_FromLong(CudaNdarray_SIZE(self));\n",
      "5282 }\n",
      "5283 \n",
      "5284 int CudaNdarray_set_device_data(CudaNdarray * self, float * data, const CudaNdarray * base)\n",
      "5285 {\n",
      "5286     return CudaNdarray_set_device_data(self, data, (PyObject *) base);\n",
      "5287 }\n",
      "5288 \n",
      "5289 PyObject * CudaNdarray_IS_C_Contiguous(CudaNdarray * self)\n",
      "5290 {\n",
      "5291     return PyBool_FromLong(CudaNdarray_is_c_contiguous(self));\n",
      "5292 }\n",
      "5293 \n",
      "5294 int fprint_CudaNdarray(FILE * fd, const CudaNdarray *self)\n",
      "5295 {\n",
      "5296     cudaError_t err = cudaGetLastError();\n",
      "5297     if( cudaSuccess != err)\n",
      "5298     {\n",
      "5299         PyErr_Format(PyExc_RuntimeError,\n",
      "5300                      \"Cuda error: %s: %s.\",\n",
      "5301                      \"fprint_CudaNdarray was called with an uncleared error\",\n",
      "5302                      cudaGetErrorString(err));\n",
      "5303         return -1;\n",
      "5304     }\n",
      "5305     fprintf(fd, \"CudaNdarray <%p, %p> nd=%i dev_structure_fresh=%d data_allocated=%d\\n\",\n",
      "5306             self, self->devdata, self->nd, self->dev_structure_fresh, self->data_allocated);\n",
      "5307     fprintf(fd, \"\\tHOST_DIMS:      \");\n",
      "5308     for (int i = 0; i < self->nd; ++i)\n",
      "5309     {\n",
      "5310         fprintf(fd, \"%i\\t\", CudaNdarray_HOST_DIMS(self)[i]);\n",
      "5311     }\n",
      "5312     fprintf(fd, \"\\n\\tHOST_STRIDES: \");\n",
      "5313     for (int i = 0; i < self->nd; ++i)\n",
      "5314     {\n",
      "5315         fprintf(fd, \"%i\\t\", CudaNdarray_HOST_STRIDES(self)[i]);\n",
      "5316     }\n",
      "5317 \n",
      "5318     if (self->dev_structure)\n",
      "5319     {\n",
      "5320         int data=0;\n",
      "5321         fprintf(fd, \"\\n\\tDEV_DIMS:      \");\n",
      "5322         for (int i = 0; i < self->nd; ++i)\n",
      "5323         {\n",
      "5324             cublasGetVector(1, sizeof(int),\n",
      "5325                             self->dev_structure+i, 1,\n",
      "5326                             &data, 1);\n",
      "5327             fprintf(fd, \"%i\\t\", data);\n",
      "5328         }\n",
      "5329         fprintf(fd, \"\\n\\tDEV_STRIDES: \");\n",
      "5330         for (int i = 0; i < self->nd; ++i)\n",
      "5331         {\n",
      "5332             cublasGetVector(1, sizeof(int),\n",
      "5333                             self->dev_structure + self->nd+i, 1,\n",
      "5334                             &data, 1);\n",
      "5335             fprintf(fd, \"%i \\t\", data);\n",
      "5336         }\n",
      "5337         fprintf(fd, \"\\n\");\n",
      "5338     }\n",
      "5339     else\n",
      "5340     {\n",
      "5341         fprintf(fd, \"\\n\\tdev_structure not allocated\\n\");\n",
      "5342     }\n",
      "5343 \n",
      "5344     err = cudaGetLastError();\n",
      "5345     if( cudaSuccess != err)\n",
      "5346     {\n",
      "5347         PyErr_Format(PyExc_RuntimeError,\n",
      "5348                      \"Cuda error: %s: %s.\",\n",
      "5349                      \"fprint_CudaNdarray\",\n",
      "5350                      cudaGetErrorString(err));\n",
      "5351         return -1;\n",
      "5352     }\n",
      "5353     return 0;\n",
      "5354 }\n",
      "5355 \n",
      "5356 \n",
      "5357 int CudaNdarray_prep_output(CudaNdarray ** arr, int nd,\n",
      "5358                             const int * dims, int fortran)\n",
      "5359 {\n",
      "5360     bool allocated = false;\n",
      "5361     if (*arr == NULL)\n",
      "5362     {\n",
      "5363         // This allocates the metadata but not the data\n",
      "5364         *arr = (CudaNdarray *) CudaNdarray_new_nd(nd);\n",
      "5365         if (*arr == NULL)\n",
      "5366             return -1;\n",
      "5367         allocated = true;\n",
      "5368     }\n",
      "5369 \n",
      "5370     if (CudaNdarray_alloc_contiguous(*arr, nd, dims, fortran))\n",
      "5371     {\n",
      "5372         if (allocated)\n",
      "5373         {\n",
      "5374             Py_DECREF(*arr);\n",
      "5375             *arr = NULL;\n",
      "5376         }\n",
      "5377         return -1;\n",
      "5378     }\n",
      "5379     return 0;\n",
      "5380 }\n",
      "5381 \n",
      "5382 \n",
      "5383 /*\n",
      "5384   Local Variables:\n",
      "5385   mode:c++\n",
      "5386   c-basic-offset:4\n",
      "5387   c-file-style:\"stroustrup\"\n",
      "5388   indent-tabs-mode:nil\n",
      "5389   fill-column:79\n",
      "5390   End:\n",
      "5391 */\n",
      "5392 // vim: filetype=cpp:expandtab:shiftwidth=4:tabstop=8:softtabstop=4:textwidth=79 :\n",
      "5393 \n",
      "===============================\n",
      "ERROR (theano.sandbox.cuda): Failed to compile cuda_ndarray.cu: ('nvcc return status', 1, 'for cmd', 'nvcc -shared -O3 -Xlinker /DEBUG -D HAVE_ROUND -m64 -Xcompiler -DCUDA_NDARRAY_CUH=mc72d035fdf91890f3b36710688069b2e,-DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION,/Zi,/MD -I\"C:\\\\Users\\\\VIPLAB\\\\AppData\\\\Local\\\\conda\\\\conda\\\\envs\\\\keras\\\\lib\\\\site-packages\\\\theano\\\\sandbox\\\\cuda\" -I\"C:\\\\Users\\\\VIPLAB\\\\AppData\\\\Local\\\\conda\\\\conda\\\\envs\\\\keras\\\\lib\\\\site-packages\\\\numpy\\\\core\\\\include\" -I\"C:\\\\Users\\\\VIPLAB\\\\AppData\\\\Local\\\\conda\\\\conda\\\\envs\\\\keras\\\\include\" -I\"C:\\\\Users\\\\VIPLAB\\\\AppData\\\\Local\\\\conda\\\\conda\\\\envs\\\\keras\\\\lib\\\\site-packages\\\\theano\\\\gof\" -L\"C:\\\\Users\\\\VIPLAB\\\\AppData\\\\Local\\\\conda\\\\conda\\\\envs\\\\keras\\\\libs\" -L\"C:\\\\Users\\\\VIPLAB\\\\AppData\\\\Local\\\\conda\\\\conda\\\\envs\\\\keras\" -o C:\\\\Users\\\\VIPLAB\\\\AppData\\\\Local\\\\Theano\\\\compiledir_Windows-10-10.0.16299-SP0-Intel64_Family_6_Model_158_Stepping_9_GenuineIntel-3.5.3-64\\\\cuda_ndarray\\\\cuda_ndarray.pyd mod.cu -lcublas -lpython35 -lcudart')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\r\n",
      "nvcc fatal   : Cannot find compiler 'cl.exe' in PATH\r\n",
      "\n",
      "['nvcc', '-shared', '-O3', '-Xlinker', '/DEBUG', '-D HAVE_ROUND', '-m64', '-Xcompiler', '-DCUDA_NDARRAY_CUH=mc72d035fdf91890f3b36710688069b2e,-DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION,/Zi,/MD', '-I\"C:\\\\Users\\\\VIPLAB\\\\AppData\\\\Local\\\\conda\\\\conda\\\\envs\\\\keras\\\\lib\\\\site-packages\\\\theano\\\\sandbox\\\\cuda\"', '-I\"C:\\\\Users\\\\VIPLAB\\\\AppData\\\\Local\\\\conda\\\\conda\\\\envs\\\\keras\\\\lib\\\\site-packages\\\\numpy\\\\core\\\\include\"', '-I\"C:\\\\Users\\\\VIPLAB\\\\AppData\\\\Local\\\\conda\\\\conda\\\\envs\\\\keras\\\\include\"', '-I\"C:\\\\Users\\\\VIPLAB\\\\AppData\\\\Local\\\\conda\\\\conda\\\\envs\\\\keras\\\\lib\\\\site-packages\\\\theano\\\\gof\"', '-L\"C:\\\\Users\\\\VIPLAB\\\\AppData\\\\Local\\\\conda\\\\conda\\\\envs\\\\keras\\\\libs\"', '-L\"C:\\\\Users\\\\VIPLAB\\\\AppData\\\\Local\\\\conda\\\\conda\\\\envs\\\\keras\"', '-o', 'C:\\\\Users\\\\VIPLAB\\\\AppData\\\\Local\\\\Theano\\\\compiledir_Windows-10-10.0.16299-SP0-Intel64_Family_6_Model_158_Stepping_9_GenuineIntel-3.5.3-64\\\\cuda_ndarray\\\\cuda_ndarray.pyd', 'mod.cu', '-lcublas', '-lpython35', '-lcudart']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Can not use cuDNN on context None: cannot compile with cuDNN. We got this error:\n",
      "b'C:\\\\Users\\\\VIPLAB\\\\AppData\\\\Local\\\\Temp\\\\try_flags_q8kynl_b.c:4:19: fatal error: cudnn.h: No such file or directory\\r\\ncompilation terminated.\\r\\n'\n",
      "Mapped name None to device cuda: GeForce GTX 1080 Ti (0000:01:00.0)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Adapted from keras example cifar10_cnn.py\n",
    "Train ResNet-18 on the CIFAR10 small images dataset.\n",
    "\n",
    "GPU run command with Theano backend (with TensorFlow, the GPU is automatically used):\n",
    "    THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatX=float32 python cifar10.py\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ReduceLROnPlateau, CSVLogger, EarlyStopping, ModelCheckpoint\n",
    "from keras import optimizers\n",
    "\n",
    "import numpy as np\n",
    "import pandas\n",
    "import resnet\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data dir\n",
    "directory = \"./lfw_only_face_resize/\"\n",
    "train_x = []\n",
    "train_y = []\n",
    "test_x = []\n",
    "test_y = []\n",
    "threhold = 3\n",
    "count = 0\n",
    "for _dir in os.listdir(directory):\n",
    "#     >5dataset\n",
    "    people_image_count = len(os.listdir(os.path.join(directory, _dir)))\n",
    "    if(people_image_count >= threhold):\n",
    "        count += 1\n",
    "        for index, filename in enumerate(os.listdir(os.path.join(directory, _dir))):\n",
    "            if filename.endswith(\".jpg\"):\n",
    "                img_path = os.path.join(directory, _dir, filename)\n",
    "                image = Image.open(img_path)\n",
    "#                 1testing\n",
    "                if(index == 0):\n",
    "                    test_x.append(np.array(image))\n",
    "                    test_y.append(_dir)\n",
    "#                     break\n",
    "                else:\n",
    "                    train_x.append(np.array(image))\n",
    "                    train_y.append(_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "901"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x, train_y = np.array(train_x), np.array(train_y)\n",
    "test_x, test_y_name = np.array(test_x), np.array(test_y)\n",
    "train_x, test_x = train_x.astype('float32'), test_x.astype('float32')\n",
    "train_y, test_y = pandas.get_dummies(train_y).values, pandas.get_dummies(test_y_name).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x /= 255\n",
    "test_x /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-6)\n",
    "early_stopper = EarlyStopping(min_delta=0.001, patience=20)\n",
    "csv_logger = CSVLogger('resnet64_faceValidation.csv')\n",
    "# filepath=\"weights-improvement-{epoch:06d}-{val_acc:.4f}.hdf5\"\n",
    "filepath=\"weights.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(\"./model_save/\" + filepath , monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "# classes = os.listdir(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "nb_classes = count\n",
    "nb_epoch = 100000\n",
    "data_augmentation = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 104, 96\n",
    "# The CIFAR10 images are RGB.\n",
    "img_channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def load_trained_model(weights_path):\n",
    "#     model = create_model()\n",
    "#     model.load_weights(weights_path)\n",
    "#    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = resnet.ResnetBuilder.build_resnet_64((img_channels, img_rows, img_cols), nb_classes)\n",
    "model = resnet.ResnetBuilder.build_resnet_34((img_channels, img_rows, img_cols), nb_classes)\n",
    "# model.compile(loss='categorical_crossentropy',\n",
    "#               optimizer='adam',\n",
    "#               metrics=['accuracy'])\n",
    "# sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "sgd = optimizers.SGD(lr=0.1, decay=5e-4, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6705, 104, 96, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6705, 901)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5364 samples, validate on 1341 samples\n",
      "Epoch 1/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 7.2742 - acc: 0.1202Epoch 00001: val_acc improved from -inf to 0.00000, saving model to ./model_save/weights.best.hdf5\n",
      "5364/5364 [==============================] - 167s 31ms/step - loss: 7.2576 - acc: 0.1217 - val_loss: 13.0987 - val_acc: 0.0000e+00\n",
      "Epoch 2/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 6.2094 - acc: 0.2319Epoch 00002: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 6.2020 - acc: 0.2340 - val_loss: 12.6443 - val_acc: 0.0000e+00\n",
      "Epoch 3/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 5.2848 - acc: 0.3542Epoch 00003: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 5.2857 - acc: 0.3538 - val_loss: 10.7900 - val_acc: 0.0000e+00\n",
      "Epoch 4/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 4.3691 - acc: 0.4809Epoch 00004: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 4.3768 - acc: 0.4802 - val_loss: 11.5050 - val_acc: 0.0000e+00\n",
      "Epoch 5/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 3.4679 - acc: 0.6189Epoch 00005: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 3.4704 - acc: 0.6188 - val_loss: 12.4563 - val_acc: 0.0000e+00\n",
      "Epoch 6/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 2.6462 - acc: 0.7853Epoch 00006: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 2.6427 - acc: 0.7858 - val_loss: 13.9657 - val_acc: 0.0000e+00\n",
      "Epoch 7/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.9757 - acc: 0.9390Epoch 00007: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.9723 - acc: 0.9394 - val_loss: 13.3656 - val_acc: 0.0000e+00\n",
      "Epoch 8/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.5716 - acc: 0.9962Epoch 00008: val_acc improved from 0.00000 to 0.00075, saving model to ./model_save/weights.best.hdf5\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.5705 - acc: 0.9963 - val_loss: 13.6255 - val_acc: 7.4571e-04\n",
      "Epoch 9/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.4412 - acc: 1.0000Epoch 00009: val_acc improved from 0.00075 to 0.00149, saving model to ./model_save/weights.best.hdf5\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.4409 - acc: 1.0000 - val_loss: 13.9247 - val_acc: 0.0015\n",
      "Epoch 10/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.4115 - acc: 1.0000Epoch 00010: val_acc improved from 0.00149 to 0.00224, saving model to ./model_save/weights.best.hdf5\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.4114 - acc: 1.0000 - val_loss: 14.1763 - val_acc: 0.0022\n",
      "Epoch 11/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.4027 - acc: 1.0000Epoch 00011: val_acc improved from 0.00224 to 0.00373, saving model to ./model_save/weights.best.hdf5\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.4028 - acc: 1.0000 - val_loss: 14.3266 - val_acc: 0.0037\n",
      "Epoch 12/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3960 - acc: 1.0000Epoch 00012: val_acc improved from 0.00373 to 0.00447, saving model to ./model_save/weights.best.hdf5\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3959 - acc: 1.0000 - val_loss: 14.4430 - val_acc: 0.0045\n",
      "Epoch 13/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3894 - acc: 1.0000Epoch 00013: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3894 - acc: 1.0000 - val_loss: 14.5553 - val_acc: 0.0045\n",
      "Epoch 14/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3832 - acc: 1.0000Epoch 00014: val_acc improved from 0.00447 to 0.00522, saving model to ./model_save/weights.best.hdf5\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3831 - acc: 1.0000 - val_loss: 14.6110 - val_acc: 0.0052\n",
      "Epoch 15/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3783 - acc: 1.0000Epoch 00015: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3783 - acc: 1.0000 - val_loss: 14.6506 - val_acc: 0.0052\n",
      "Epoch 16/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3763 - acc: 1.0000Epoch 00016: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3763 - acc: 1.0000 - val_loss: 14.6791 - val_acc: 0.0052\n",
      "Epoch 17/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3743 - acc: 1.0000Epoch 00017: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3743 - acc: 1.0000 - val_loss: 14.6900 - val_acc: 0.0052\n",
      "Epoch 18/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3725 - acc: 1.0000Epoch 00018: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3725 - acc: 1.0000 - val_loss: 14.7013 - val_acc: 0.0052\n",
      "Epoch 19/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3709 - acc: 1.0000Epoch 00019: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3708 - acc: 1.0000 - val_loss: 14.7249 - val_acc: 0.0052\n",
      "Epoch 20/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3693 - acc: 1.0000Epoch 00020: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3694 - acc: 1.0000 - val_loss: 14.7307 - val_acc: 0.0052\n",
      "Epoch 21/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3688 - acc: 1.0000Epoch 00021: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3688 - acc: 1.0000 - val_loss: 14.7348 - val_acc: 0.0052\n",
      "Epoch 22/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3683 - acc: 1.0000Epoch 00022: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3683 - acc: 1.0000 - val_loss: 14.7390 - val_acc: 0.0052\n",
      "Epoch 23/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3678 - acc: 1.0000Epoch 00023: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3678 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 24/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3672 - acc: 1.0000Epoch 00024: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3672 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 25/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3668 - acc: 1.0000Epoch 00025: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3668 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 26/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3667 - acc: 1.0000Epoch 00026: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3666 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 27/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3664 - acc: 1.0000Epoch 00027: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3665 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 28/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3662 - acc: 1.0000Epoch 00028: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3662 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 29/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3662 - acc: 1.0000Epoch 00029: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3662 - acc: 1.0000 - val_loss: 14.7430 - val_acc: 0.0052\n",
      "Epoch 30/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3661 - acc: 1.0000Epoch 00030: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3661 - acc: 1.0000 - val_loss: 14.7429 - val_acc: 0.0052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3660 - acc: 1.0000Epoch 00031: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3660 - acc: 1.0000 - val_loss: 14.7431 - val_acc: 0.0052\n",
      "Epoch 32/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00032: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3660 - acc: 1.0000 - val_loss: 14.7436 - val_acc: 0.0052\n",
      "Epoch 33/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00033: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 34/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00034: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 35/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00035: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 36/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00036: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 37/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00037: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7466 - val_acc: 0.0052\n",
      "Epoch 38/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00038: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 39/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00039: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 40/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00040: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 41/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00041: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 42/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00042: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 43/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00043: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7438 - val_acc: 0.0052\n",
      "Epoch 44/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00044: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 45/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00045: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 46/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00046: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 47/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00047: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 48/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00048: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 49/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00049: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 50/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00050: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 51/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00051: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 52/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00052: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 53/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00053: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 54/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00054: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7436 - val_acc: 0.0052\n",
      "Epoch 55/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00055: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7462 - val_acc: 0.0052\n",
      "Epoch 56/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00056: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 57/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00057: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7466 - val_acc: 0.0052\n",
      "Epoch 58/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00058: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7461 - val_acc: 0.0052\n",
      "Epoch 59/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00059: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 60/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00060: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 61/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00061: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 62/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00062: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7462 - val_acc: 0.0052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00063: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 64/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00064: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 65/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00065: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 66/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00066: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 67/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00067: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 68/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00068: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 69/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00069: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 70/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00070: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7465 - val_acc: 0.0052\n",
      "Epoch 71/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00071: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7470 - val_acc: 0.0052\n",
      "Epoch 72/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00072: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 73/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00073: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7465 - val_acc: 0.0052\n",
      "Epoch 74/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00074: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7469 - val_acc: 0.0052\n",
      "Epoch 75/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00075: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 76/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00076: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 77/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00077: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7466 - val_acc: 0.0052\n",
      "Epoch 78/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00078: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7460 - val_acc: 0.0052\n",
      "Epoch 79/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00079: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 80/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00080: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 81/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00081: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 82/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00082: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 83/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00083: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 84/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00084: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 85/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00085: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 86/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00086: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7459 - val_acc: 0.0052\n",
      "Epoch 87/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00087: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 88/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00088: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 89/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00089: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 90/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00090: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 91/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00091: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 92/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00092: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 93/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00093: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 94/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00094: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7439 - val_acc: 0.0052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00095: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 96/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00096: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 97/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00097: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 98/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00098: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7461 - val_acc: 0.0052\n",
      "Epoch 99/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00099: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 100/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00100: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 101/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00101: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 102/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00102: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 103/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00103: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 104/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00104: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 105/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00105: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7461 - val_acc: 0.0052\n",
      "Epoch 106/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00106: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7468 - val_acc: 0.0052\n",
      "Epoch 107/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00107: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7462 - val_acc: 0.0052\n",
      "Epoch 108/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00108: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7463 - val_acc: 0.0052\n",
      "Epoch 109/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00109: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7463 - val_acc: 0.0052\n",
      "Epoch 110/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00110: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7465 - val_acc: 0.0052\n",
      "Epoch 111/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00111: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 112/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00112: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 113/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00113: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 114/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00114: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7436 - val_acc: 0.0052\n",
      "Epoch 115/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00115: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 116/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00116: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 117/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00117: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7440 - val_acc: 0.0052\n",
      "Epoch 118/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00118: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7440 - val_acc: 0.0052\n",
      "Epoch 119/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00119: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 120/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00120: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7439 - val_acc: 0.0052\n",
      "Epoch 121/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00121: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7439 - val_acc: 0.0052\n",
      "Epoch 122/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00122: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7437 - val_acc: 0.0052\n",
      "Epoch 123/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00123: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7464 - val_acc: 0.0052\n",
      "Epoch 124/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00124: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7468 - val_acc: 0.0052\n",
      "Epoch 125/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00125: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7470 - val_acc: 0.0052\n",
      "Epoch 126/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00126: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 127/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00127: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 128/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00128: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7465 - val_acc: 0.0052\n",
      "Epoch 129/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00129: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 130/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00130: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 131/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00131: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 132/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00132: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 133/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00133: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 134/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00134: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 135/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00135: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 136/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00136: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 137/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00137: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 138/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00138: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 139/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00139: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 140/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00140: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7466 - val_acc: 0.0052\n",
      "Epoch 141/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00141: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7468 - val_acc: 0.0052\n",
      "Epoch 142/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00142: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7474 - val_acc: 0.0052\n",
      "Epoch 143/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00143: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7472 - val_acc: 0.0052\n",
      "Epoch 144/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00144: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 145/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00145: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 146/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00146: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7461 - val_acc: 0.0052\n",
      "Epoch 147/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00147: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7461 - val_acc: 0.0052\n",
      "Epoch 148/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00148: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7462 - val_acc: 0.0052\n",
      "Epoch 149/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00149: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7439 - val_acc: 0.0052\n",
      "Epoch 150/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00150: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7433 - val_acc: 0.0052\n",
      "Epoch 151/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00151: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 152/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00152: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7466 - val_acc: 0.0052\n",
      "Epoch 153/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00153: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7465 - val_acc: 0.0052\n",
      "Epoch 154/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00154: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 155/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00155: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 156/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00156: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 157/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00157: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 158/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00158: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 159/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00159: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7436 - val_acc: 0.0052\n",
      "Epoch 160/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00160: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 161/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00161: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 162/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00162: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7434 - val_acc: 0.0052\n",
      "Epoch 163/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00163: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7439 - val_acc: 0.0052\n",
      "Epoch 164/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00164: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 165/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00165: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 166/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00166: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7460 - val_acc: 0.0052\n",
      "Epoch 167/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00167: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7461 - val_acc: 0.0052\n",
      "Epoch 168/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00168: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7467 - val_acc: 0.0052\n",
      "Epoch 169/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00169: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7460 - val_acc: 0.0052\n",
      "Epoch 170/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00170: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7464 - val_acc: 0.0052\n",
      "Epoch 171/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00171: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 172/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00172: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 173/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00173: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 174/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00174: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7474 - val_acc: 0.0052\n",
      "Epoch 175/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00175: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7483 - val_acc: 0.0052\n",
      "Epoch 176/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00176: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7474 - val_acc: 0.0052\n",
      "Epoch 177/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00177: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7465 - val_acc: 0.0052\n",
      "Epoch 178/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00178: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 179/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00179: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7465 - val_acc: 0.0052\n",
      "Epoch 180/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00180: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7468 - val_acc: 0.0052\n",
      "Epoch 181/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00181: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7461 - val_acc: 0.0052\n",
      "Epoch 182/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00182: val_acc did not improve\n",
      "5364/5364 [==============================] - 164s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7463 - val_acc: 0.0052\n",
      "Epoch 183/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00183: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 184/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00184: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7459 - val_acc: 0.0052\n",
      "Epoch 185/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00185: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 186/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00186: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 187/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00187: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 188/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00188: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7462 - val_acc: 0.0052\n",
      "Epoch 189/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00189: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7461 - val_acc: 0.0052\n",
      "Epoch 190/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00190: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7467 - val_acc: 0.0052\n",
      "Epoch 191/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00191: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7466 - val_acc: 0.0052\n",
      "Epoch 192/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00192: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7461 - val_acc: 0.0052\n",
      "Epoch 193/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00193: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 194/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00194: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7435 - val_acc: 0.0052\n",
      "Epoch 195/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00195: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7427 - val_acc: 0.0052\n",
      "Epoch 196/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00196: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7435 - val_acc: 0.0052\n",
      "Epoch 197/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00197: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7439 - val_acc: 0.0052\n",
      "Epoch 198/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00198: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7432 - val_acc: 0.0052\n",
      "Epoch 199/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00199: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7433 - val_acc: 0.0052\n",
      "Epoch 200/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00200: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7431 - val_acc: 0.0052\n",
      "Epoch 201/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00201: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7429 - val_acc: 0.0052\n",
      "Epoch 202/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00202: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7435 - val_acc: 0.0052\n",
      "Epoch 203/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00203: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7431 - val_acc: 0.0052\n",
      "Epoch 204/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00204: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7435 - val_acc: 0.0052\n",
      "Epoch 205/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00205: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7430 - val_acc: 0.0052\n",
      "Epoch 206/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00206: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7439 - val_acc: 0.0052\n",
      "Epoch 207/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00207: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 208/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00208: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7462 - val_acc: 0.0052\n",
      "Epoch 209/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00209: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7460 - val_acc: 0.0052\n",
      "Epoch 210/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00210: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7464 - val_acc: 0.0052\n",
      "Epoch 211/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00211: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7468 - val_acc: 0.0052\n",
      "Epoch 212/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00212: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7459 - val_acc: 0.0052\n",
      "Epoch 213/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00213: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 214/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00214: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 215/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00215: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 216/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00216: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 217/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00217: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 218/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00218: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7465 - val_acc: 0.0052\n",
      "Epoch 219/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00219: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7460 - val_acc: 0.0052\n",
      "Epoch 220/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00220: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 221/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00221: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 222/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00222: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 223/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00223: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7465 - val_acc: 0.0052\n",
      "Epoch 224/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00224: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 225/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00225: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 226/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00226: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 227/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00227: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 228/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00228: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 229/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00229: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 230/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00230: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 231/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00231: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 232/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00232: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 233/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00233: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 234/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00234: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 235/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00235: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 236/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00236: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7469 - val_acc: 0.0052\n",
      "Epoch 237/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00237: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7467 - val_acc: 0.0052\n",
      "Epoch 238/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00238: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7462 - val_acc: 0.0052\n",
      "Epoch 239/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00239: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7475 - val_acc: 0.0052\n",
      "Epoch 240/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00240: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7468 - val_acc: 0.0052\n",
      "Epoch 241/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00241: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 242/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00242: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 243/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00243: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 244/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00244: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7439 - val_acc: 0.0052\n",
      "Epoch 245/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00245: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 246/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00246: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 247/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00247: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7438 - val_acc: 0.0052\n",
      "Epoch 248/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00248: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7426 - val_acc: 0.0052\n",
      "Epoch 249/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00249: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 250/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00250: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 251/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00251: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7440 - val_acc: 0.0052\n",
      "Epoch 252/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00252: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 253/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00253: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7438 - val_acc: 0.0052\n",
      "Epoch 254/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00254: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 255/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00255: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 256/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00256: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 257/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00257: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7461 - val_acc: 0.0052\n",
      "Epoch 258/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00258: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 259/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00259: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 260/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00260: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 261/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00261: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 262/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00262: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 263/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00263: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 264/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00264: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 265/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00265: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7434 - val_acc: 0.0052\n",
      "Epoch 266/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00266: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 267/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00267: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7433 - val_acc: 0.0052\n",
      "Epoch 268/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00268: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 269/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00269: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7461 - val_acc: 0.0052\n",
      "Epoch 270/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00270: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7440 - val_acc: 0.0052\n",
      "Epoch 271/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00271: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 272/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00272: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 273/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00273: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 274/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00274: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 275/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00275: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7459 - val_acc: 0.0052\n",
      "Epoch 276/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00276: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7461 - val_acc: 0.0052\n",
      "Epoch 277/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00277: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 278/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00278: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7438 - val_acc: 0.0052\n",
      "Epoch 279/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00279: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7432 - val_acc: 0.0052\n",
      "Epoch 280/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00280: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7432 - val_acc: 0.0052\n",
      "Epoch 281/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00281: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 282/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00282: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 283/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00283: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 284/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00284: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 285/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00285: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7460 - val_acc: 0.0052\n",
      "Epoch 286/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00286: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 287/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00287: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7464 - val_acc: 0.0052\n",
      "Epoch 288/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00288: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7472 - val_acc: 0.0052\n",
      "Epoch 289/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00289: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 290/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00290: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 291/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00291: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 292/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00292: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7437 - val_acc: 0.0052\n",
      "Epoch 293/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00293: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7438 - val_acc: 0.0052\n",
      "Epoch 294/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00294: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 295/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00295: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 296/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00296: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 297/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00297: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 298/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00298: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 299/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00299: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 300/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00300: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7472 - val_acc: 0.0052\n",
      "Epoch 301/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00301: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7461 - val_acc: 0.0052\n",
      "Epoch 302/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00302: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 303/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00303: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 304/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00304: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 305/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00305: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 306/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00306: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7474 - val_acc: 0.0052\n",
      "Epoch 307/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00307: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7462 - val_acc: 0.0052\n",
      "Epoch 308/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00308: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 309/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00309: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 310/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00310: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 311/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00311: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 312/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00312: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 313/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00313: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7459 - val_acc: 0.0052\n",
      "Epoch 314/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00314: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 315/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00315: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7459 - val_acc: 0.0052\n",
      "Epoch 316/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00316: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7461 - val_acc: 0.0052\n",
      "Epoch 317/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00317: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7464 - val_acc: 0.0052\n",
      "Epoch 318/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00318: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 319/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00319: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 320/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00320: val_acc did not improve\n",
      "5364/5364 [==============================] - 162s 30ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 321/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00321: val_acc did not improve\n",
      "5364/5364 [==============================] - 162s 30ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 322/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00322: val_acc did not improve\n",
      "5364/5364 [==============================] - 162s 30ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7463 - val_acc: 0.0052\n",
      "Epoch 323/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00323: val_acc did not improve\n",
      "5364/5364 [==============================] - 162s 30ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7464 - val_acc: 0.0052\n",
      "Epoch 324/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00324: val_acc did not improve\n",
      "5364/5364 [==============================] - 162s 30ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7469 - val_acc: 0.0052\n",
      "Epoch 325/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00325: val_acc did not improve\n",
      "5364/5364 [==============================] - 162s 30ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7472 - val_acc: 0.0052\n",
      "Epoch 326/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00326: val_acc did not improve\n",
      "5364/5364 [==============================] - 163s 30ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7474 - val_acc: 0.0052\n",
      "Epoch 327/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00327: val_acc did not improve\n",
      "5364/5364 [==============================] - 163s 30ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7461 - val_acc: 0.0052\n",
      "Epoch 328/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00328: val_acc did not improve\n",
      "5364/5364 [==============================] - 163s 30ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7471 - val_acc: 0.0052\n",
      "Epoch 329/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00329: val_acc did not improve\n",
      "5364/5364 [==============================] - 163s 30ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7461 - val_acc: 0.0052\n",
      "Epoch 330/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00330: val_acc did not improve\n",
      "5364/5364 [==============================] - 163s 30ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7471 - val_acc: 0.0052\n",
      "Epoch 331/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00331: val_acc did not improve\n",
      "5364/5364 [==============================] - 163s 30ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7466 - val_acc: 0.0052\n",
      "Epoch 332/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00332: val_acc did not improve\n",
      "5364/5364 [==============================] - 163s 30ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 333/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00333: val_acc did not improve\n",
      "5364/5364 [==============================] - 163s 30ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 334/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00334: val_acc did not improve\n",
      "5364/5364 [==============================] - 163s 30ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7433 - val_acc: 0.0052\n",
      "Epoch 335/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00335: val_acc did not improve\n",
      "5364/5364 [==============================] - 163s 30ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7439 - val_acc: 0.0052\n",
      "Epoch 336/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00336: val_acc did not improve\n",
      "5364/5364 [==============================] - 163s 30ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7430 - val_acc: 0.0052\n",
      "Epoch 337/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00337: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7440 - val_acc: 0.0052\n",
      "Epoch 338/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00338: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7423 - val_acc: 0.0052\n",
      "Epoch 339/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00339: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7424 - val_acc: 0.0052\n",
      "Epoch 340/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00340: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7430 - val_acc: 0.0052\n",
      "Epoch 341/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00341: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7432 - val_acc: 0.0052\n",
      "Epoch 342/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00342: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7430 - val_acc: 0.0052\n",
      "Epoch 343/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00343: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 344/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00344: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7435 - val_acc: 0.0052\n",
      "Epoch 345/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3656 - acc: 1.0000Epoch 00345: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3656 - acc: 1.0000 - val_loss: 14.7425 - val_acc: 0.0052\n",
      "Epoch 346/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00346: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7424 - val_acc: 0.0052\n",
      "Epoch 347/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00347: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 348/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00348: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 349/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00349: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 350/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00350: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7463 - val_acc: 0.0052\n",
      "Epoch 351/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00351: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7460 - val_acc: 0.0052\n",
      "Epoch 352/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00352: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 353/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00353: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 354/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00354: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 355/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00355: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 356/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00356: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7430 - val_acc: 0.0052\n",
      "Epoch 357/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00357: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7431 - val_acc: 0.0052\n",
      "Epoch 358/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00358: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7430 - val_acc: 0.0052\n",
      "Epoch 359/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00359: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 360/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00360: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 361/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00361: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7437 - val_acc: 0.0052\n",
      "Epoch 362/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00362: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 363/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00363: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7459 - val_acc: 0.0052\n",
      "Epoch 364/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00364: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 365/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00365: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7464 - val_acc: 0.0052\n",
      "Epoch 366/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00366: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7463 - val_acc: 0.0052\n",
      "Epoch 367/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00367: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7461 - val_acc: 0.0052\n",
      "Epoch 368/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00368: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 369/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00369: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7437 - val_acc: 0.0052\n",
      "Epoch 370/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00370: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 371/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00371: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 372/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00372: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 373/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00373: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 374/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00374: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7440 - val_acc: 0.0052\n",
      "Epoch 375/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00375: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 376/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00376: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7464 - val_acc: 0.0052\n",
      "Epoch 377/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00377: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 378/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00378: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 379/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00379: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 380/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00380: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 381/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00381: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 382/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00382: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7435 - val_acc: 0.0052\n",
      "Epoch 383/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00383: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 384/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00384: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7438 - val_acc: 0.0052\n",
      "Epoch 385/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00385: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 386/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00386: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 387/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00387: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 388/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00388: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 389/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00389: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7436 - val_acc: 0.0052\n",
      "Epoch 390/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00390: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7440 - val_acc: 0.0052\n",
      "Epoch 391/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00391: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 392/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00392: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 393/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00393: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 394/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00394: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 395/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00395: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 396/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00396: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 397/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00397: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 398/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00398: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 399/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00399: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 400/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00400: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 401/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00401: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 402/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3656 - acc: 1.0000Epoch 00402: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7427 - val_acc: 0.0052\n",
      "Epoch 403/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00403: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7429 - val_acc: 0.0052\n",
      "Epoch 404/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00404: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7434 - val_acc: 0.0052\n",
      "Epoch 405/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00405: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 406/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00406: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 407/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00407: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7437 - val_acc: 0.0052\n",
      "Epoch 408/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00408: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7437 - val_acc: 0.0052\n",
      "Epoch 409/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00409: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 410/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00410: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 411/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00411: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 412/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00412: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 413/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00413: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7459 - val_acc: 0.0052\n",
      "Epoch 414/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00414: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 415/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00415: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 416/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00416: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7436 - val_acc: 0.0052\n",
      "Epoch 417/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00417: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7438 - val_acc: 0.0052\n",
      "Epoch 418/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00418: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7439 - val_acc: 0.0052\n",
      "Epoch 419/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00419: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 420/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00420: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7459 - val_acc: 0.0052\n",
      "Epoch 421/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00421: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 422/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00422: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 423/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00423: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 424/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00424: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 425/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00425: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 426/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00426: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7460 - val_acc: 0.0052\n",
      "Epoch 427/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00427: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 428/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00428: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7435 - val_acc: 0.0052\n",
      "Epoch 429/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00429: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 430/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00430: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 431/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00431: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 432/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00432: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 433/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00433: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 434/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00434: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 435/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3660 - acc: 1.0000Epoch 00435: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3660 - acc: 1.0000 - val_loss: 14.7465 - val_acc: 0.0052\n",
      "Epoch 436/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00436: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7467 - val_acc: 0.0052\n",
      "Epoch 437/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00437: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 438/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00438: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 439/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00439: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7461 - val_acc: 0.0052\n",
      "Epoch 440/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00440: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 441/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00441: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7459 - val_acc: 0.0052\n",
      "Epoch 442/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00442: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7469 - val_acc: 0.0052\n",
      "Epoch 443/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00443: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7468 - val_acc: 0.0052\n",
      "Epoch 444/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00444: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7465 - val_acc: 0.0052\n",
      "Epoch 445/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00445: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 446/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00446: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 447/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00447: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 448/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00448: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7459 - val_acc: 0.0052\n",
      "Epoch 449/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00449: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 450/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00450: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7438 - val_acc: 0.0052\n",
      "Epoch 451/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00451: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 452/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00452: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 453/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00453: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7439 - val_acc: 0.0052\n",
      "Epoch 454/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00454: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 455/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00455: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 456/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00456: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 457/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00457: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 458/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00458: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7435 - val_acc: 0.0052\n",
      "Epoch 459/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00459: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 460/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00460: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 461/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00461: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 462/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00462: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 463/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00463: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 464/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00464: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 465/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00465: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 466/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00466: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 467/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00467: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7464 - val_acc: 0.0052\n",
      "Epoch 468/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00468: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 469/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00469: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7465 - val_acc: 0.0052\n",
      "Epoch 470/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00470: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 471/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00471: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7470 - val_acc: 0.0052\n",
      "Epoch 472/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00472: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 473/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00473: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 474/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00474: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7460 - val_acc: 0.0052\n",
      "Epoch 475/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00475: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 476/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00476: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7439 - val_acc: 0.0052\n",
      "Epoch 477/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00477: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 478/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00478: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7434 - val_acc: 0.0052\n",
      "Epoch 479/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00479: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7436 - val_acc: 0.0052\n",
      "Epoch 480/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00480: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7431 - val_acc: 0.0052\n",
      "Epoch 481/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00481: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7438 - val_acc: 0.0052\n",
      "Epoch 482/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00482: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 483/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00483: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 484/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00484: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7468 - val_acc: 0.0052\n",
      "Epoch 485/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00485: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7465 - val_acc: 0.0052\n",
      "Epoch 486/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00486: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7475 - val_acc: 0.0052\n",
      "Epoch 487/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00487: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 488/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00488: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 489/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00489: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7459 - val_acc: 0.0052\n",
      "Epoch 490/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00490: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7469 - val_acc: 0.0052\n",
      "Epoch 491/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00491: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7466 - val_acc: 0.0052\n",
      "Epoch 492/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00492: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 493/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00493: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 494/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00494: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7427 - val_acc: 0.0052\n",
      "Epoch 495/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00495: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7423 - val_acc: 0.0052\n",
      "Epoch 496/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00496: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7432 - val_acc: 0.0052\n",
      "Epoch 497/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00497: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7436 - val_acc: 0.0052\n",
      "Epoch 498/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00498: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 499/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00499: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 500/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00500: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7470 - val_acc: 0.0052\n",
      "Epoch 501/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00501: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7460 - val_acc: 0.0052\n",
      "Epoch 502/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00502: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 503/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00503: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7437 - val_acc: 0.0052\n",
      "Epoch 504/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00504: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7435 - val_acc: 0.0052\n",
      "Epoch 505/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00505: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7428 - val_acc: 0.0052\n",
      "Epoch 506/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00506: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7438 - val_acc: 0.0052\n",
      "Epoch 507/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00507: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 508/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00508: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 509/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00509: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 510/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00510: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 511/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00511: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7439 - val_acc: 0.0052\n",
      "Epoch 512/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00512: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 513/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00513: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7462 - val_acc: 0.0052\n",
      "Epoch 514/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00514: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7461 - val_acc: 0.0052\n",
      "Epoch 515/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00515: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7467 - val_acc: 0.0052\n",
      "Epoch 516/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00516: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7467 - val_acc: 0.0052\n",
      "Epoch 517/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00517: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7468 - val_acc: 0.0052\n",
      "Epoch 518/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00518: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 519/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00519: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7468 - val_acc: 0.0052\n",
      "Epoch 520/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00520: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7470 - val_acc: 0.0052\n",
      "Epoch 521/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00521: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7464 - val_acc: 0.0052\n",
      "Epoch 522/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00522: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 523/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00523: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7462 - val_acc: 0.0052\n",
      "Epoch 524/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00524: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 525/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00525: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 526/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00526: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7459 - val_acc: 0.0052\n",
      "Epoch 527/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00527: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 528/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00528: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 529/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00529: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7428 - val_acc: 0.0052\n",
      "Epoch 530/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00530: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7434 - val_acc: 0.0052\n",
      "Epoch 531/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00531: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 532/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00532: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 533/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00533: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 534/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00534: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7439 - val_acc: 0.0052\n",
      "Epoch 535/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00535: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 536/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00536: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 537/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00537: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7439 - val_acc: 0.0052\n",
      "Epoch 538/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00538: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7440 - val_acc: 0.0052\n",
      "Epoch 539/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00539: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 540/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00540: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7436 - val_acc: 0.0052\n",
      "Epoch 541/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00541: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 542/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00542: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7437 - val_acc: 0.0052\n",
      "Epoch 543/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00543: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 544/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00544: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7434 - val_acc: 0.0052\n",
      "Epoch 545/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00545: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 546/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00546: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7437 - val_acc: 0.0052\n",
      "Epoch 547/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00547: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 548/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00548: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7461 - val_acc: 0.0052\n",
      "Epoch 549/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00549: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 550/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00550: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 551/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00551: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 552/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00552: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 553/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00553: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7440 - val_acc: 0.0052\n",
      "Epoch 554/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00554: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7433 - val_acc: 0.0052\n",
      "Epoch 555/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00555: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7433 - val_acc: 0.0052\n",
      "Epoch 556/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00556: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 557/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00557: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7459 - val_acc: 0.0052\n",
      "Epoch 558/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00558: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7461 - val_acc: 0.0052\n",
      "Epoch 559/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00559: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7462 - val_acc: 0.0052\n",
      "Epoch 560/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00560: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 561/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00561: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 562/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00562: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 563/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00563: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 564/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00564: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 565/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00565: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 566/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00566: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 567/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00567: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 568/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00568: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 569/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00569: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 570/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00570: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 571/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00571: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 572/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00572: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 573/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00573: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 574/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00574: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7437 - val_acc: 0.0052\n",
      "Epoch 575/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00575: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7433 - val_acc: 0.0052\n",
      "Epoch 576/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00576: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7437 - val_acc: 0.0052\n",
      "Epoch 577/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00577: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7440 - val_acc: 0.0052\n",
      "Epoch 578/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00578: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 579/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00579: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 580/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00580: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 581/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00581: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 582/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00582: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 583/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00583: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7469 - val_acc: 0.0052\n",
      "Epoch 584/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00584: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 585/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00585: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 586/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00586: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7460 - val_acc: 0.0052\n",
      "Epoch 587/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00587: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 588/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00588: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 589/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00589: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 590/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00590: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7463 - val_acc: 0.0052\n",
      "Epoch 591/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00591: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 592/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00592: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7460 - val_acc: 0.0052\n",
      "Epoch 593/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00593: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7464 - val_acc: 0.0052\n",
      "Epoch 594/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00594: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 595/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00595: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 596/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00596: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7438 - val_acc: 0.0052\n",
      "Epoch 597/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00597: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 598/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00598: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 599/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00599: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 600/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00600: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7459 - val_acc: 0.0052\n",
      "Epoch 601/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00601: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 602/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00602: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 603/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00603: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 604/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00604: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7467 - val_acc: 0.0052\n",
      "Epoch 605/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00605: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7473 - val_acc: 0.0052\n",
      "Epoch 606/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00606: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7463 - val_acc: 0.0052\n",
      "Epoch 607/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00607: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 608/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00608: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 609/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00609: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 610/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00610: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 611/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00611: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 612/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00612: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 613/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00613: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 614/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00614: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7463 - val_acc: 0.0052\n",
      "Epoch 615/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00615: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7460 - val_acc: 0.0052\n",
      "Epoch 616/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00616: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7462 - val_acc: 0.0052\n",
      "Epoch 617/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00617: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 618/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00618: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 619/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00619: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 620/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00620: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 621/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00621: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 622/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00622: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 623/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00623: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 624/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00624: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 625/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00625: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 626/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00626: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 627/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00627: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 628/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00628: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 629/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00629: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 630/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00630: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 631/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00631: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7463 - val_acc: 0.0052\n",
      "Epoch 632/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00632: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 633/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00633: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7439 - val_acc: 0.0052\n",
      "Epoch 634/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00634: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 635/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00635: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 636/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00636: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 637/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00637: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 638/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00638: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 639/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00639: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 640/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00640: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7430 - val_acc: 0.0052\n",
      "Epoch 641/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00641: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7435 - val_acc: 0.0052\n",
      "Epoch 642/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3660 - acc: 1.0000Epoch 00642: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 643/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00643: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7430 - val_acc: 0.0052\n",
      "Epoch 644/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00644: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7424 - val_acc: 0.0052\n",
      "Epoch 645/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00645: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7419 - val_acc: 0.0052\n",
      "Epoch 646/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00646: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 647/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00647: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 648/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00648: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 649/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00649: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 650/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00650: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7459 - val_acc: 0.0052\n",
      "Epoch 651/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00651: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 652/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00652: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 653/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00653: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7464 - val_acc: 0.0052\n",
      "Epoch 654/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00654: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 655/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00655: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 656/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00656: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7438 - val_acc: 0.0052\n",
      "Epoch 657/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00657: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 658/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00658: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 659/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00659: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 660/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00660: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 661/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00661: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 662/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00662: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 663/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00663: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 664/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00664: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7434 - val_acc: 0.0052\n",
      "Epoch 665/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00665: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 666/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00666: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 667/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00667: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7464 - val_acc: 0.0052\n",
      "Epoch 668/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00668: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7464 - val_acc: 0.0052\n",
      "Epoch 669/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00669: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7461 - val_acc: 0.0052\n",
      "Epoch 670/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00670: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 671/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00671: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7435 - val_acc: 0.0052\n",
      "Epoch 672/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00672: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 673/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00673: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7467 - val_acc: 0.0052\n",
      "Epoch 674/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00674: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7464 - val_acc: 0.0052\n",
      "Epoch 675/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00675: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 676/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00676: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 677/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00677: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 678/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00678: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 679/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00679: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7471 - val_acc: 0.0052\n",
      "Epoch 680/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00680: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7466 - val_acc: 0.0052\n",
      "Epoch 681/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00681: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 682/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00682: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 683/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00683: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 684/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00684: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 685/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00685: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 686/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00686: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 687/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00687: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 688/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00688: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7465 - val_acc: 0.0052\n",
      "Epoch 689/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00689: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 690/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00690: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7467 - val_acc: 0.0052\n",
      "Epoch 691/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00691: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 692/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00692: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 693/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00693: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 694/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00694: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7459 - val_acc: 0.0052\n",
      "Epoch 695/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00695: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 696/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00696: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7460 - val_acc: 0.0052\n",
      "Epoch 697/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00697: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7462 - val_acc: 0.0052\n",
      "Epoch 698/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00698: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 699/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00699: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 700/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00700: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 701/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00701: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7430 - val_acc: 0.0052\n",
      "Epoch 702/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00702: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7437 - val_acc: 0.0052\n",
      "Epoch 703/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00703: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 704/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00704: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7428 - val_acc: 0.0052\n",
      "Epoch 705/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00705: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7429 - val_acc: 0.0052\n",
      "Epoch 706/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00706: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7428 - val_acc: 0.0052\n",
      "Epoch 707/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00707: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 708/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00708: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 709/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00709: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 710/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00710: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 711/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00711: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 712/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00712: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7440 - val_acc: 0.0052\n",
      "Epoch 713/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00713: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 714/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00714: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 715/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00715: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 716/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00716: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 717/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00717: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 718/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00718: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 719/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00719: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 720/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00720: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 721/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00721: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 722/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00722: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 723/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00723: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 724/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00724: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 725/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00725: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 726/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00726: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 727/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00727: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7462 - val_acc: 0.0052\n",
      "Epoch 728/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00728: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 729/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00729: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 730/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00730: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 731/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00731: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7437 - val_acc: 0.0052\n",
      "Epoch 732/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00732: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 733/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00733: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 734/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00734: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 735/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00735: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7438 - val_acc: 0.0052\n",
      "Epoch 736/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00736: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7436 - val_acc: 0.0052\n",
      "Epoch 737/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00737: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 738/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00738: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 739/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00739: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 740/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00740: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 741/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00741: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 742/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00742: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7440 - val_acc: 0.0052\n",
      "Epoch 743/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00743: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7440 - val_acc: 0.0052\n",
      "Epoch 744/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00744: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 745/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00745: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 746/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00746: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7435 - val_acc: 0.0052\n",
      "Epoch 747/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00747: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7438 - val_acc: 0.0052\n",
      "Epoch 748/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00748: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 749/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00749: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 750/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00750: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 751/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00751: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7460 - val_acc: 0.0052\n",
      "Epoch 752/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00752: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 753/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00753: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 754/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00754: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 755/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00755: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 756/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00756: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 757/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00757: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 758/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00758: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 759/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00759: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 760/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00760: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7467 - val_acc: 0.0052\n",
      "Epoch 761/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00761: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 762/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00762: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7465 - val_acc: 0.0052\n",
      "Epoch 763/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00763: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 764/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00764: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7435 - val_acc: 0.0052\n",
      "Epoch 765/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00765: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 766/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00766: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7463 - val_acc: 0.0052\n",
      "Epoch 767/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00767: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 768/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00768: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 769/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00769: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 770/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00770: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7438 - val_acc: 0.0052\n",
      "Epoch 771/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00771: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7436 - val_acc: 0.0052\n",
      "Epoch 772/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00772: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7437 - val_acc: 0.0052\n",
      "Epoch 773/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00773: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 774/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00774: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 775/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00775: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 776/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00776: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 777/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00777: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7438 - val_acc: 0.0052\n",
      "Epoch 778/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00778: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7426 - val_acc: 0.0052\n",
      "Epoch 779/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00779: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 780/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00780: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 781/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00781: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7465 - val_acc: 0.0052\n",
      "Epoch 782/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00782: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 783/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00783: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 784/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00784: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 785/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00785: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 786/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00786: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 787/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00787: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 788/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00788: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7437 - val_acc: 0.0052\n",
      "Epoch 789/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00789: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7437 - val_acc: 0.0052\n",
      "Epoch 790/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00790: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 791/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00791: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7469 - val_acc: 0.0052\n",
      "Epoch 792/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00792: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7479 - val_acc: 0.0052\n",
      "Epoch 793/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00793: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 794/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00794: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 795/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00795: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 796/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00796: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 797/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00797: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 798/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00798: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 799/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00799: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 800/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00800: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 801/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00801: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 802/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00802: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 803/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00803: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7459 - val_acc: 0.0052\n",
      "Epoch 804/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00804: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 805/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00805: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7460 - val_acc: 0.0052\n",
      "Epoch 806/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00806: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 807/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00807: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 808/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00808: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 809/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00809: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 810/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00810: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 811/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00811: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7428 - val_acc: 0.0052\n",
      "Epoch 812/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00812: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7436 - val_acc: 0.0052\n",
      "Epoch 813/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00813: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7434 - val_acc: 0.0052\n",
      "Epoch 814/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00814: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7438 - val_acc: 0.0052\n",
      "Epoch 815/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00815: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7428 - val_acc: 0.0052\n",
      "Epoch 816/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00816: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7436 - val_acc: 0.0052\n",
      "Epoch 817/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00817: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3660 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 818/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00818: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 819/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00819: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 820/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00820: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 821/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00821: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 822/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00822: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 823/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00823: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7432 - val_acc: 0.0052\n",
      "Epoch 824/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00824: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7436 - val_acc: 0.0052\n",
      "Epoch 825/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00825: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 826/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00826: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 827/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00827: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 828/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00828: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 829/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00829: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7465 - val_acc: 0.0052\n",
      "Epoch 830/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00830: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7469 - val_acc: 0.0052\n",
      "Epoch 831/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00831: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7473 - val_acc: 0.0052\n",
      "Epoch 832/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00832: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 833/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00833: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7463 - val_acc: 0.0052\n",
      "Epoch 834/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00834: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7462 - val_acc: 0.0052\n",
      "Epoch 835/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00835: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 836/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00836: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 837/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00837: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 838/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00838: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 839/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3660 - acc: 1.0000Epoch 00839: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3660 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 840/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00840: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7440 - val_acc: 0.0052\n",
      "Epoch 841/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00841: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7431 - val_acc: 0.0052\n",
      "Epoch 842/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00842: val_acc did not improve\n",
      "5364/5364 [==============================] - 163s 30ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 843/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00843: val_acc did not improve\n",
      "5364/5364 [==============================] - 162s 30ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7440 - val_acc: 0.0052\n",
      "Epoch 844/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00844: val_acc did not improve\n",
      "5364/5364 [==============================] - 162s 30ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7438 - val_acc: 0.0052\n",
      "Epoch 845/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00845: val_acc did not improve\n",
      "5364/5364 [==============================] - 162s 30ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7459 - val_acc: 0.0052\n",
      "Epoch 846/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00846: val_acc did not improve\n",
      "5364/5364 [==============================] - 162s 30ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 847/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00847: val_acc did not improve\n",
      "5364/5364 [==============================] - 162s 30ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7440 - val_acc: 0.0052\n",
      "Epoch 848/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00848: val_acc did not improve\n",
      "5364/5364 [==============================] - 163s 30ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7431 - val_acc: 0.0052\n",
      "Epoch 849/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00849: val_acc did not improve\n",
      "5364/5364 [==============================] - 163s 30ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7434 - val_acc: 0.0052\n",
      "Epoch 850/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00850: val_acc did not improve\n",
      "5364/5364 [==============================] - 163s 30ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 851/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00851: val_acc did not improve\n",
      "5364/5364 [==============================] - 164s 30ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 852/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00852: val_acc did not improve\n",
      "5364/5364 [==============================] - 163s 30ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 853/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00853: val_acc did not improve\n",
      "5364/5364 [==============================] - 164s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7465 - val_acc: 0.0052\n",
      "Epoch 854/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00854: val_acc did not improve\n",
      "5364/5364 [==============================] - 164s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7459 - val_acc: 0.0052\n",
      "Epoch 855/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00855: val_acc did not improve\n",
      "5364/5364 [==============================] - 164s 30ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7459 - val_acc: 0.0052\n",
      "Epoch 856/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00856: val_acc did not improve\n",
      "5364/5364 [==============================] - 163s 30ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7459 - val_acc: 0.0052\n",
      "Epoch 857/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00857: val_acc did not improve\n",
      "5364/5364 [==============================] - 163s 30ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 858/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00858: val_acc did not improve\n",
      "5364/5364 [==============================] - 164s 30ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7437 - val_acc: 0.0052\n",
      "Epoch 859/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00859: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 860/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00860: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 861/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00861: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 862/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00862: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 863/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00863: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7464 - val_acc: 0.0052\n",
      "Epoch 864/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00864: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7475 - val_acc: 0.0052\n",
      "Epoch 865/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00865: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 866/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00866: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 867/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00867: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7462 - val_acc: 0.0052\n",
      "Epoch 868/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00868: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 869/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00869: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7438 - val_acc: 0.0052\n",
      "Epoch 870/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00870: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 871/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00871: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 872/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00872: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 873/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00873: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7467 - val_acc: 0.0052\n",
      "Epoch 874/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00874: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 875/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00875: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 876/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00876: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 877/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00877: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 878/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00878: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 879/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00879: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 880/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00880: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 881/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00881: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 882/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00882: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 883/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00883: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7435 - val_acc: 0.0052\n",
      "Epoch 884/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00884: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 885/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00885: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 886/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00886: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 887/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00887: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 888/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00888: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7422 - val_acc: 0.0052\n",
      "Epoch 889/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00889: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 890/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00890: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 891/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00891: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7440 - val_acc: 0.0052\n",
      "Epoch 892/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00892: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7461 - val_acc: 0.0052\n",
      "Epoch 893/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00893: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 894/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00894: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7436 - val_acc: 0.0052\n",
      "Epoch 895/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00895: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7466 - val_acc: 0.0052\n",
      "Epoch 896/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00896: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7460 - val_acc: 0.0052\n",
      "Epoch 897/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00897: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7463 - val_acc: 0.0052\n",
      "Epoch 898/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00898: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 899/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00899: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 900/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00900: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 901/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00901: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 902/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00902: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7437 - val_acc: 0.0052\n",
      "Epoch 903/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00903: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 904/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00904: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 905/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00905: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 906/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00906: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7461 - val_acc: 0.0052\n",
      "Epoch 907/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00907: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7465 - val_acc: 0.0052\n",
      "Epoch 908/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00908: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 909/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00909: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7461 - val_acc: 0.0052\n",
      "Epoch 910/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00910: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 911/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00911: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 912/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00912: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 913/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00913: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 914/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00914: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 915/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00915: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 916/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00916: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 917/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00917: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 918/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00918: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7433 - val_acc: 0.0052\n",
      "Epoch 919/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00919: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7437 - val_acc: 0.0052\n",
      "Epoch 920/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00920: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 921/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00921: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7460 - val_acc: 0.0052\n",
      "Epoch 922/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00922: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7460 - val_acc: 0.0052\n",
      "Epoch 923/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00923: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7459 - val_acc: 0.0052\n",
      "Epoch 924/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00924: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 925/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00925: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7434 - val_acc: 0.0052\n",
      "Epoch 926/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00926: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7435 - val_acc: 0.0052\n",
      "Epoch 927/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00927: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 928/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00928: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 929/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00929: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7429 - val_acc: 0.0052\n",
      "Epoch 930/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00930: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7434 - val_acc: 0.0052\n",
      "Epoch 931/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00931: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 932/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00932: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7462 - val_acc: 0.0052\n",
      "Epoch 933/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00933: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 934/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00934: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7465 - val_acc: 0.0052\n",
      "Epoch 935/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00935: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7459 - val_acc: 0.0052\n",
      "Epoch 936/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00936: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 937/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00937: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7435 - val_acc: 0.0052\n",
      "Epoch 938/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00938: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7431 - val_acc: 0.0052\n",
      "Epoch 939/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00939: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 940/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00940: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7434 - val_acc: 0.0052\n",
      "Epoch 941/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00941: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7440 - val_acc: 0.0052\n",
      "Epoch 942/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00942: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7439 - val_acc: 0.0052\n",
      "Epoch 943/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00943: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 944/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00944: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 945/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00945: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 946/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00946: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 947/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00947: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 948/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00948: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 949/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00949: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7463 - val_acc: 0.0052\n",
      "Epoch 950/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00950: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7460 - val_acc: 0.0052\n",
      "Epoch 951/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00951: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 952/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00952: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 953/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00953: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 954/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00954: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7461 - val_acc: 0.0052\n",
      "Epoch 955/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00955: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7464 - val_acc: 0.0052\n",
      "Epoch 956/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00956: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 957/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00957: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 958/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00958: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 959/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00959: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 960/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00960: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 961/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00961: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 962/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00962: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 963/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00963: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7436 - val_acc: 0.0052\n",
      "Epoch 964/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00964: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 965/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00965: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 966/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00966: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 967/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00967: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 968/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00968: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 969/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00969: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7466 - val_acc: 0.0052\n",
      "Epoch 970/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00970: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 971/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00971: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7460 - val_acc: 0.0052\n",
      "Epoch 972/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00972: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 973/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00973: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 974/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00974: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 975/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00975: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 976/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00976: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7467 - val_acc: 0.0052\n",
      "Epoch 977/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00977: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 978/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00978: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 979/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00979: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 980/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00980: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 981/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00981: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7439 - val_acc: 0.0052\n",
      "Epoch 982/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00982: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7431 - val_acc: 0.0052\n",
      "Epoch 983/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00983: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 984/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00984: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 985/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00985: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 986/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00986: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 987/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 00987: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 988/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00988: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7475 - val_acc: 0.0052\n",
      "Epoch 989/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3656 - acc: 1.0000Epoch 00989: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 990/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00990: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 991/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00991: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7436 - val_acc: 0.0052\n",
      "Epoch 992/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00992: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7439 - val_acc: 0.0052\n",
      "Epoch 993/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00993: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7433 - val_acc: 0.0052\n",
      "Epoch 994/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00994: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7439 - val_acc: 0.0052\n",
      "Epoch 995/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00995: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7439 - val_acc: 0.0052\n",
      "Epoch 996/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00996: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 997/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 00997: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 998/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00998: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 999/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 00999: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 1000/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01000: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 1001/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01001: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7466 - val_acc: 0.0052\n",
      "Epoch 1002/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01002: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7470 - val_acc: 0.0052\n",
      "Epoch 1003/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01003: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7462 - val_acc: 0.0052\n",
      "Epoch 1004/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01004: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 1005/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01005: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7438 - val_acc: 0.0052\n",
      "Epoch 1006/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01006: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 1007/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01007: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 1008/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01008: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 1009/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01009: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7440 - val_acc: 0.0052\n",
      "Epoch 1010/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01010: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 1011/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01011: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 1012/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01012: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 1013/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01013: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 1014/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01014: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 1015/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01015: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 1016/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01016: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 1017/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01017: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 1018/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01018: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 1019/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01019: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 1020/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01020: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 1021/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01021: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 1022/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01022: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 1023/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01023: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 1024/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01024: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 1025/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01025: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 1026/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01026: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 1027/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01027: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 1028/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01028: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 1029/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01029: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7463 - val_acc: 0.0052\n",
      "Epoch 1030/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01030: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 1031/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01031: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 1032/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01032: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7463 - val_acc: 0.0052\n",
      "Epoch 1033/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01033: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7465 - val_acc: 0.0052\n",
      "Epoch 1034/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01034: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 1035/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01035: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 1036/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01036: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 1037/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01037: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 1038/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01038: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 1039/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01039: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 1040/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01040: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 1041/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01041: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 1042/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01042: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 1043/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01043: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7461 - val_acc: 0.0052\n",
      "Epoch 1044/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01044: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7477 - val_acc: 0.0052\n",
      "Epoch 1045/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01045: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 1046/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01046: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7459 - val_acc: 0.0052\n",
      "Epoch 1047/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01047: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 1048/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01048: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 1049/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01049: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 1050/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01050: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 1051/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01051: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 1052/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01052: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 1053/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01053: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 1054/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01054: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 1055/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01055: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7459 - val_acc: 0.0052\n",
      "Epoch 1056/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01056: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7462 - val_acc: 0.0052\n",
      "Epoch 1057/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01057: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7482 - val_acc: 0.0052\n",
      "Epoch 1058/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01058: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7474 - val_acc: 0.0052\n",
      "Epoch 1059/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01059: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7470 - val_acc: 0.0052\n",
      "Epoch 1060/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01060: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7476 - val_acc: 0.0052\n",
      "Epoch 1061/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01061: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7467 - val_acc: 0.0052\n",
      "Epoch 1062/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01062: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 1063/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01063: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 1064/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01064: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 1065/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01065: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7429 - val_acc: 0.0052\n",
      "Epoch 1066/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01066: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7439 - val_acc: 0.0052\n",
      "Epoch 1067/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01067: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7430 - val_acc: 0.0052\n",
      "Epoch 1068/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01068: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7423 - val_acc: 0.0052\n",
      "Epoch 1069/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01069: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 1070/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01070: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7461 - val_acc: 0.0052\n",
      "Epoch 1071/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01071: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 1072/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01072: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 1073/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01073: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 1074/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01074: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 1075/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01075: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7463 - val_acc: 0.0052\n",
      "Epoch 1076/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01076: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 1077/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01077: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7461 - val_acc: 0.0052\n",
      "Epoch 1078/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01078: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7459 - val_acc: 0.0052\n",
      "Epoch 1079/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01079: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 1080/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01080: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 1081/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01081: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 1082/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01082: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 1083/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01083: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7469 - val_acc: 0.0052\n",
      "Epoch 1084/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01084: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7462 - val_acc: 0.0052\n",
      "Epoch 1085/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01085: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7464 - val_acc: 0.0052\n",
      "Epoch 1086/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01086: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 1087/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01087: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 1088/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01088: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 1089/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01089: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7461 - val_acc: 0.0052\n",
      "Epoch 1090/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01090: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7467 - val_acc: 0.0052\n",
      "Epoch 1091/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01091: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 1092/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01092: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 1093/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01093: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 1094/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01094: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 1095/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01095: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 1096/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01096: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 1097/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01097: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 1098/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01098: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 1099/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01099: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 1100/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01100: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 1101/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01101: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 1102/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01102: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 1103/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01103: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 1104/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01104: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7461 - val_acc: 0.0052\n",
      "Epoch 1105/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01105: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7460 - val_acc: 0.0052\n",
      "Epoch 1106/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01106: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7437 - val_acc: 0.0052\n",
      "Epoch 1107/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01107: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 1108/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01108: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 1109/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01109: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7431 - val_acc: 0.0052\n",
      "Epoch 1110/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01110: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7430 - val_acc: 0.0052\n",
      "Epoch 1111/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01111: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7430 - val_acc: 0.0052\n",
      "Epoch 1112/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01112: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7432 - val_acc: 0.0052\n",
      "Epoch 1113/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01113: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 1114/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01114: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 1115/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01115: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 1116/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01116: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 1117/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01117: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7437 - val_acc: 0.0052\n",
      "Epoch 1118/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01118: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7425 - val_acc: 0.0052\n",
      "Epoch 1119/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01119: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7415 - val_acc: 0.0052\n",
      "Epoch 1120/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01120: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7427 - val_acc: 0.0052\n",
      "Epoch 1121/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01121: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 1122/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01122: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7463 - val_acc: 0.0052\n",
      "Epoch 1123/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01123: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 1124/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01124: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 1125/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01125: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7460 - val_acc: 0.0052\n",
      "Epoch 1126/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01126: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7473 - val_acc: 0.0052\n",
      "Epoch 1127/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01127: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7479 - val_acc: 0.0052\n",
      "Epoch 1128/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01128: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7482 - val_acc: 0.0052\n",
      "Epoch 1129/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01129: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7464 - val_acc: 0.0052\n",
      "Epoch 1130/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01130: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 1131/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01131: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 1132/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01132: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 1133/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01133: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 1134/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01134: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 1135/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01135: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 1136/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01136: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 1137/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01137: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 1138/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01138: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 1139/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01139: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7435 - val_acc: 0.0052\n",
      "Epoch 1140/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01140: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7433 - val_acc: 0.0052\n",
      "Epoch 1141/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01141: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7435 - val_acc: 0.0052\n",
      "Epoch 1142/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01142: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 1143/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01143: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 1144/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01144: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 1145/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01145: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 1146/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01146: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 1147/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01147: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 1148/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01148: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 1149/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01149: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 1150/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01150: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 1151/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01151: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 1152/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01152: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 1153/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01153: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 1154/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01154: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 1155/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01155: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 1156/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01156: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7440 - val_acc: 0.0052\n",
      "Epoch 1157/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01157: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 1158/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01158: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 1159/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01159: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7436 - val_acc: 0.0052\n",
      "Epoch 1160/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01160: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 1161/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01161: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 1162/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01162: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 1163/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01163: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 1164/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01164: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7439 - val_acc: 0.0052\n",
      "Epoch 1165/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01165: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 1166/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01166: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 1167/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01167: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 1168/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01168: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 1169/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01169: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7460 - val_acc: 0.0052\n",
      "Epoch 1170/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01170: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7465 - val_acc: 0.0052\n",
      "Epoch 1171/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01171: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 1172/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01172: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7465 - val_acc: 0.0052\n",
      "Epoch 1173/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01173: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7464 - val_acc: 0.0052\n",
      "Epoch 1174/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01174: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7471 - val_acc: 0.0052\n",
      "Epoch 1175/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01175: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7459 - val_acc: 0.0052\n",
      "Epoch 1176/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01176: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7462 - val_acc: 0.0052\n",
      "Epoch 1177/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01177: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7462 - val_acc: 0.0052\n",
      "Epoch 1178/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01178: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7462 - val_acc: 0.0052\n",
      "Epoch 1179/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01179: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 1180/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01180: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7459 - val_acc: 0.0052\n",
      "Epoch 1181/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01181: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7464 - val_acc: 0.0052\n",
      "Epoch 1182/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01182: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 1183/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01183: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7468 - val_acc: 0.0052\n",
      "Epoch 1184/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01184: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7468 - val_acc: 0.0052\n",
      "Epoch 1185/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01185: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7473 - val_acc: 0.0052\n",
      "Epoch 1186/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01186: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7466 - val_acc: 0.0052\n",
      "Epoch 1187/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01187: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 1188/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01188: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 1189/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01189: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 1190/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01190: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7433 - val_acc: 0.0052\n",
      "Epoch 1191/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01191: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7440 - val_acc: 0.0052\n",
      "Epoch 1192/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01192: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7432 - val_acc: 0.0052\n",
      "Epoch 1193/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01193: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7440 - val_acc: 0.0052\n",
      "Epoch 1194/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01194: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7435 - val_acc: 0.0052\n",
      "Epoch 1195/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01195: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7434 - val_acc: 0.0052\n",
      "Epoch 1196/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01196: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7435 - val_acc: 0.0052\n",
      "Epoch 1197/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01197: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7432 - val_acc: 0.0052\n",
      "Epoch 1198/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01198: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7431 - val_acc: 0.0052\n",
      "Epoch 1199/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01199: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 1200/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01200: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 1201/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01201: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7461 - val_acc: 0.0052\n",
      "Epoch 1202/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01202: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7459 - val_acc: 0.0052\n",
      "Epoch 1203/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01203: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 1204/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01204: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 1205/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01205: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7428 - val_acc: 0.0052\n",
      "Epoch 1206/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01206: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7439 - val_acc: 0.0052\n",
      "Epoch 1207/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01207: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7436 - val_acc: 0.0052\n",
      "Epoch 1208/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01208: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 1209/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01209: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7432 - val_acc: 0.0052\n",
      "Epoch 1210/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01210: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7432 - val_acc: 0.0052\n",
      "Epoch 1211/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01211: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7428 - val_acc: 0.0052\n",
      "Epoch 1212/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01212: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7428 - val_acc: 0.0052\n",
      "Epoch 1213/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01213: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 1214/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01214: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 1215/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01215: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 1216/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01216: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 1217/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01217: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 1218/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3656 - acc: 1.0000Epoch 01218: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 1219/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01219: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 1220/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01220: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 1221/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01221: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 1222/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01222: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 1223/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01223: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7435 - val_acc: 0.0052\n",
      "Epoch 1224/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01224: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7437 - val_acc: 0.0052\n",
      "Epoch 1225/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01225: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 1226/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01226: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 1227/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01227: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 1228/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01228: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7438 - val_acc: 0.0052\n",
      "Epoch 1229/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01229: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7440 - val_acc: 0.0052\n",
      "Epoch 1230/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01230: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 1231/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01231: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 1232/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01232: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 1233/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01233: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 1234/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01234: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 1235/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01235: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 1236/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01236: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7464 - val_acc: 0.0052\n",
      "Epoch 1237/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01237: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 1238/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01238: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 1239/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01239: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7461 - val_acc: 0.0052\n",
      "Epoch 1240/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01240: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 1241/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01241: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 1242/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01242: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 1243/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01243: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 1244/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01244: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7474 - val_acc: 0.0052\n",
      "Epoch 1245/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01245: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 1246/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01246: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7462 - val_acc: 0.0052\n",
      "Epoch 1247/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01247: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 1248/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01248: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7471 - val_acc: 0.0052\n",
      "Epoch 1249/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01249: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7475 - val_acc: 0.0052\n",
      "Epoch 1250/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01250: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 1251/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01251: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 1252/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01252: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 1253/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01253: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 1254/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01254: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 1255/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01255: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 1256/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01256: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 1257/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01257: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7436 - val_acc: 0.0052\n",
      "Epoch 1258/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01258: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 1259/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01259: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 1260/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01260: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7440 - val_acc: 0.0052\n",
      "Epoch 1261/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01261: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7438 - val_acc: 0.0052\n",
      "Epoch 1262/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01262: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 1263/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01263: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 1264/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01264: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7431 - val_acc: 0.0052\n",
      "Epoch 1265/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01265: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7433 - val_acc: 0.0052\n",
      "Epoch 1266/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01266: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 1267/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01267: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 1268/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01268: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 1269/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01269: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 1270/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01270: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 1271/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01271: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 1272/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01272: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 1273/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01273: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 1274/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01274: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 1275/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01275: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7459 - val_acc: 0.0052\n",
      "Epoch 1276/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01276: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 1277/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01277: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7433 - val_acc: 0.0052\n",
      "Epoch 1278/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01278: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 1279/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01279: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7435 - val_acc: 0.0052\n",
      "Epoch 1280/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01280: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 1281/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01281: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 1282/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01282: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 1283/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01283: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 1284/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01284: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7438 - val_acc: 0.0052\n",
      "Epoch 1285/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01285: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 1286/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01286: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 1287/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01287: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 1288/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01288: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 1289/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01289: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7459 - val_acc: 0.0052\n",
      "Epoch 1290/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01290: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 1291/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01291: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7460 - val_acc: 0.0052\n",
      "Epoch 1292/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01292: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 1293/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01293: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 1294/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01294: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7439 - val_acc: 0.0052\n",
      "Epoch 1295/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01295: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7440 - val_acc: 0.0052\n",
      "Epoch 1296/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01296: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 1297/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01297: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 1298/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01298: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 1299/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01299: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7465 - val_acc: 0.0052\n",
      "Epoch 1300/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01300: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 1301/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01301: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7463 - val_acc: 0.0052\n",
      "Epoch 1302/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01302: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 1303/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01303: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 1304/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01304: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7468 - val_acc: 0.0052\n",
      "Epoch 1305/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01305: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7462 - val_acc: 0.0052\n",
      "Epoch 1306/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01306: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7468 - val_acc: 0.0052\n",
      "Epoch 1307/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01307: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7467 - val_acc: 0.0052\n",
      "Epoch 1308/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01308: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 1309/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01309: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 1310/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01310: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7459 - val_acc: 0.0052\n",
      "Epoch 1311/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01311: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 1312/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01312: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 1313/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01313: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 1314/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01314: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 1315/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01315: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 1316/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01316: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 1317/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01317: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 1318/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01318: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 1319/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01319: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 1320/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01320: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 1321/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01321: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7438 - val_acc: 0.0052\n",
      "Epoch 1322/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01322: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 1323/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3660 - acc: 1.0000Epoch 01323: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 1324/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01324: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 1325/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01325: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 1326/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01326: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 1327/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01327: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 1328/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01328: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 1329/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01329: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 1330/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01330: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7437 - val_acc: 0.0052\n",
      "Epoch 1331/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01331: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7437 - val_acc: 0.0052\n",
      "Epoch 1332/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01332: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 1333/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01333: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 1334/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01334: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 1335/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01335: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 1336/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01336: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 1337/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01337: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7435 - val_acc: 0.0052\n",
      "Epoch 1338/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01338: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 1339/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01339: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7467 - val_acc: 0.0052\n",
      "Epoch 1340/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01340: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7459 - val_acc: 0.0052\n",
      "Epoch 1341/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01341: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 1342/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01342: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7459 - val_acc: 0.0052\n",
      "Epoch 1343/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01343: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 1344/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01344: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 1345/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01345: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7469 - val_acc: 0.0052\n",
      "Epoch 1346/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01346: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7468 - val_acc: 0.0052\n",
      "Epoch 1347/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01347: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7465 - val_acc: 0.0052\n",
      "Epoch 1348/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01348: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7465 - val_acc: 0.0052\n",
      "Epoch 1349/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01349: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7463 - val_acc: 0.0052\n",
      "Epoch 1350/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01350: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7463 - val_acc: 0.0052\n",
      "Epoch 1351/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01351: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7467 - val_acc: 0.0052\n",
      "Epoch 1352/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01352: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7462 - val_acc: 0.0052\n",
      "Epoch 1353/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01353: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 1354/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01354: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 1355/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01355: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 1356/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01356: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7432 - val_acc: 0.0052\n",
      "Epoch 1357/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01357: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7430 - val_acc: 0.0052\n",
      "Epoch 1358/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01358: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7418 - val_acc: 0.0052\n",
      "Epoch 1359/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01359: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7431 - val_acc: 0.0052\n",
      "Epoch 1360/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01360: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7423 - val_acc: 0.0052\n",
      "Epoch 1361/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01361: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7427 - val_acc: 0.0052\n",
      "Epoch 1362/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01362: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7435 - val_acc: 0.0052\n",
      "Epoch 1363/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01363: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7438 - val_acc: 0.0052\n",
      "Epoch 1364/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01364: val_acc did not improve\n",
      "5364/5364 [==============================] - 164s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 1365/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01365: val_acc did not improve\n",
      "5364/5364 [==============================] - 162s 30ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 1366/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01366: val_acc did not improve\n",
      "5364/5364 [==============================] - 162s 30ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 1367/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01367: val_acc did not improve\n",
      "5364/5364 [==============================] - 162s 30ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 1368/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01368: val_acc did not improve\n",
      "5364/5364 [==============================] - 162s 30ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 1369/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01369: val_acc did not improve\n",
      "5364/5364 [==============================] - 162s 30ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 1370/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01370: val_acc did not improve\n",
      "5364/5364 [==============================] - 163s 30ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 1371/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01371: val_acc did not improve\n",
      "5364/5364 [==============================] - 163s 30ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7464 - val_acc: 0.0052\n",
      "Epoch 1372/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01372: val_acc did not improve\n",
      "5364/5364 [==============================] - 163s 30ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7469 - val_acc: 0.0052\n",
      "Epoch 1373/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01373: val_acc did not improve\n",
      "5364/5364 [==============================] - 163s 30ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7467 - val_acc: 0.0052\n",
      "Epoch 1374/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01374: val_acc did not improve\n",
      "5364/5364 [==============================] - 163s 30ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7463 - val_acc: 0.0052\n",
      "Epoch 1375/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01375: val_acc did not improve\n",
      "5364/5364 [==============================] - 163s 30ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 1376/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01376: val_acc did not improve\n",
      "5364/5364 [==============================] - 163s 30ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 1377/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01377: val_acc did not improve\n",
      "5364/5364 [==============================] - 163s 30ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 1378/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01378: val_acc did not improve\n",
      "5364/5364 [==============================] - 164s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 1379/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01379: val_acc did not improve\n",
      "5364/5364 [==============================] - 163s 30ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 1380/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01380: val_acc did not improve\n",
      "5364/5364 [==============================] - 163s 30ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 1381/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01381: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 1382/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01382: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7460 - val_acc: 0.0052\n",
      "Epoch 1383/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01383: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7459 - val_acc: 0.0052\n",
      "Epoch 1384/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01384: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7465 - val_acc: 0.0052\n",
      "Epoch 1385/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01385: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7461 - val_acc: 0.0052\n",
      "Epoch 1386/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01386: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7465 - val_acc: 0.0052\n",
      "Epoch 1387/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01387: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7472 - val_acc: 0.0052\n",
      "Epoch 1388/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01388: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7478 - val_acc: 0.0052\n",
      "Epoch 1389/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01389: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7461 - val_acc: 0.0052\n",
      "Epoch 1390/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01390: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 1391/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01391: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7461 - val_acc: 0.0052\n",
      "Epoch 1392/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01392: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7461 - val_acc: 0.0052\n",
      "Epoch 1393/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01393: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 1394/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01394: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 1395/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01395: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 1396/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01396: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 1397/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01397: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 1398/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01398: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 1399/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01399: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 1400/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01400: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 1401/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01401: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7437 - val_acc: 0.0052\n",
      "Epoch 1402/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01402: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7431 - val_acc: 0.0052\n",
      "Epoch 1403/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01403: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7427 - val_acc: 0.0052\n",
      "Epoch 1404/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01404: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 1405/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01405: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 1406/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01406: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 1407/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01407: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7463 - val_acc: 0.0052\n",
      "Epoch 1408/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01408: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7462 - val_acc: 0.0052\n",
      "Epoch 1409/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01409: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 1410/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01410: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7435 - val_acc: 0.0052\n",
      "Epoch 1411/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01411: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7431 - val_acc: 0.0052\n",
      "Epoch 1412/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01412: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 1413/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01413: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 1414/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01414: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 1415/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01415: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 1416/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01416: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 1417/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01417: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 1418/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01418: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7464 - val_acc: 0.0052\n",
      "Epoch 1419/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01419: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 1420/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01420: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 1421/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01421: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7464 - val_acc: 0.0052\n",
      "Epoch 1422/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01422: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 1423/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01423: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 1424/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01424: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 1425/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01425: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 1426/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01426: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7436 - val_acc: 0.0052\n",
      "Epoch 1427/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01427: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 1428/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01428: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 1429/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01429: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 1430/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01430: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 1431/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01431: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 1432/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01432: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 1433/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01433: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 1434/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01434: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 1435/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01435: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 1436/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01436: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 1437/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01437: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 1438/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01438: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7465 - val_acc: 0.0052\n",
      "Epoch 1439/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01439: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7465 - val_acc: 0.0052\n",
      "Epoch 1440/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01440: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7470 - val_acc: 0.0052\n",
      "Epoch 1441/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01441: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7468 - val_acc: 0.0052\n",
      "Epoch 1442/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01442: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 1443/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01443: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7434 - val_acc: 0.0052\n",
      "Epoch 1444/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01444: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7432 - val_acc: 0.0052\n",
      "Epoch 1445/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01445: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 1446/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01446: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 1447/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01447: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 1448/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01448: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 1449/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01449: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 1450/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01450: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 1451/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01451: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 1452/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01452: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 1453/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01453: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7434 - val_acc: 0.0052\n",
      "Epoch 1454/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01454: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7425 - val_acc: 0.0052\n",
      "Epoch 1455/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01455: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7436 - val_acc: 0.0052\n",
      "Epoch 1456/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01456: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 1457/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01457: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7433 - val_acc: 0.0052\n",
      "Epoch 1458/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01458: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 1459/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01459: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7462 - val_acc: 0.0052\n",
      "Epoch 1460/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01460: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7471 - val_acc: 0.0052\n",
      "Epoch 1461/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01461: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7464 - val_acc: 0.0052\n",
      "Epoch 1462/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01462: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7459 - val_acc: 0.0052\n",
      "Epoch 1463/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01463: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 1464/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01464: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 1465/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01465: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 1466/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01466: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 1467/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01467: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7474 - val_acc: 0.0052\n",
      "Epoch 1468/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01468: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7463 - val_acc: 0.0052\n",
      "Epoch 1469/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01469: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7477 - val_acc: 0.0052\n",
      "Epoch 1470/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01470: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7461 - val_acc: 0.0052\n",
      "Epoch 1471/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01471: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7461 - val_acc: 0.0052\n",
      "Epoch 1472/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01472: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7464 - val_acc: 0.0052\n",
      "Epoch 1473/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01473: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7461 - val_acc: 0.0052\n",
      "Epoch 1474/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01474: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 1475/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01475: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7463 - val_acc: 0.0052\n",
      "Epoch 1476/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01476: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 1477/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01477: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 1478/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01478: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 1479/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01479: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 1480/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01480: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 1481/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01481: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 1482/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01482: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 1483/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01483: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 1484/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01484: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 1485/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01485: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 1486/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01486: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 1487/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01487: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 1488/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01488: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 1489/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01489: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 1490/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01490: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 1491/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01491: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7459 - val_acc: 0.0052\n",
      "Epoch 1492/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01492: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7471 - val_acc: 0.0052\n",
      "Epoch 1493/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01493: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7465 - val_acc: 0.0052\n",
      "Epoch 1494/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01494: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7459 - val_acc: 0.0052\n",
      "Epoch 1495/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01495: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 1496/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01496: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 1497/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01497: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 1498/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01498: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 1499/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01499: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 1500/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01500: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 1501/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01501: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7440 - val_acc: 0.0052\n",
      "Epoch 1502/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01502: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7436 - val_acc: 0.0052\n",
      "Epoch 1503/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01503: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7436 - val_acc: 0.0052\n",
      "Epoch 1504/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01504: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7438 - val_acc: 0.0052\n",
      "Epoch 1505/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01505: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7438 - val_acc: 0.0052\n",
      "Epoch 1506/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01506: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 1507/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01507: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7440 - val_acc: 0.0052\n",
      "Epoch 1508/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01508: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7426 - val_acc: 0.0052\n",
      "Epoch 1509/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01509: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7438 - val_acc: 0.0052\n",
      "Epoch 1510/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01510: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7440 - val_acc: 0.0052\n",
      "Epoch 1511/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01511: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 1512/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01512: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 1513/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01513: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 1514/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01514: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 1515/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01515: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 1516/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01516: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 1517/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01517: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7466 - val_acc: 0.0052\n",
      "Epoch 1518/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01518: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7461 - val_acc: 0.0052\n",
      "Epoch 1519/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01519: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7462 - val_acc: 0.0052\n",
      "Epoch 1520/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01520: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 1521/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01521: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 1522/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01522: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7465 - val_acc: 0.0052\n",
      "Epoch 1523/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01523: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 1524/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01524: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7465 - val_acc: 0.0052\n",
      "Epoch 1525/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01525: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 1526/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01526: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 1527/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01527: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 1528/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01528: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 1529/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01529: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7466 - val_acc: 0.0052\n",
      "Epoch 1530/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01530: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7463 - val_acc: 0.0052\n",
      "Epoch 1531/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01531: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7476 - val_acc: 0.0052\n",
      "Epoch 1532/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01532: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7471 - val_acc: 0.0052\n",
      "Epoch 1533/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01533: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 1534/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01534: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 1535/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01535: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 1536/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01536: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 1537/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01537: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7463 - val_acc: 0.0052\n",
      "Epoch 1538/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01538: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 1539/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01539: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 1540/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01540: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7434 - val_acc: 0.0052\n",
      "Epoch 1541/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01541: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 1542/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01542: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 1543/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01543: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 1544/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01544: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 1545/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01545: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 1546/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01546: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 1547/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01547: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7435 - val_acc: 0.0052\n",
      "Epoch 1548/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01548: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7434 - val_acc: 0.0052\n",
      "Epoch 1549/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01549: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7432 - val_acc: 0.0052\n",
      "Epoch 1550/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01550: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7440 - val_acc: 0.0052\n",
      "Epoch 1551/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01551: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 1552/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01552: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 1553/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01553: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7435 - val_acc: 0.0052\n",
      "Epoch 1554/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01554: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7439 - val_acc: 0.0052\n",
      "Epoch 1555/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01555: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7438 - val_acc: 0.0052\n",
      "Epoch 1556/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01556: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7423 - val_acc: 0.0052\n",
      "Epoch 1557/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01557: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7425 - val_acc: 0.0052\n",
      "Epoch 1558/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01558: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7431 - val_acc: 0.0052\n",
      "Epoch 1559/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01559: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 1560/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01560: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7459 - val_acc: 0.0052\n",
      "Epoch 1561/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01561: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 1562/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01562: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 1563/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01563: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 1564/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01564: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 1565/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01565: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 1566/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01566: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 1567/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01567: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7460 - val_acc: 0.0052\n",
      "Epoch 1568/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01568: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7472 - val_acc: 0.0052\n",
      "Epoch 1569/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01569: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7481 - val_acc: 0.0052\n",
      "Epoch 1570/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01570: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7476 - val_acc: 0.0052\n",
      "Epoch 1571/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01571: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7469 - val_acc: 0.0052\n",
      "Epoch 1572/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01572: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7472 - val_acc: 0.0052\n",
      "Epoch 1573/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01573: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 1574/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01574: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7463 - val_acc: 0.0052\n",
      "Epoch 1575/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01575: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7461 - val_acc: 0.0052\n",
      "Epoch 1576/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01576: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 1577/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01577: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7460 - val_acc: 0.0052\n",
      "Epoch 1578/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01578: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 1579/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01579: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7460 - val_acc: 0.0052\n",
      "Epoch 1580/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01580: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7466 - val_acc: 0.0052\n",
      "Epoch 1581/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01581: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 1582/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01582: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7459 - val_acc: 0.0052\n",
      "Epoch 1583/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01583: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 1584/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01584: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 1585/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01585: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 1586/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01586: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7468 - val_acc: 0.0052\n",
      "Epoch 1587/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01587: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7460 - val_acc: 0.0052\n",
      "Epoch 1588/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01588: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 1589/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01589: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 1590/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01590: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 1591/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01591: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 1592/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01592: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7434 - val_acc: 0.0052\n",
      "Epoch 1593/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01593: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7460 - val_acc: 0.0052\n",
      "Epoch 1594/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01594: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7465 - val_acc: 0.0052\n",
      "Epoch 1595/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01595: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 1596/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01596: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7465 - val_acc: 0.0052\n",
      "Epoch 1597/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01597: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 1598/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01598: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7464 - val_acc: 0.0052\n",
      "Epoch 1599/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01599: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 1600/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01600: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 1601/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01601: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7440 - val_acc: 0.0052\n",
      "Epoch 1602/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01602: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 1603/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01603: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 1604/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01604: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7437 - val_acc: 0.0052\n",
      "Epoch 1605/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01605: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7433 - val_acc: 0.0052\n",
      "Epoch 1606/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01606: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7440 - val_acc: 0.0052\n",
      "Epoch 1607/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01607: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 1608/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01608: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7437 - val_acc: 0.0052\n",
      "Epoch 1609/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01609: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7435 - val_acc: 0.0052\n",
      "Epoch 1610/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01610: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7435 - val_acc: 0.0052\n",
      "Epoch 1611/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01611: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 1612/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01612: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7429 - val_acc: 0.0052\n",
      "Epoch 1613/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01613: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7440 - val_acc: 0.0052\n",
      "Epoch 1614/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01614: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 1615/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01615: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 1616/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01616: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 1617/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01617: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 1618/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01618: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 1619/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01619: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 1620/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01620: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7429 - val_acc: 0.0052\n",
      "Epoch 1621/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01621: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 1622/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01622: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 1623/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01623: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 1624/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01624: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 1625/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01625: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 1626/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01626: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 1627/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01627: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7462 - val_acc: 0.0052\n",
      "Epoch 1628/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01628: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7465 - val_acc: 0.0052\n",
      "Epoch 1629/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01629: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7460 - val_acc: 0.0052\n",
      "Epoch 1630/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01630: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 1631/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01631: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 1632/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01632: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 1633/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01633: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 1634/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01634: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7461 - val_acc: 0.0052\n",
      "Epoch 1635/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01635: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 1636/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01636: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 1637/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01637: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7459 - val_acc: 0.0052\n",
      "Epoch 1638/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01638: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 1639/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01639: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 1640/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01640: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 1641/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01641: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 1642/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01642: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7460 - val_acc: 0.0052\n",
      "Epoch 1643/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01643: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7470 - val_acc: 0.0052\n",
      "Epoch 1644/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01644: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 1645/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01645: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 1646/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01646: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 1647/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01647: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 1648/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01648: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 1649/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01649: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 1650/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01650: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 1651/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01651: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 1652/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01652: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7460 - val_acc: 0.0052\n",
      "Epoch 1653/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01653: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 1654/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01654: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 1655/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01655: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 1656/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01656: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 1657/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01657: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 1658/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01658: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7439 - val_acc: 0.0052\n",
      "Epoch 1659/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01659: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 1660/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01660: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 1661/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01661: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 1662/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01662: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 1663/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01663: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 1664/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01664: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 1665/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01665: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 1666/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01666: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 1667/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01667: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 1668/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01668: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 1669/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01669: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 1670/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01670: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 1671/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01671: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7433 - val_acc: 0.0052\n",
      "Epoch 1672/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01672: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 1673/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01673: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7438 - val_acc: 0.0052\n",
      "Epoch 1674/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01674: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7436 - val_acc: 0.0052\n",
      "Epoch 1675/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01675: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 1676/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01676: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 1677/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01677: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 1678/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01678: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 1679/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01679: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 1680/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01680: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7459 - val_acc: 0.0052\n",
      "Epoch 1681/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01681: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7460 - val_acc: 0.0052\n",
      "Epoch 1682/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01682: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7431 - val_acc: 0.0052\n",
      "Epoch 1683/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01683: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 1684/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01684: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 1685/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01685: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 1686/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01686: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 1687/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01687: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 1688/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01688: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7470 - val_acc: 0.0052\n",
      "Epoch 1689/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01689: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7463 - val_acc: 0.0052\n",
      "Epoch 1690/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01690: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7465 - val_acc: 0.0052\n",
      "Epoch 1691/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01691: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 1692/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01692: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 1693/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01693: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7427 - val_acc: 0.0052\n",
      "Epoch 1694/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01694: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7439 - val_acc: 0.0052\n",
      "Epoch 1695/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01695: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 1696/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01696: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 1697/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01697: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7437 - val_acc: 0.0052\n",
      "Epoch 1698/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01698: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 1699/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01699: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 1700/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01700: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7429 - val_acc: 0.0052\n",
      "Epoch 1701/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01701: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7434 - val_acc: 0.0052\n",
      "Epoch 1702/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01702: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 1703/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01703: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 1704/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01704: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 1705/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01705: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 1706/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01706: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 1707/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01707: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 1708/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01708: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 1709/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01709: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 1710/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01710: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7440 - val_acc: 0.0052\n",
      "Epoch 1711/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01711: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7429 - val_acc: 0.0052\n",
      "Epoch 1712/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01712: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 1713/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01713: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 1714/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01714: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 1715/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01715: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 1716/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01716: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7459 - val_acc: 0.0052\n",
      "Epoch 1717/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01717: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7467 - val_acc: 0.0052\n",
      "Epoch 1718/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01718: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7464 - val_acc: 0.0052\n",
      "Epoch 1719/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01719: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 1720/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01720: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7426 - val_acc: 0.0052\n",
      "Epoch 1721/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01721: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7437 - val_acc: 0.0052\n",
      "Epoch 1722/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01722: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7440 - val_acc: 0.0052\n",
      "Epoch 1723/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01723: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 1724/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01724: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 1725/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01725: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 1726/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01726: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7440 - val_acc: 0.0052\n",
      "Epoch 1727/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01727: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 1728/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01728: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 1729/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01729: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 1730/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01730: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 1731/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01731: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 1732/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01732: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7464 - val_acc: 0.0052\n",
      "Epoch 1733/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01733: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7460 - val_acc: 0.0052\n",
      "Epoch 1734/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01734: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 1735/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01735: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 1736/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01736: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 1737/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01737: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 1738/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01738: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 1739/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01739: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 1740/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01740: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 1741/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01741: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 1742/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01742: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 1743/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01743: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 1744/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01744: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 1745/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01745: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7439 - val_acc: 0.0052\n",
      "Epoch 1746/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01746: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 1747/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01747: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 1748/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01748: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 1749/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01749: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 1750/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01750: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7459 - val_acc: 0.0052\n",
      "Epoch 1751/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01751: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 1752/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01752: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 1753/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01753: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 1754/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01754: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 1755/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01755: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 1756/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01756: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 1757/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01757: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 1758/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01758: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 1759/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01759: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7464 - val_acc: 0.0052\n",
      "Epoch 1760/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01760: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7463 - val_acc: 0.0052\n",
      "Epoch 1761/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01761: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 1762/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01762: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 1763/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01763: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 1764/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01764: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 1765/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01765: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 1766/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01766: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 1767/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01767: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7438 - val_acc: 0.0052\n",
      "Epoch 1768/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01768: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7435 - val_acc: 0.0052\n",
      "Epoch 1769/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01769: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 1770/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01770: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 1771/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01771: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7440 - val_acc: 0.0052\n",
      "Epoch 1772/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01772: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 1773/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01773: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 1774/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01774: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 1775/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01775: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 1776/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01776: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 1777/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01777: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 1778/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01778: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7440 - val_acc: 0.0052\n",
      "Epoch 1779/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3660 - acc: 1.0000Epoch 01779: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 1780/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01780: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 1781/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01781: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 1782/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01782: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7459 - val_acc: 0.0052\n",
      "Epoch 1783/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01783: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7467 - val_acc: 0.0052\n",
      "Epoch 1784/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01784: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 1785/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01785: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 1786/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01786: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 1787/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01787: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 1788/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01788: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 1789/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01789: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 1790/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01790: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7438 - val_acc: 0.0052\n",
      "Epoch 1791/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01791: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 1792/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01792: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 1793/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01793: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 1794/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01794: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 1795/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01795: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 1796/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01796: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 1797/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01797: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 1798/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01798: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7432 - val_acc: 0.0052\n",
      "Epoch 1799/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01799: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7435 - val_acc: 0.0052\n",
      "Epoch 1800/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01800: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7437 - val_acc: 0.0052\n",
      "Epoch 1801/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01801: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 1802/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01802: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 1803/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01803: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 1804/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01804: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7472 - val_acc: 0.0052\n",
      "Epoch 1805/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01805: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7479 - val_acc: 0.0052\n",
      "Epoch 1806/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01806: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7466 - val_acc: 0.0052\n",
      "Epoch 1807/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01807: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7466 - val_acc: 0.0052\n",
      "Epoch 1808/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01808: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 1809/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01809: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 1810/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01810: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 1811/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01811: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 1812/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01812: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7440 - val_acc: 0.0052\n",
      "Epoch 1813/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01813: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7438 - val_acc: 0.0052\n",
      "Epoch 1814/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01814: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7424 - val_acc: 0.0052\n",
      "Epoch 1815/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01815: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7437 - val_acc: 0.0052\n",
      "Epoch 1816/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01816: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7432 - val_acc: 0.0052\n",
      "Epoch 1817/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01817: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7421 - val_acc: 0.0052\n",
      "Epoch 1818/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01818: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7417 - val_acc: 0.0052\n",
      "Epoch 1819/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01819: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7438 - val_acc: 0.0052\n",
      "Epoch 1820/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01820: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 1821/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01821: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7439 - val_acc: 0.0052\n",
      "Epoch 1822/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01822: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 1823/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01823: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 1824/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01824: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 1825/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01825: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7466 - val_acc: 0.0052\n",
      "Epoch 1826/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01826: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 1827/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01827: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 1828/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01828: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 1829/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01829: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 1830/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01830: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 1831/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01831: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 1832/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01832: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 1833/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01833: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7440 - val_acc: 0.0052\n",
      "Epoch 1834/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01834: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 1835/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01835: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 1836/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01836: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 1837/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01837: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7434 - val_acc: 0.0052\n",
      "Epoch 1838/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01838: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7431 - val_acc: 0.0052\n",
      "Epoch 1839/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01839: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 1840/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01840: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 1841/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01841: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 1842/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01842: val_acc did not improve\n",
      "5364/5364 [==============================] - 162s 30ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 1843/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01843: val_acc did not improve\n",
      "5364/5364 [==============================] - 162s 30ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7466 - val_acc: 0.0052\n",
      "Epoch 1844/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01844: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7463 - val_acc: 0.0052\n",
      "Epoch 1845/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01845: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 1846/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01846: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 1847/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01847: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 1848/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01848: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 1849/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01849: val_acc did not improve\n",
      "5364/5364 [==============================] - 164s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 1850/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01850: val_acc did not improve\n",
      "5364/5364 [==============================] - 163s 30ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 1851/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01851: val_acc did not improve\n",
      "5364/5364 [==============================] - 162s 30ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 1852/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01852: val_acc did not improve\n",
      "5364/5364 [==============================] - 163s 30ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 1853/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01853: val_acc did not improve\n",
      "5364/5364 [==============================] - 163s 30ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 1854/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01854: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 1855/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01855: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 1856/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01856: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7471 - val_acc: 0.0052\n",
      "Epoch 1857/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01857: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7469 - val_acc: 0.0052\n",
      "Epoch 1858/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01858: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7459 - val_acc: 0.0052\n",
      "Epoch 1859/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01859: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 1860/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01860: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7464 - val_acc: 0.0052\n",
      "Epoch 1861/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01861: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7465 - val_acc: 0.0052\n",
      "Epoch 1862/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01862: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 1863/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01863: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 1864/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01864: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 1865/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01865: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 1866/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01866: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 1867/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01867: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7464 - val_acc: 0.0052\n",
      "Epoch 1868/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01868: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 1869/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01869: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7463 - val_acc: 0.0052\n",
      "Epoch 1870/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01870: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7465 - val_acc: 0.0052\n",
      "Epoch 1871/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01871: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7468 - val_acc: 0.0052\n",
      "Epoch 1872/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01872: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 1873/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01873: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 1874/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01874: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 1875/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01875: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 1876/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01876: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 1877/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01877: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7460 - val_acc: 0.0052\n",
      "Epoch 1878/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01878: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7462 - val_acc: 0.0052\n",
      "Epoch 1879/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01879: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7440 - val_acc: 0.0052\n",
      "Epoch 1880/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01880: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 1881/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01881: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 1882/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01882: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 1883/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01883: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 1884/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01884: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 1885/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01885: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 1886/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01886: val_acc did not improve\n",
      "5364/5364 [==============================] - 164s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7440 - val_acc: 0.0052\n",
      "Epoch 1887/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01887: val_acc did not improve\n",
      "5364/5364 [==============================] - 163s 30ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7438 - val_acc: 0.0052\n",
      "Epoch 1888/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01888: val_acc did not improve\n",
      "5364/5364 [==============================] - 162s 30ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 1889/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01889: val_acc did not improve\n",
      "5364/5364 [==============================] - 162s 30ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 1890/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01890: val_acc did not improve\n",
      "5364/5364 [==============================] - 162s 30ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7461 - val_acc: 0.0052\n",
      "Epoch 1891/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01891: val_acc did not improve\n",
      "5364/5364 [==============================] - 162s 30ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7461 - val_acc: 0.0052\n",
      "Epoch 1892/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01892: val_acc did not improve\n",
      "5364/5364 [==============================] - 162s 30ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7466 - val_acc: 0.0052\n",
      "Epoch 1893/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01893: val_acc did not improve\n",
      "5364/5364 [==============================] - 163s 30ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7465 - val_acc: 0.0052\n",
      "Epoch 1894/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01894: val_acc did not improve\n",
      "5364/5364 [==============================] - 164s 30ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 1895/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01895: val_acc did not improve\n",
      "5364/5364 [==============================] - 164s 30ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7467 - val_acc: 0.0052\n",
      "Epoch 1896/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01896: val_acc did not improve\n",
      "5364/5364 [==============================] - 163s 30ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7459 - val_acc: 0.0052\n",
      "Epoch 1897/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01897: val_acc did not improve\n",
      "5364/5364 [==============================] - 163s 30ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7476 - val_acc: 0.0052\n",
      "Epoch 1898/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01898: val_acc did not improve\n",
      "5364/5364 [==============================] - 163s 30ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7464 - val_acc: 0.0052\n",
      "Epoch 1899/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01899: val_acc did not improve\n",
      "5364/5364 [==============================] - 163s 30ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7470 - val_acc: 0.0052\n",
      "Epoch 1900/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01900: val_acc did not improve\n",
      "5364/5364 [==============================] - 163s 30ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7462 - val_acc: 0.0052\n",
      "Epoch 1901/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01901: val_acc did not improve\n",
      "5364/5364 [==============================] - 163s 30ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 1902/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01902: val_acc did not improve\n",
      "5364/5364 [==============================] - 163s 30ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7459 - val_acc: 0.0052\n",
      "Epoch 1903/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01903: val_acc did not improve\n",
      "5364/5364 [==============================] - 164s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 1904/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01904: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7471 - val_acc: 0.0052\n",
      "Epoch 1905/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01905: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7470 - val_acc: 0.0052\n",
      "Epoch 1906/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01906: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7465 - val_acc: 0.0052\n",
      "Epoch 1907/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01907: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7461 - val_acc: 0.0052\n",
      "Epoch 1908/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01908: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7463 - val_acc: 0.0052\n",
      "Epoch 1909/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01909: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7465 - val_acc: 0.0052\n",
      "Epoch 1910/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01910: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7465 - val_acc: 0.0052\n",
      "Epoch 1911/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01911: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7462 - val_acc: 0.0052\n",
      "Epoch 1912/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01912: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 1913/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01913: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 1914/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01914: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 1915/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01915: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 1916/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01916: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 1917/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01917: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 1918/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01918: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 1919/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01919: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 1920/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01920: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7440 - val_acc: 0.0052\n",
      "Epoch 1921/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01921: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 1922/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01922: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7436 - val_acc: 0.0052\n",
      "Epoch 1923/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01923: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 1924/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01924: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 1925/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01925: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 1926/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01926: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 1927/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01927: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 1928/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01928: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 1929/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01929: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 1930/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01930: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7435 - val_acc: 0.0052\n",
      "Epoch 1931/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01931: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 1932/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01932: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 1933/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01933: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7465 - val_acc: 0.0052\n",
      "Epoch 1934/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01934: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7481 - val_acc: 0.0052\n",
      "Epoch 1935/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01935: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7474 - val_acc: 0.0052\n",
      "Epoch 1936/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01936: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7463 - val_acc: 0.0052\n",
      "Epoch 1937/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01937: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7459 - val_acc: 0.0052\n",
      "Epoch 1938/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01938: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7463 - val_acc: 0.0052\n",
      "Epoch 1939/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01939: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7459 - val_acc: 0.0052\n",
      "Epoch 1940/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01940: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7459 - val_acc: 0.0052\n",
      "Epoch 1941/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01941: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 1942/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01942: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 1943/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01943: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7439 - val_acc: 0.0052\n",
      "Epoch 1944/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01944: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 1945/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01945: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 1946/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01946: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7426 - val_acc: 0.0052\n",
      "Epoch 1947/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01947: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7433 - val_acc: 0.0052\n",
      "Epoch 1948/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01948: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7435 - val_acc: 0.0052\n",
      "Epoch 1949/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01949: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7436 - val_acc: 0.0052\n",
      "Epoch 1950/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01950: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 1951/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01951: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 1952/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01952: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 1953/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01953: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 1954/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01954: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 1955/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01955: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 1956/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01956: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7462 - val_acc: 0.0052\n",
      "Epoch 1957/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01957: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 1958/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3660 - acc: 1.0000Epoch 01958: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3660 - acc: 1.0000 - val_loss: 14.7464 - val_acc: 0.0052\n",
      "Epoch 1959/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01959: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7460 - val_acc: 0.0052\n",
      "Epoch 1960/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01960: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7459 - val_acc: 0.0052\n",
      "Epoch 1961/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01961: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7437 - val_acc: 0.0052\n",
      "Epoch 1962/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01962: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 1963/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01963: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7438 - val_acc: 0.0052\n",
      "Epoch 1964/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01964: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 1965/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01965: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7459 - val_acc: 0.0052\n",
      "Epoch 1966/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01966: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 1967/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01967: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7437 - val_acc: 0.0052\n",
      "Epoch 1968/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01968: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7438 - val_acc: 0.0052\n",
      "Epoch 1969/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01969: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7437 - val_acc: 0.0052\n",
      "Epoch 1970/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01970: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 1971/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01971: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7440 - val_acc: 0.0052\n",
      "Epoch 1972/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01972: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 1973/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01973: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 1974/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01974: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7476 - val_acc: 0.0052\n",
      "Epoch 1975/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01975: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7480 - val_acc: 0.0052\n",
      "Epoch 1976/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01976: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7464 - val_acc: 0.0052\n",
      "Epoch 1977/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01977: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 1978/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01978: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 1979/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01979: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 1980/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01980: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 1981/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01981: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 1982/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01982: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 1983/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01983: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 1984/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01984: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 1985/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01985: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 1986/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01986: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 1987/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01987: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 1988/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 01988: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7461 - val_acc: 0.0052\n",
      "Epoch 1989/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01989: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7465 - val_acc: 0.0052\n",
      "Epoch 1990/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01990: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7469 - val_acc: 0.0052\n",
      "Epoch 1991/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01991: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 1992/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01992: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7460 - val_acc: 0.0052\n",
      "Epoch 1993/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01993: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 1994/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01994: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 1995/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01995: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7435 - val_acc: 0.0052\n",
      "Epoch 1996/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01996: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 1997/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01997: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 1998/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 01998: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 1999/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 01999: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 2000/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02000: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 2001/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02001: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 2002/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02002: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 2003/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02003: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 2004/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 02004: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 2005/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02005: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 2006/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02006: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7464 - val_acc: 0.0052\n",
      "Epoch 2007/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02007: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7460 - val_acc: 0.0052\n",
      "Epoch 2008/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02008: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 2009/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 02009: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 2010/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02010: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 2011/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02011: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 2012/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 02012: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 2013/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02013: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7460 - val_acc: 0.0052\n",
      "Epoch 2014/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02014: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 2015/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 02015: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7463 - val_acc: 0.0052\n",
      "Epoch 2016/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02016: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 2017/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02017: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 2018/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02018: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7440 - val_acc: 0.0052\n",
      "Epoch 2019/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02019: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 2020/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02020: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 2021/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02021: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 2022/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 02022: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 2023/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02023: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 2024/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02024: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 2025/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02025: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 2026/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 02026: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7460 - val_acc: 0.0052\n",
      "Epoch 2027/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 02027: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 2028/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02028: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7463 - val_acc: 0.0052\n",
      "Epoch 2029/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 02029: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 2030/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 02030: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 2031/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02031: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7435 - val_acc: 0.0052\n",
      "Epoch 2032/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 02032: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 2033/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02033: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 2034/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02034: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7462 - val_acc: 0.0052\n",
      "Epoch 2035/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 02035: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 2036/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 02036: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 2037/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 02037: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7440 - val_acc: 0.0052\n",
      "Epoch 2038/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 02038: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7432 - val_acc: 0.0052\n",
      "Epoch 2039/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02039: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7431 - val_acc: 0.0052\n",
      "Epoch 2040/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02040: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7433 - val_acc: 0.0052\n",
      "Epoch 2041/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02041: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7431 - val_acc: 0.0052\n",
      "Epoch 2042/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02042: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7425 - val_acc: 0.0052\n",
      "Epoch 2043/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02043: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 2044/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 02044: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 2045/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 02045: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 2046/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 02046: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7460 - val_acc: 0.0052\n",
      "Epoch 2047/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02047: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7463 - val_acc: 0.0052\n",
      "Epoch 2048/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02048: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7466 - val_acc: 0.0052\n",
      "Epoch 2049/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02049: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 2050/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02050: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 2051/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 02051: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7438 - val_acc: 0.0052\n",
      "Epoch 2052/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02052: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 2053/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02053: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 2054/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02054: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 2055/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 02055: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7434 - val_acc: 0.0052\n",
      "Epoch 2056/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02056: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 2057/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 02057: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7463 - val_acc: 0.0052\n",
      "Epoch 2058/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 02058: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7460 - val_acc: 0.0052\n",
      "Epoch 2059/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02059: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7465 - val_acc: 0.0052\n",
      "Epoch 2060/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02060: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 2061/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02061: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 2062/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02062: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7440 - val_acc: 0.0052\n",
      "Epoch 2063/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 02063: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 2064/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02064: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7462 - val_acc: 0.0052\n",
      "Epoch 2065/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02065: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 2066/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02066: val_acc did not improve\n",
      "5364/5364 [==============================] - 164s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 2067/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 02067: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7426 - val_acc: 0.0052\n",
      "Epoch 2068/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02068: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7438 - val_acc: 0.0052\n",
      "Epoch 2069/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 02069: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 2070/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 02070: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 2071/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02071: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 2072/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 02072: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 2073/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02073: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7462 - val_acc: 0.0052\n",
      "Epoch 2074/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 02074: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 2075/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02075: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7439 - val_acc: 0.0052\n",
      "Epoch 2076/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 02076: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 2077/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02077: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 2078/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02078: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 2079/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 02079: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7465 - val_acc: 0.0052\n",
      "Epoch 2080/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 02080: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 2081/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02081: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 2082/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 02082: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 2083/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 02083: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 2084/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02084: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7472 - val_acc: 0.0052\n",
      "Epoch 2085/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 02085: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7469 - val_acc: 0.0052\n",
      "Epoch 2086/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02086: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7459 - val_acc: 0.0052\n",
      "Epoch 2087/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02087: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 2088/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02088: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 2089/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02089: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 2090/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02090: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7460 - val_acc: 0.0052\n",
      "Epoch 2091/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02091: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 2092/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 02092: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7472 - val_acc: 0.0052\n",
      "Epoch 2093/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 02093: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7482 - val_acc: 0.0052\n",
      "Epoch 2094/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 02094: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7467 - val_acc: 0.0052\n",
      "Epoch 2095/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02095: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7461 - val_acc: 0.0052\n",
      "Epoch 2096/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 02096: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 2097/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02097: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 2098/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02098: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7431 - val_acc: 0.0052\n",
      "Epoch 2099/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 02099: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 2100/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02100: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 2101/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02101: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7435 - val_acc: 0.0052\n",
      "Epoch 2102/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02102: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7438 - val_acc: 0.0052\n",
      "Epoch 2103/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02103: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 2104/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 02104: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 2105/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02105: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 2106/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02106: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 2107/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02107: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 2108/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 02108: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7461 - val_acc: 0.0052\n",
      "Epoch 2109/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02109: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7459 - val_acc: 0.0052\n",
      "Epoch 2110/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02110: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7467 - val_acc: 0.0052\n",
      "Epoch 2111/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 02111: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7468 - val_acc: 0.0052\n",
      "Epoch 2112/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02112: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7475 - val_acc: 0.0052\n",
      "Epoch 2113/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02113: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7462 - val_acc: 0.0052\n",
      "Epoch 2114/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 02114: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 2115/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02115: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 2116/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02116: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7460 - val_acc: 0.0052\n",
      "Epoch 2117/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 02117: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 2118/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02118: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7473 - val_acc: 0.0052\n",
      "Epoch 2119/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 02119: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7469 - val_acc: 0.0052\n",
      "Epoch 2120/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 02120: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7468 - val_acc: 0.0052\n",
      "Epoch 2121/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02121: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7467 - val_acc: 0.0052\n",
      "Epoch 2122/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02122: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 2123/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02123: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 2124/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02124: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 2125/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02125: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7460 - val_acc: 0.0052\n",
      "Epoch 2126/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3660 - acc: 1.0000Epoch 02126: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7477 - val_acc: 0.0052\n",
      "Epoch 2127/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 02127: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7470 - val_acc: 0.0052\n",
      "Epoch 2128/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02128: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7461 - val_acc: 0.0052\n",
      "Epoch 2129/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02129: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7460 - val_acc: 0.0052\n",
      "Epoch 2130/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02130: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7460 - val_acc: 0.0052\n",
      "Epoch 2131/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02131: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 2132/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02132: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 2133/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 02133: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7439 - val_acc: 0.0052\n",
      "Epoch 2134/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 02134: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 2135/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02135: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7440 - val_acc: 0.0052\n",
      "Epoch 2136/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 02136: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7460 - val_acc: 0.0052\n",
      "Epoch 2137/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02137: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7463 - val_acc: 0.0052\n",
      "Epoch 2138/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02138: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7465 - val_acc: 0.0052\n",
      "Epoch 2139/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 02139: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7464 - val_acc: 0.0052\n",
      "Epoch 2140/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02140: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7463 - val_acc: 0.0052\n",
      "Epoch 2141/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02141: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7465 - val_acc: 0.0052\n",
      "Epoch 2142/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02142: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7468 - val_acc: 0.0052\n",
      "Epoch 2143/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02143: val_acc did not improve\n",
      "5364/5364 [==============================] - 164s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7462 - val_acc: 0.0052\n",
      "Epoch 2144/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 02144: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7471 - val_acc: 0.0052\n",
      "Epoch 2145/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02145: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7467 - val_acc: 0.0052\n",
      "Epoch 2146/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 02146: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7467 - val_acc: 0.0052\n",
      "Epoch 2147/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02147: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7464 - val_acc: 0.0052\n",
      "Epoch 2148/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 02148: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 2149/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02149: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 2150/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02150: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 2151/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02151: val_acc did not improve\n",
      "5364/5364 [==============================] - 165s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 2152/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02152: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 2153/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02153: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 2154/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02154: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7436 - val_acc: 0.0052\n",
      "Epoch 2155/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 02155: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7428 - val_acc: 0.0052\n",
      "Epoch 2156/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02156: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7439 - val_acc: 0.0052\n",
      "Epoch 2157/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 02157: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7438 - val_acc: 0.0052\n",
      "Epoch 2158/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 02158: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 2159/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 02159: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 2160/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02160: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 2161/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 02161: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 2162/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 02162: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 2163/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02163: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 2164/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 02164: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7461 - val_acc: 0.0052\n",
      "Epoch 2165/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02165: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7467 - val_acc: 0.0052\n",
      "Epoch 2166/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 02166: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7472 - val_acc: 0.0052\n",
      "Epoch 2167/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 02167: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7463 - val_acc: 0.0052\n",
      "Epoch 2168/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02168: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 2169/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 02169: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 2170/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02170: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 2171/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02171: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7438 - val_acc: 0.0052\n",
      "Epoch 2172/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02172: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 2173/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02173: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 2174/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02174: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7431 - val_acc: 0.0052\n",
      "Epoch 2175/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02175: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 2176/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02176: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 2177/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 02177: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 2178/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02178: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 2179/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02179: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 2180/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02180: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7438 - val_acc: 0.0052\n",
      "Epoch 2181/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02181: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 2182/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02182: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 2183/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02183: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 2184/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 02184: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 2185/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 02185: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 2186/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02186: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7439 - val_acc: 0.0052\n",
      "Epoch 2187/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02187: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7422 - val_acc: 0.0052\n",
      "Epoch 2188/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02188: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7440 - val_acc: 0.0052\n",
      "Epoch 2189/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02189: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7438 - val_acc: 0.0052\n",
      "Epoch 2190/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02190: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 2191/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02191: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 2192/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02192: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 2193/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 02193: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 2194/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02194: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 2195/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02195: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7463 - val_acc: 0.0052\n",
      "Epoch 2196/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 02196: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 2197/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02197: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 2198/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 02198: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7460 - val_acc: 0.0052\n",
      "Epoch 2199/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 02199: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 2200/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 02200: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 2201/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02201: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 2202/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02202: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 2203/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02203: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7463 - val_acc: 0.0052\n",
      "Epoch 2204/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02204: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 2205/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02205: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 2206/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02206: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7439 - val_acc: 0.0052\n",
      "Epoch 2207/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02207: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 2208/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 02208: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7462 - val_acc: 0.0052\n",
      "Epoch 2209/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02209: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 2210/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02210: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 2211/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02211: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 2212/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 02212: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 2213/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02213: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 2214/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02214: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 2215/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02215: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7426 - val_acc: 0.0052\n",
      "Epoch 2216/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02216: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7426 - val_acc: 0.0052\n",
      "Epoch 2217/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02217: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7436 - val_acc: 0.0052\n",
      "Epoch 2218/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02218: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 2219/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 02219: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7436 - val_acc: 0.0052\n",
      "Epoch 2220/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02220: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 2221/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 02221: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 2222/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02222: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7434 - val_acc: 0.0052\n",
      "Epoch 2223/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02223: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7440 - val_acc: 0.0052\n",
      "Epoch 2224/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02224: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 2225/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 02225: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 2226/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 02226: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 2227/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02227: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 2228/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 02228: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 2229/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02229: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 2230/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02230: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 2231/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02231: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 2232/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 02232: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7464 - val_acc: 0.0052\n",
      "Epoch 2233/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 02233: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 2234/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02234: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 2235/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02235: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 2236/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02236: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7440 - val_acc: 0.0052\n",
      "Epoch 2237/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02237: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7438 - val_acc: 0.0052\n",
      "Epoch 2238/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 02238: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 2239/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 02239: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7436 - val_acc: 0.0052\n",
      "Epoch 2240/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02240: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7434 - val_acc: 0.0052\n",
      "Epoch 2241/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02241: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7435 - val_acc: 0.0052\n",
      "Epoch 2242/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02242: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7430 - val_acc: 0.0052\n",
      "Epoch 2243/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02243: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 2244/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 02244: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 2245/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02245: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 2246/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02246: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 2247/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 02247: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 2248/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02248: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 2249/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02249: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 2250/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02250: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 2251/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02251: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 2252/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02252: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 2253/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02253: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 2254/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 02254: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7438 - val_acc: 0.0052\n",
      "Epoch 2255/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 02255: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 2256/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02256: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7439 - val_acc: 0.0052\n",
      "Epoch 2257/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 02257: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 2258/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02258: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 2259/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 02259: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 2260/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02260: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 2261/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02261: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 2262/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02262: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 2263/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 02263: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7451 - val_acc: 0.0052\n",
      "Epoch 2264/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 02264: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7450 - val_acc: 0.0052\n",
      "Epoch 2265/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02265: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7458 - val_acc: 0.0052\n",
      "Epoch 2266/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 02266: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7438 - val_acc: 0.0052\n",
      "Epoch 2267/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02267: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7439 - val_acc: 0.0052\n",
      "Epoch 2268/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02268: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 2269/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 02269: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 2270/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02270: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7438 - val_acc: 0.0052\n",
      "Epoch 2271/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02271: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7459 - val_acc: 0.0052\n",
      "Epoch 2272/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02272: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 2273/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02273: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 2274/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02274: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7439 - val_acc: 0.0052\n",
      "Epoch 2275/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02275: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7443 - val_acc: 0.0052\n",
      "Epoch 2276/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 02276: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 2277/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02277: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7454 - val_acc: 0.0052\n",
      "Epoch 2278/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02278: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7455 - val_acc: 0.0052\n",
      "Epoch 2279/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02279: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 2280/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02280: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7457 - val_acc: 0.0052\n",
      "Epoch 2281/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02281: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7461 - val_acc: 0.0052\n",
      "Epoch 2282/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02282: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7453 - val_acc: 0.0052\n",
      "Epoch 2283/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 02283: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 2284/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02284: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 2285/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 02285: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7442 - val_acc: 0.0052\n",
      "Epoch 2286/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02286: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 2287/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02287: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7447 - val_acc: 0.0052\n",
      "Epoch 2288/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02288: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7456 - val_acc: 0.0052\n",
      "Epoch 2289/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02289: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7452 - val_acc: 0.0052\n",
      "Epoch 2290/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02290: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 2291/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02291: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7449 - val_acc: 0.0052\n",
      "Epoch 2292/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02292: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 2293/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02293: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7446 - val_acc: 0.0052\n",
      "Epoch 2294/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02294: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7438 - val_acc: 0.0052\n",
      "Epoch 2295/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 02295: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7434 - val_acc: 0.0052\n",
      "Epoch 2296/100000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02296: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7436 - val_acc: 0.0052\n",
      "Epoch 2297/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02297: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7444 - val_acc: 0.0052\n",
      "Epoch 2298/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02298: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7448 - val_acc: 0.0052\n",
      "Epoch 2299/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02299: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7441 - val_acc: 0.0052\n",
      "Epoch 2300/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 02300: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7445 - val_acc: 0.0052\n",
      "Epoch 2301/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02301: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7464 - val_acc: 0.0052\n",
      "Epoch 2302/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02302: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7461 - val_acc: 0.0052\n",
      "Epoch 2303/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02303: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7469 - val_acc: 0.0052\n",
      "Epoch 2304/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02304: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7467 - val_acc: 0.0052\n",
      "Epoch 2305/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 02305: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3659 - acc: 1.0000 - val_loss: 14.7480 - val_acc: 0.0052\n",
      "Epoch 2306/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3659 - acc: 1.0000Epoch 02306: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7484 - val_acc: 0.0052\n",
      "Epoch 2307/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000Epoch 02307: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3657 - acc: 1.0000 - val_loss: 14.7476 - val_acc: 0.0052\n",
      "Epoch 2308/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3658 - acc: 1.0000Epoch 02308: val_acc did not improve\n",
      "5364/5364 [==============================] - 166s 31ms/step - loss: 1.3658 - acc: 1.0000 - val_loss: 14.7463 - val_acc: 0.0052\n",
      "Epoch 2309/100000\n",
      "5248/5364 [============================>.] - ETA: 3s - loss: 1.3657 - acc: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-9983c3cbceab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#           callbacks=[lr_reducer, early_stopper, csv_logger, checkpoint])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m           callbacks=[lr_reducer, csv_logger, checkpoint])\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\VIPLAB\\AppData\\Local\\conda\\conda\\envs\\keras\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1629\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1630\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1631\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1632\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1633\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\Users\\VIPLAB\\AppData\\Local\\conda\\conda\\envs\\keras\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1225\u001b[0m                             val_outs = self._test_loop(val_f, val_ins,\n\u001b[0;32m   1226\u001b[0m                                                        \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1227\u001b[1;33m                                                        verbose=0)\n\u001b[0m\u001b[0;32m   1228\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1229\u001b[0m                                 \u001b[0mval_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\VIPLAB\\AppData\\Local\\conda\\conda\\envs\\keras\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_test_loop\u001b[1;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1368\u001b[0m                     \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1370\u001b[1;33m                 \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1371\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1372\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\VIPLAB\\AppData\\Local\\conda\\conda\\envs\\keras\\lib\\site-packages\\keras\\backend\\theano_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   1221\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1222\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1223\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\VIPLAB\\AppData\\Local\\conda\\conda\\envs\\keras\\lib\\site-packages\\theano\\compile\\function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    882\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 884\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    886\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\VIPLAB\\AppData\\Local\\conda\\conda\\envs\\keras\\lib\\site-packages\\theano\\ifelse.py\u001b[0m in \u001b[0;36mthunk\u001b[1;34m()\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mthunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcompute_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcond\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(train_x, train_y,\n",
    "          batch_size=batch_size,\n",
    "          epochs=nb_epoch,\n",
    "          shuffle=True,\n",
    "          validation_split=0.2,\n",
    "          verbose=1,\n",
    "#           callbacks=[lr_reducer, early_stopper, csv_logger, checkpoint])\n",
    "          callbacks=[lr_reducer, csv_logger, checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save\n",
    "output_h5 = \"sgd_resnet34_my_final_balance_model_%d.h5\" % threhold\n",
    "model.save(output_h5)   # HDF5 file, you have to pip3 install h5py if don't have it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print('test before save: ', model.predict(X_test[0:2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "901/901 [==============================] - 8s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_x, test_y, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 18.31%\n"
     ]
    }
   ],
   "source": [
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
