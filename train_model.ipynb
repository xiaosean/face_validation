{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Adapted from keras example cifar10_cnn.py\n",
    "Train ResNet-18 on the CIFAR10 small images dataset.\n",
    "\n",
    "GPU run command with Theano backend (with TensorFlow, the GPU is automatically used):\n",
    "    THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatX=float32 python cifar10.py\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ReduceLROnPlateau, CSVLogger, EarlyStopping\n",
    "import numpy as np\n",
    "import pandas\n",
    "import resnet\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data dir\n",
    "directory = \"./lfw_only_face_resize/\"\n",
    "train_x = []\n",
    "train_y = []\n",
    "test_x = []\n",
    "test_y = []\n",
    "threhold = 2\n",
    "count = 0\n",
    "for _dir in os.listdir(directory):\n",
    "#     只訓練>5張的dataset\n",
    "    people_image_count = len(os.listdir(os.path.join(directory, _dir)))\n",
    "    if(people_image_count >= threhold):\n",
    "        count += 1\n",
    "        for index, filename in enumerate(os.listdir(os.path.join(directory, _dir))):\n",
    "            if filename.endswith(\".jpg\"):\n",
    "                img_path = os.path.join(directory, _dir, filename)\n",
    "                image = Image.open(img_path)\n",
    "#                 每個人取1張當作testing\n",
    "                if(index == 0):\n",
    "                    test_x.append(np.array(image))\n",
    "                    test_y.append(_dir)\n",
    "                else:\n",
    "                    train_x.append(np.array(image))\n",
    "                    train_y.append(_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x, train_y = np.array(train_x), np.array(train_y)\n",
    "test_x, test_y = np.array(test_x), np.array(test_y)\n",
    "train_x, test_x = train_x.astype('float32'), test_x.astype('float32')\n",
    "train_y, test_y = pandas.get_dummies(train_y).values, pandas.get_dummies(test_y).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x /= 255\n",
    "test_x /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-6)\n",
    "early_stopper = EarlyStopping(min_delta=0.001, patience=10)\n",
    "csv_logger = CSVLogger('resnet64_faceValidation.csv')\n",
    "# classes = os.listdir(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "nb_classes = count\n",
    "nb_epoch = 100000\n",
    "data_augmentation = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 104, 96\n",
    "# The CIFAR10 images are RGB.\n",
    "img_channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = resnet.ResnetBuilder.build_resnet_64((img_channels, img_rows, img_cols), nb_classes)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7484, 104, 96, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7484, 1680)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7484 samples, validate on 1680 samples\n",
      "Epoch 1/100000\n",
      "7484/7484 [==============================] - 143s 19ms/step - loss: 12.4892 - acc: 0.0655 - val_loss: 18.5901 - val_acc: 0.0000e+00\n",
      "Epoch 2/100000\n",
      "7484/7484 [==============================] - 51s 7ms/step - loss: 10.2683 - acc: 0.0677 - val_loss: 10.7239 - val_acc: 5.9524e-04\n",
      "Epoch 3/100000\n",
      "7484/7484 [==============================] - 51s 7ms/step - loss: 9.5096 - acc: 0.0699 - val_loss: 10.4921 - val_acc: 0.0012\n",
      "Epoch 4/100000\n",
      "7484/7484 [==============================] - 51s 7ms/step - loss: 8.9729 - acc: 0.0712 - val_loss: 11.8103 - val_acc: 5.9524e-04\n",
      "Epoch 5/100000\n",
      "7484/7484 [==============================] - 51s 7ms/step - loss: 8.0366 - acc: 0.0742 - val_loss: 9.7056 - val_acc: 5.9524e-04\n",
      "Epoch 6/100000\n",
      "7484/7484 [==============================] - 54s 7ms/step - loss: 7.3576 - acc: 0.0776 - val_loss: 9.6588 - val_acc: 0.0024\n",
      "Epoch 7/100000\n",
      "7484/7484 [==============================] - 53s 7ms/step - loss: 6.8365 - acc: 0.0946 - val_loss: 9.3424 - val_acc: 0.0036\n",
      "Epoch 8/100000\n",
      "7484/7484 [==============================] - 51s 7ms/step - loss: 6.3247 - acc: 0.1219 - val_loss: 9.7233 - val_acc: 0.0048\n",
      "Epoch 9/100000\n",
      "7484/7484 [==============================] - 51s 7ms/step - loss: 5.9628 - acc: 0.1446 - val_loss: 10.2713 - val_acc: 0.0036\n",
      "Epoch 10/100000\n",
      "7484/7484 [==============================] - 51s 7ms/step - loss: 5.5428 - acc: 0.1792 - val_loss: 9.9349 - val_acc: 0.0107\n",
      "Epoch 11/100000\n",
      "7484/7484 [==============================] - 51s 7ms/step - loss: 5.0192 - acc: 0.2179 - val_loss: 9.8484 - val_acc: 0.0119\n",
      "Epoch 12/100000\n",
      "7484/7484 [==============================] - 51s 7ms/step - loss: 4.5235 - acc: 0.2577 - val_loss: 10.5783 - val_acc: 0.0161\n",
      "Epoch 13/100000\n",
      "7484/7484 [==============================] - 52s 7ms/step - loss: 4.0778 - acc: 0.3156 - val_loss: 10.2788 - val_acc: 0.0232\n",
      "Epoch 14/100000\n",
      "2752/7484 [==========>...................] - ETA: 30s - loss: 3.1172 - acc: 0.5124"
     ]
    }
   ],
   "source": [
    "model.fit(train_x, train_y,\n",
    "          batch_size=batch_size,\n",
    "          epochs=nb_epoch,\n",
    "          validation_data=(test_x, test_y),\n",
    "          shuffle=True,\n",
    "          verbose=1,\n",
    "          callbacks=[lr_reducer, early_stopper, csv_logger])\n",
    "# verbose=1,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save\n",
    "model.save('my_model.h5')   # HDF5 file, you have to pip3 install h5py if don't have it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print('test before save: ', model.predict(X_test[0:2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, batch_size=128)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
