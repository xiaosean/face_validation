{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "import cv2\n",
    "import facenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "cascade_path = \"./haarcascade_frontalface_default.xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "face_detector = dlib.get_frontal_face_detector()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# face detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    \n",
    "    if frame is None:\n",
    "        print(\"lost camera\")\n",
    "        continue\n",
    "#     else:\n",
    "#         frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "    detected_faces = face_detector(frame, 1)\n",
    "    facerect = [(x.left(), x.top(),\n",
    "                    x.right(), x.bottom()) for x in detected_faces]\n",
    "    if len(facerect) > 0:\n",
    "        print('face detected')\n",
    "#         color = (255, 255, 255)  # 白\n",
    "        color = (0,255,0) # 綠\n",
    "        for rect in facerect:\n",
    "            # 找出人臉位置的地方, 並用長方形框起來\n",
    "        \n",
    "            cv2.rectangle(frame, tuple(rect[0:2]), tuple(rect[2:4]), color, 2)\n",
    "#             cv2.rectangle(frame,(384,0),(510,128),(0,255,0),3)\n",
    "\n",
    "            x, y = rect[0:2]\n",
    "            width, height = rect[2:4]\n",
    "            image = frame[y - 10: y + height, x: x + width]\n",
    "            cv2.putText(frame,\"Hello World!!!\", (x,y + 30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, fontScale  = 1,\n",
    "                        color = color,\n",
    "                        thickness=2)\n",
    "\n",
    "            #                 result = model.predict(image)\n",
    "#                 if result == 0:  # boss\n",
    "#                     print('Boss is approaching')\n",
    "\n",
    "#                 else:\n",
    "#                     print('Not boss')\n",
    "    cv2.imshow(\"face dection\", frame)\n",
    "                \n",
    "    #10msecキー入力待ち\n",
    "    k = cv2.waitKey(100)\n",
    "    #Escキーを押されたら終了\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "    #キャプチャを終了\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "failed_image_list = []\n",
    "with tf.Graph().as_default():\n",
    "      \n",
    "        with tf.Session() as sess:\n",
    "            \n",
    "            np.random.seed(seed=666)\n",
    "            \n",
    "            \n",
    "            dataset = facenet.get_dataset(data_dir)\n",
    "\n",
    "            # Check that there are at least one training image per class\n",
    "            for cls in dataset:\n",
    "                assert(len(cls.image_paths)>0, 'There must be at least one image for each class in the dataset')            \n",
    "\n",
    "                 \n",
    "            paths, labels = facenet.get_image_paths_and_labels(dataset)\n",
    "            print('Number of classes: %d' % len(dataset))\n",
    "            print('Number of images: %d' % len(paths))\n",
    "            \n",
    "            # Load the model\n",
    "            print('Loading feature extraction model')\n",
    "            facenet.load_model(model)\n",
    "            \n",
    "            # Get input and output tensors\n",
    "            images_placeholder = tf.get_default_graph().get_tensor_by_name(\"input:0\")\n",
    "            embeddings = tf.get_default_graph().get_tensor_by_name(\"embeddings:0\")\n",
    "            phase_train_placeholder = tf.get_default_graph().get_tensor_by_name(\"phase_train:0\")\n",
    "            embedding_size = embeddings.get_shape()[1]\n",
    "            \n",
    "            # Run forward pass to calculate embeddings\n",
    "            print('Calculating features for images')\n",
    "            nrof_images = len(paths)\n",
    "            nrof_batches_per_epoch = int(math.ceil(1.0*nrof_images / batch_size))\n",
    "            emb_array = np.zeros((nrof_images, embedding_size))\n",
    "            for i in range(nrof_batches_per_epoch):\n",
    "                start_index = i*batch_size\n",
    "                end_index = min((i+1)*batch_size, nrof_images)\n",
    "                paths_batch = paths[start_index:end_index]\n",
    "                images = facenet.load_data(paths_batch, False, False, image_size)\n",
    "                feed_dict = { images_placeholder:images, phase_train_placeholder:False }\n",
    "                emb_array[start_index:end_index,:] = sess.run(embeddings, feed_dict=feed_dict)\n",
    "            \n",
    "            classifier_filename_exp = os.path.expanduser(classifier_filename)\n",
    "\n",
    "            if (mode=='TRAIN'):\n",
    "                # Train classifier\n",
    "                print('Training classifier')\n",
    "                model = SVC(kernel='linear', probability=True)\n",
    "                model.fit(emb_array, labels)\n",
    "            \n",
    "                # Create a list of class names\n",
    "                class_names = [ cls.name.replace('_', ' ') for cls in dataset]\n",
    "\n",
    "                # Saving classifier model\n",
    "                with open(classifier_filename_exp, 'wb') as outfile:\n",
    "                    pickle.dump((model, class_names), outfile)\n",
    "                print('Saved classifier model to file \"%s\"' % classifier_filename_exp)\n",
    "                \n",
    "            elif (mode=='CLASSIFY'):\n",
    "                # Classify images\n",
    "                print('Testing classifier')\n",
    "                with open(classifier_filename_exp, 'rb') as infile:\n",
    "                    (model, class_names) = pickle.load(infile)\n",
    "\n",
    "                print('Loaded classifier model from file \"%s\"' % classifier_filename_exp)\n",
    "\n",
    "                predictions = model.predict_proba(emb_array)\n",
    "                best_class_indices = np.argmax(predictions, axis=1)\n",
    "                best_class_probabilities = predictions[np.arange(len(best_class_indices)), best_class_indices]\n",
    "\n",
    "                for i in range(len(best_class_indices)):\n",
    "                    image_name = paths[i].split(\"/\")[-1]\n",
    "                    person_name = image_name.split(\"\\\\\")[0]\n",
    "#                     print('ground truth name %s: my predict = %s' % (, class_names[best_class_indices[i]]))\n",
    "#                     print('%4d  %s: %.3f' % (i, class_names[best_class_indices[i]], best_class_probabilities[i]))\n",
    "                    if(person_name != class_names[best_class_indices[i]]):\n",
    "                        print(image_name)\n",
    "                        failed_image_list.append(paths[i])\n",
    "                        \n",
    "                accuracy = np.mean(np.equal(best_class_indices, labels))\n",
    "                print('Accuracy: %.3f' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
