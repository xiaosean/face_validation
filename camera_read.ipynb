{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "import cv2\n",
    "import facenet\n",
    "import dlib\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "face_detector = dlib.get_frontal_face_detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = 'C:/Users/VIPLAB/models/facenet/20171227_lfw_add_10.pb'\n",
    "# classifier_filename = 'C:/Users/VIPLAB/models/facenet/20171227_lfw_add_10.pkl'\n",
    "model = 'C:/Users/VIPLAB/models/facenet/20171208_only_3image_8people.pb'\n",
    "classifier_filename = 'C:/Users/VIPLAB/models/facenet/20171208_only_3image_8people.pkl'\n",
    "\n",
    "# train_data_dir = \"../xiao_face_dataset_only_face/\"\n",
    "# train_data_dir = \"../xiao_face_lfw_and_own/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# classes = os.listdir(train_data_dir)\n",
    "# classes.sort()\n",
    "# classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model filename: C:/Users/VIPLAB/models/facenet/20171208_only_3image_8people.pb\n",
      "Calculating features for images\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "facenet.load_model(model)\n",
    "            \n",
    "# Get input and output tensors\n",
    "images_placeholder = tf.get_default_graph().get_tensor_by_name(\"input:0\")\n",
    "embeddings = tf.get_default_graph().get_tensor_by_name(\"embeddings:0\")\n",
    "phase_train_placeholder = tf.get_default_graph().get_tensor_by_name(\"phase_train:0\")\n",
    "embedding_size = embeddings.get_shape()[1]\n",
    "# Run forward pass to calculate embeddings\n",
    "print('Calculating features for images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded classifier model from file \"C:/Users/VIPLAB/models/facenet/20171208_only_3image_8people.pkl\"\n"
     ]
    }
   ],
   "source": [
    "classifier_filename_exp = os.path.expanduser(classifier_filename)\n",
    "with open(classifier_filename_exp, 'rb') as infile:\n",
    "                    (model, class_names) = pickle.load(infile)\n",
    "print('Loaded classifier model from file \"%s\"' % classifier_filename_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded classifier model class_names \"['劉宴任', '宋俊樺', '林彥丞', '林詠翔', '柳威寧', '聶誠漢', '陳仕傑', '陳廷冠']\"\n"
     ]
    }
   ],
   "source": [
    "print('Loaded classifier model class_names \"%s\"' % class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(images, threshold = 0.15):\n",
    "    results = []\n",
    "    threshold = threshold\n",
    "    size = 160\n",
    "    image_count = len(images)\n",
    "    resize_images = [cv2.resize(image,(size, size), interpolation = cv2.INTER_CUBIC) for image in images]\n",
    "    feed_dict = { images_placeholder:resize_images, phase_train_placeholder:False }\n",
    "    emb_array = np.zeros((image_count, embedding_size))\n",
    "    emb_array[0:image_count,:] = sess.run(embeddings, feed_dict=feed_dict)\n",
    "    predictions = model.predict_proba(emb_array)\n",
    "    best_class_indices = np.argmax(predictions, axis=1)\n",
    "    best_class_probabilities = predictions[np.arange(len(best_class_indices)), best_class_indices]\n",
    "    \n",
    "    for i in range(len(best_class_indices)):\n",
    "        print('%4d  %s: %.3f' % (i, class_names[best_class_indices[i]], best_class_probabilities[i]))\\\n",
    "        \n",
    "        if(best_class_probabilities[i] >= threshold):\n",
    "#             print(class_names[best_class_indices[i]])\n",
    "            results.append(class_names[best_class_indices[i]])\n",
    "        else:\n",
    "            results.append(\"unknown\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "correct_people = ['林詠翔', '陳廷冠']\n",
    "correct_color = (0,255,0) # 綠\n",
    "failed_color = (255,0,0) # 紅\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.295\n",
      "林詠翔\n",
      "   0  林詠翔: 0.295\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.297\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.297\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.295\n",
      "林詠翔\n",
      "   0  林詠翔: 0.295\n",
      "林詠翔\n",
      "   0  林詠翔: 0.295\n",
      "林詠翔\n",
      "   0  林詠翔: 0.295\n",
      "林詠翔\n",
      "   0  林詠翔: 0.295\n",
      "林詠翔\n",
      "   0  林詠翔: 0.297\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "   1  林詠翔: 0.299\n",
      "林詠翔\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.295\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.295\n",
      "林詠翔\n",
      "   0  林詠翔: 0.295\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.295\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.295\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.295\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.298\n",
      "林詠翔\n",
      "   0  林詠翔: 0.297\n",
      "林詠翔\n",
      "   0  林詠翔: 0.295\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.297\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.297\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.297\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.298\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.297\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.297\n",
      "林詠翔\n",
      "   0  林詠翔: 0.297\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.295\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.295\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.297\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.295\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.295\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.297\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.297\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.297\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.297\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.297\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.297\n",
      "林詠翔\n",
      "   0  林詠翔: 0.297\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.297\n",
      "林詠翔\n",
      "   0  林詠翔: 0.297\n",
      "林詠翔\n",
      "   0  林詠翔: 0.297\n",
      "林詠翔\n",
      "   0  林詠翔: 0.297\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n",
      "   0  林詠翔: 0.296\n",
      "林詠翔\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-5c5bd14eb34c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mdetected_faces\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface_detector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     facerect = [(x.left(), x.top(),\n\u001b[0;32m     10\u001b[0m                     x.right(), x.bottom()) for x in detected_faces]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    \n",
    "    if frame is None:\n",
    "        print(\"lost camera\")\n",
    "        break\n",
    "\n",
    "    detected_faces = face_detector(frame, 1)\n",
    "    facerect = [(x.left(), x.top(),\n",
    "                    x.right(), x.bottom()) for x in detected_faces]\n",
    "    width, height = frame.shape[1], frame.shape[0]\n",
    "    facerect_revise = []\n",
    "    for index, rect in enumerate(facerect):\n",
    "        x_left = rect[0]\n",
    "        x_right = rect[2]\n",
    "        y_top = rect[1]\n",
    "        y_bottom = rect[3]\n",
    "#         避免超出邊界\n",
    "        if(x_left < 0):\n",
    "            x_left = 0\n",
    "        if(x_right > width):\n",
    "            x_right = width-1\n",
    "        if(y_top < 0):\n",
    "            y_top = 0\n",
    "        if(y_bottom > height):\n",
    "            y_bottom = height-1\n",
    "        facerect_revise.append(tuple([x_left, y_top, x_right, y_bottom]))\n",
    "    facerect = facerect_revise\n",
    "    if len(facerect) > 0:\n",
    "#         print('face detected')\n",
    "        \n",
    "#         color = (255, 255, 255)  # 白\n",
    "        images = [frame[rect[1]: rect[3], rect[0]: rect[2]] for rect in facerect]\n",
    "        result = predict(images)\n",
    "        \n",
    "#         cv2.imshow(\"face dection\", images[0])\n",
    "#         k = cv2.waitKey(100)\n",
    "#         #點擊esc離開\n",
    "#         if k == 27:\n",
    "#             break\n",
    "\n",
    "#         continue\n",
    "        for index, rect in enumerate(facerect):\n",
    "            # 找出人臉位置的地方, 並用長方形框起來\n",
    "                \n",
    "            if(result[index] != \"unknown\"):\n",
    "#                 cv2.rectangle(frame, tuple(rect[0:2]), tuple(rect[2:4]), color, 2)\n",
    "#                 print(result[index])\n",
    "                person_name = result[index]\n",
    "                print(person_name)\n",
    "                if(result[index] == '陳廷冠'):\n",
    "                    color = correct_color\n",
    "                    person_name = \"toby\"\n",
    "                if(result[index] == '林詠翔'):\n",
    "                    color = correct_color\n",
    "                    person_name = \"xiaosean\"\n",
    "#                 if(result[index] in correct_people):\n",
    "#                     color = correct_color\n",
    "#                     person_name = \"xiaosean\"\n",
    "                else:\n",
    "                    color = failed_color\n",
    "                x, y = rect[0], rect[1]\n",
    "                cv2.rectangle(frame, tuple(rect[0:2]), tuple(rect[2:4]), color, 2)\n",
    "                cv2.putText(frame, person_name, (x,y + 30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, fontScale  = 1,\n",
    "                        color = color,\n",
    "                        thickness=2)\n",
    "                \n",
    "            \n",
    "    cv2.imshow(\"face dection\", frame)\n",
    "                \n",
    "    #延遲 10msec\n",
    "    k = cv2.waitKey(100)\n",
    "    #點擊esc離開\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "    #キャプチャを終了\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = \"../lfw_mtcnnpy_160/\"\n",
    "paths, labels = facenet.get_image_paths_and_labels(dataset)\n",
    "print('Number of classes: %d' % len(dataset))\n",
    "print('Number of images: %d' % len(paths))\n",
    "# Load the model\n",
    "print('Loading feature extraction model')\n",
    "facenet.load_model(model)\n",
    "\n",
    "# Get input and output tensors\n",
    "images_placeholder = tf.get_default_graph().get_tensor_by_name(\"input:0\")\n",
    "embeddings = tf.get_default_graph().get_tensor_by_name(\"embeddings:0\")\n",
    "phase_train_placeholder = tf.get_default_graph().get_tensor_by_name(\"phase_train:0\")\n",
    "embedding_size = embeddings.get_shape()[1]\n",
    "\n",
    "# Run forward pass to calculate embeddings\n",
    "print('Calculating features for images')\n",
    "nrof_images = len(paths)\n",
    "nrof_batches_per_epoch = int(math.ceil(1.0*nrof_images / batch_size))\n",
    "emb_array = np.zeros((nrof_images, embedding_size))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
