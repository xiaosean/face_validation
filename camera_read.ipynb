{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "import cv2\n",
    "import facenet\n",
    "import dlib\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "face_detector = dlib.get_frontal_face_detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = 'C:/Users/VIPLAB/models/facenet/20171208_only_3image_8people.pb'\n",
    "classifier_filename = 'C:/Users/VIPLAB/models/facenet/20171208_only_3image_8people.pkl'\n",
    "train_data_dir = \"../xiao_face_dataset_only_face/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = os.listdir(train_data_dir)\n",
    "classes.sort()\n",
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "facenet.load_model(model)\n",
    "            \n",
    "# Get input and output tensors\n",
    "images_placeholder = tf.get_default_graph().get_tensor_by_name(\"input:0\")\n",
    "embeddings = tf.get_default_graph().get_tensor_by_name(\"embeddings:0\")\n",
    "phase_train_placeholder = tf.get_default_graph().get_tensor_by_name(\"phase_train:0\")\n",
    "embedding_size = embeddings.get_shape()[1]\n",
    "# Run forward pass to calculate embeddings\n",
    "print('Calculating features for images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_filename_exp = os.path.expanduser(classifier_filename)\n",
    "with open(classifier_filename_exp, 'rb') as infile:\n",
    "                    (model, class_names) = pickle.load(infile)\n",
    "print('Loaded classifier model from file \"%s\"' % classifier_filename_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(images, threshold = 0.15):\n",
    "    results = []\n",
    "    threshold = threshold\n",
    "    size = 160\n",
    "    image_count = len(images)\n",
    "    resize_images = [cv2.resize(image,(size, size), interpolation = cv2.INTER_CUBIC) for image in images]\n",
    "    feed_dict = { images_placeholder:resize_images, phase_train_placeholder:False }\n",
    "    emb_array = np.zeros((image_count, embedding_size))\n",
    "    emb_array[0:image_count,:] = sess.run(embeddings, feed_dict=feed_dict)\n",
    "    predictions = model.predict_proba(emb_array)\n",
    "    best_class_indices = np.argmax(predictions, axis=1)\n",
    "    best_class_probabilities = predictions[np.arange(len(best_class_indices)), best_class_indices]\n",
    "    \n",
    "    for i in range(len(best_class_indices)):\n",
    "#         print('%4d  %s: %.3f' % (i, class_names[best_class_indices[i]], best_class_probabilities[i]))\n",
    "        if(best_class_probabilities[i] >= threshold):\n",
    "#             print(class_names[best_class_indices[i]])\n",
    "            results.append(class_names[best_class_indices[i]])\n",
    "        else:\n",
    "            results.append(\"unknown\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "correct_people = '林詠翔'\n",
    "correct_color = (0,255,0) # 綠\n",
    "failed_color = (255,0,0) # 紅\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    \n",
    "    if frame is None:\n",
    "        print(\"lost camera\")\n",
    "        break\n",
    "\n",
    "    detected_faces = face_detector(frame, 1)\n",
    "    facerect = [(x.left(), x.top(),\n",
    "                    x.right(), x.bottom()) for x in detected_faces]\n",
    "    facerect_revise = []\n",
    "    for index, rect in enumerate(facerect):\n",
    "        x_left = rect[0]\n",
    "        x_right = rect[2]\n",
    "        y_top = rect[1]\n",
    "        y_bottom = rect[3]\n",
    "#         避免超出邊界\n",
    "        if(x_left < 0):\n",
    "            x_left = 0\n",
    "        if(x_right > width):\n",
    "            x_right = width-1\n",
    "        if(y_top < 0):\n",
    "            y_top = 0\n",
    "        if(y_bottom > height):\n",
    "            y_bottom = height-1\n",
    "        facerect_revise.append(tuple([x_left, y_top, x_right, y_bottom]))\n",
    "    facerect = facerect_revise\n",
    "    if len(facerect) > 0:\n",
    "#         print('face detected')\n",
    "        \n",
    "#         color = (255, 255, 255)  # 白\n",
    "        images = [frame[rect[1]: rect[3], rect[0]: rect[2]] for rect in facerect]\n",
    "        result = predict(images)\n",
    "        for index, rect in enumerate(facerect):\n",
    "            # 找出人臉位置的地方, 並用長方形框起來\n",
    "                \n",
    "            if(result[index] != \"unknown\"):\n",
    "#                 cv2.rectangle(frame, tuple(rect[0:2]), tuple(rect[2:4]), color, 2)\n",
    "#                 print(result[index])\n",
    "                person_name = result[index]\n",
    "                if(result[index] == correct_people):\n",
    "                    color = correct_color\n",
    "                    person_name = \"xiaosean\"\n",
    "                else:\n",
    "                    color = failed_color\n",
    "                x, y = rect[0], rect[1]\n",
    "                cv2.rectangle(frame, tuple(rect[0:2]), tuple(rect[2:4]), color, 2)\n",
    "                cv2.putText(frame, person_name, (x,y + 30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, fontScale  = 1,\n",
    "                        color = color,\n",
    "                        thickness=2)\n",
    "                \n",
    "            \n",
    "    cv2.imshow(\"face dection\", frame)\n",
    "                \n",
    "    #延遲 10msec\n",
    "    k = cv2.waitKey(10)\n",
    "    #點擊esc離開\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "    #キャプチャを終了\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
